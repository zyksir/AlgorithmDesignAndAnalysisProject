{\rtf1\ansi\ansicpg936\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \CocoaLigature0 current epoch 1\
1591273382: step 1, loss 1.80521, acc 0.318182\
1591273383: step 2, loss 1.9457, acc 0.363636\
1591273384: step 3, loss 1.74913, acc 0.227273\
1591273385: step 4, loss 1.37754, acc 0.409091\
1591273386: step 5, loss 2.18911, acc 0.136364\
1591273387: step 6, loss 1.85382, acc 0.0909091\
1591273388: step 7, loss 1.6945, acc 0.272727\
1591273389: step 8, loss 1.62427, acc 0.272727\
1591273390: step 9, loss 1.61416, acc 0.363636\
1591273391: step 10, loss 1.69115, acc 0.227273\
1591273392: step 11, loss 1.61287, acc 0.318182\
1591273393: step 12, loss 1.72675, acc 0.227273\
1591273394: step 13, loss 1.47419, acc 0.409091\
1591273395: step 14, loss 1.88807, acc 0.181818\
1591273396: step 15, loss 1.6983, acc 0.363636\
1591273397: step 16, loss 1.61019, acc 0.363636\
1591273398: step 17, loss 1.78636, acc 0.318182\
1591273399: step 18, loss 1.52858, acc 0.454545\
1591273400: step 19, loss 1.6488, acc 0.318182\
1591273401: step 20, loss 1.78513, acc 0.318182\
1591273402: step 21, loss 1.77567, acc 0.181818\
1591273403: step 22, loss 1.43455, acc 0.454545\
1591273404: step 23, loss 1.51118, acc 0.227273\
1591273405: step 24, loss 1.48469, acc 0.363636\
1591273406: step 25, loss 1.7755, acc 0.227273\
1591273407: step 26, loss 1.58433, acc 0.272727\
1591273408: step 27, loss 1.66225, acc 0.227273\
1591273409: step 28, loss 1.71469, acc 0.272727\
1591273410: step 29, loss 1.54196, acc 0.272727\
1591273411: step 30, loss 1.52676, acc 0.272727\
1591273412: step 31, loss 1.59491, acc 0.409091\
1591273413: step 32, loss 1.6589, acc 0.136364\
1591273414: step 33, loss 1.51987, acc 0.318182\
1591273415: step 34, loss 1.58119, acc 0.272727\
1591273416: step 35, loss 1.73861, acc 0.272727\
1591273417: step 36, loss 1.62846, acc 0.318182\
1591273418: step 37, loss 1.51101, acc 0.272727\
1591273419: step 38, loss 1.54691, acc 0.136364\
1591273419: step 39, loss 1.39758, acc 0.409091\
1591273420: step 40, loss 1.49961, acc 0.318182\
1591273421: step 41, loss 1.6329, acc 0.272727\
1591273422: step 42, loss 1.78123, acc 0.227273\
1591273423: step 43, loss 1.52275, acc 0.5\
1591273424: step 44, loss 1.52772, acc 0.272727\
1591273425: step 45, loss 1.81298, acc 0.227273\
1591273426: step 46, loss 1.83518, acc 0.181818\
1591273427: step 47, loss 1.46929, acc 0.409091\
1591273428: step 48, loss 1.49132, acc 0.318182\
1591273429: step 49, loss 1.65361, acc 0.318182\
1591273430: step 50, loss 1.60689, acc 0.272727\
1591273431: step 51, loss 1.51605, acc 0.227273\
1591273432: step 52, loss 1.52866, acc 0.181818\
1591273433: step 53, loss 1.55383, acc 0.272727\
1591273434: step 54, loss 1.65828, acc 0.181818\
1591273435: step 55, loss 1.55006, acc 0.318182\
1591273436: step 56, loss 1.49808, acc 0.409091\
1591273437: step 57, loss 1.75294, acc 0.272727\
1591273438: step 58, loss 1.71935, acc 0.181818\
1591273439: step 59, loss 1.61731, acc 0.136364\
1591273440: step 60, loss 1.42275, acc 0.318182\
1591273441: step 61, loss 1.66692, acc 0.318182\
1591273442: step 62, loss 1.46831, acc 0.5\
1591273443: step 63, loss 1.56601, acc 0.318182\
1591273444: step 64, loss 1.30639, acc 0.454545\
1591273445: step 65, loss 1.30431, acc 0.5\
1591273446: step 66, loss 1.59927, acc 0.227273\
1591273447: step 67, loss 1.5129, acc 0.227273\
1591273448: step 68, loss 1.67436, acc 0.0909091\
1591273449: step 69, loss 1.62113, acc 0.181818\
1591273450: step 70, loss 1.35118, acc 0.454545\
1591273451: step 71, loss 1.54363, acc 0.318182\
1591273452: step 72, loss 1.69432, acc 0.272727\
1591273453: step 73, loss 1.35176, acc 0.318182\
1591273454: step 74, loss 1.4322, acc 0.363636\
1591273455: step 75, loss 1.50909, acc 0.318182\
1591273456: step 76, loss 1.46365, acc 0.363636\
1591273457: step 77, loss 1.50159, acc 0.318182\
1591273458: step 78, loss 1.64571, acc 0.318182\
1591273459: step 79, loss 1.18812, acc 0.545455\
1591273460: step 80, loss 1.47181, acc 0.409091\
1591273461: step 81, loss 1.7178, acc 0.227273\
1591273462: step 82, loss 1.26668, acc 0.5\
1591273463: step 83, loss 1.37314, acc 0.363636\
1591273464: step 84, loss 1.35869, acc 0.5\
1591273465: step 85, loss 1.31429, acc 0.454545\
1591273466: step 86, loss 1.46596, acc 0.318182\
1591273467: step 87, loss 1.4202, acc 0.363636\
1591273468: step 88, loss 1.38151, acc 0.272727\
1591273469: step 89, loss 1.60171, acc 0.227273\
1591273470: step 90, loss 1.44871, acc 0.272727\
1591273471: step 91, loss 1.25855, acc 0.454545\
1591273472: step 92, loss 1.34649, acc 0.454545\
1591273473: step 93, loss 1.45029, acc 0.318182\
1591273474: step 94, loss 1.42095, acc 0.363636\
1591273475: step 95, loss 1.15372, acc 0.409091\
1591273476: step 96, loss 1.3967, acc 0.454545\
1591273477: step 97, loss 1.32259, acc 0.318182\
1591273478: step 98, loss 1.29504, acc 0.454545\
1591273479: step 99, loss 1.3979, acc 0.363636\
1591273480: step 100, loss 1.25009, acc 0.5\
++++++++++++++++++dev++++++++++++++1591273489: step 100, loss 1.40676, acc 0.352113\
1591273490: step 101, loss 1.40349, acc 0.409091\
1591273491: step 102, loss 1.79913, acc 0.363636\
1591273492: step 103, loss 1.28056, acc 0.454545\
1591273493: step 104, loss 1.47674, acc 0.318182\
1591273494: step 105, loss 1.15025, acc 0.545455\
1591273495: step 106, loss 1.41012, acc 0.454545\
1591273496: step 107, loss 1.18271, acc 0.409091\
1591273497: step 108, loss 1.48713, acc 0.409091\
1591273498: step 109, loss 1.42393, acc 0.318182\
1591273499: step 110, loss 1.53864, acc 0.318182\
1591273500: step 111, loss 1.30661, acc 0.363636\
1591273501: step 112, loss 1.24973, acc 0.409091\
1591273502: step 113, loss 1.60455, acc 0.181818\
1591273503: step 114, loss 1.17633, acc 0.318182\
1591273504: step 115, loss 1.42652, acc 0.318182\
1591273505: step 116, loss 1.5901, acc 0.227273\
1591273506: step 117, loss 1.15377, acc 0.5\
1591273507: step 118, loss 1.3163, acc 0.409091\
1591273508: step 119, loss 1.34089, acc 0.409091\
1591273509: step 120, loss 1.19004, acc 0.363636\
1591273510: step 121, loss 1.46564, acc 0.318182\
1591273510: step 122, loss 1.51157, acc 0.409091\
1591273511: step 123, loss 1.33739, acc 0.363636\
1591273512: step 124, loss 1.50508, acc 0.272727\
1591273513: step 125, loss 1.23677, acc 0.454545\
1591273514: step 126, loss 1.29159, acc 0.318182\
1591273515: step 127, loss 1.23645, acc 0.454545\
1591273516: step 128, loss 1.33642, acc 0.454545\
1591273517: step 129, loss 1.17716, acc 0.590909\
1591273518: step 130, loss 1.09156, acc 0.409091\
1591273519: step 131, loss 1.14281, acc 0.636364\
1591273520: step 132, loss 1.38545, acc 0.454545\
1591273521: step 133, loss 1.2897, acc 0.545455\
1591273522: step 134, loss 1.17337, acc 0.545455\
1591273523: step 135, loss 1.34151, acc 0.409091\
1591273524: step 136, loss 1.40174, acc 0.454545\
1591273525: step 137, loss 1.23007, acc 0.318182\
1591273526: step 138, loss 1.50637, acc 0.318182\
1591273527: step 139, loss 1.28445, acc 0.363636\
1591273528: step 140, loss 1.10548, acc 0.5\
1591273529: step 141, loss 1.25109, acc 0.5\
1591273530: step 142, loss 0.966726, acc 0.590909\
1591273530: step 143, loss 1.09831, acc 0.5\
1591273531: step 144, loss 1.32461, acc 0.409091\
1591273532: step 145, loss 1.01576, acc 0.545455\
1591273533: step 146, loss 1.45544, acc 0.227273\
1591273534: step 147, loss 1.22901, acc 0.454545\
1591273535: step 148, loss 1.25703, acc 0.363636\
1591273536: step 149, loss 1.17824, acc 0.454545\
1591273537: step 150, loss 1.3806, acc 0.454545\
1591273538: step 151, loss 1.36433, acc 0.454545\
1591273539: step 152, loss 1.17866, acc 0.545455\
1591273540: step 153, loss 1.04935, acc 0.5\
1591273541: step 154, loss 1.21486, acc 0.363636\
1591273542: step 155, loss 1.5779, acc 0.318182\
1591273543: step 156, loss 1.27625, acc 0.409091\
1591273544: step 157, loss 1.2351, acc 0.5\
1591273545: step 158, loss 1.14385, acc 0.454545\
1591273546: step 159, loss 1.11454, acc 0.454545\
1591273547: step 160, loss 1.23891, acc 0.363636\
1591273548: step 161, loss 1.0954, acc 0.5\
1591273549: step 162, loss 1.27148, acc 0.363636\
1591273549: step 163, loss 1.31302, acc 0.5\
1591273550: step 164, loss 1.24505, acc 0.409091\
1591273551: step 165, loss 0.981574, acc 0.5\
1591273552: step 166, loss 1.22209, acc 0.272727\
1591273553: step 167, loss 1.07072, acc 0.590909\
1591273554: step 168, loss 0.914986, acc 0.681818\
1591273555: step 169, loss 1.25505, acc 0.363636\
1591273556: step 170, loss 1.29121, acc 0.363636\
1591273557: step 171, loss 1.30468, acc 0.409091\
1591273558: step 172, loss 1.15046, acc 0.545455\
1591273559: step 173, loss 1.17825, acc 0.545455\
1591273560: step 174, loss 1.22082, acc 0.318182\
1591273561: step 175, loss 1.3511, acc 0.272727\
1591273562: step 176, loss 1.03302, acc 0.636364\
1591273563: step 177, loss 0.913263, acc 0.590909\
1591273564: step 178, loss 1.06189, acc 0.5\
1591273565: step 179, loss 1.03342, acc 0.545455\
1591273566: step 180, loss 1.28638, acc 0.363636\
1591273567: step 181, loss 1.1256, acc 0.409091\
1591273568: step 182, loss 1.10324, acc 0.5\
1591273569: step 183, loss 1.00087, acc 0.5\
1591273570: step 184, loss 1.26818, acc 0.590909\
1591273571: step 185, loss 1.23108, acc 0.454545\
1591273572: step 186, loss 1.03115, acc 0.590909\
1591273573: step 187, loss 1.41647, acc 0.5\
1591273574: step 188, loss 1.26225, acc 0.363636\
1591273575: step 189, loss 0.856568, acc 0.590909\
1591273576: step 190, loss 1.24263, acc 0.5\
1591273577: step 191, loss 1.51839, acc 0.5\
1591273578: step 192, loss 1.13992, acc 0.318182\
1591273579: step 193, loss 1.25207, acc 0.5\
1591273580: step 194, loss 1.43173, acc 0.272727\
1591273581: step 195, loss 1.02438, acc 0.545455\
1591273582: step 196, loss 1.11998, acc 0.5\
1591273583: step 197, loss 1.25307, acc 0.409091\
1591273584: step 198, loss 1.17935, acc 0.5\
1591273585: step 199, loss 1.13642, acc 0.545455\
1591273586: step 200, loss 1.13459, acc 0.454545\
++++++++++++++++++dev++++++++++++++1591273594: step 200, loss 1.1227, acc 0.50503\
1591273595: step 201, loss 1.08793, acc 0.590909\
1591273596: step 202, loss 1.11283, acc 0.5\
1591273597: step 203, loss 1.09312, acc 0.5\
1591273597: step 204, loss 0.856424, acc 0.571429\
current epoch 2\
1591273598: step 205, loss 0.973619, acc 0.5\
1591273599: step 206, loss 1.06342, acc 0.636364\
1591273600: step 207, loss 1.1874, acc 0.5\
1591273601: step 208, loss 1.26367, acc 0.409091\
1591273602: step 209, loss 1.15953, acc 0.318182\
1591273603: step 210, loss 0.878884, acc 0.590909\
1591273604: step 211, loss 0.867703, acc 0.727273\
1591273605: step 212, loss 1.08584, acc 0.5\
1591273606: step 213, loss 0.720573, acc 0.727273\
1591273607: step 214, loss 0.979601, acc 0.636364\
1591273608: step 215, loss 1.04911, acc 0.454545\
1591273609: step 216, loss 1.23426, acc 0.409091\
1591273610: step 217, loss 1.16024, acc 0.590909\
1591273611: step 218, loss 1.47319, acc 0.363636\
1591273612: step 219, loss 1.07372, acc 0.545455\
1591273613: step 220, loss 0.74288, acc 0.727273\
1591273614: step 221, loss 1.09634, acc 0.454545\
1591273615: step 222, loss 0.897332, acc 0.590909\
1591273616: step 223, loss 1.19808, acc 0.636364\
1591273617: step 224, loss 1.11616, acc 0.590909\
1591273618: step 225, loss 1.43622, acc 0.454545\
1591273619: step 226, loss 0.998662, acc 0.636364\
1591273620: step 227, loss 0.782786, acc 0.727273\
1591273621: step 228, loss 1.0022, acc 0.590909\
1591273622: step 229, loss 1.4367, acc 0.409091\
1591273623: step 230, loss 0.977875, acc 0.590909\
1591273624: step 231, loss 1.05567, acc 0.454545\
1591273625: step 232, loss 0.827271, acc 0.681818\
1591273626: step 233, loss 0.863323, acc 0.636364\
1591273627: step 234, loss 0.999657, acc 0.454545\
1591273628: step 235, loss 0.92464, acc 0.545455\
1591273629: step 236, loss 1.44542, acc 0.454545\
1591273630: step 237, loss 0.867954, acc 0.681818\
1591273631: step 238, loss 1.0871, acc 0.545455\
1591273632: step 239, loss 0.935354, acc 0.454545\
1591273633: step 240, loss 0.878697, acc 0.636364\
1591273634: step 241, loss 0.991653, acc 0.454545\
1591273635: step 242, loss 0.876885, acc 0.636364\
1591273636: step 243, loss 0.978974, acc 0.590909\
1591273637: step 244, loss 1.08562, acc 0.590909\
1591273638: step 245, loss 0.921757, acc 0.681818\
1591273639: step 246, loss 0.842127, acc 0.636364\
1591273640: step 247, loss 0.890777, acc 0.545455\
1591273641: step 248, loss 0.995377, acc 0.545455\
1591273642: step 249, loss 1.34809, acc 0.5\
1591273643: step 250, loss 1.24418, acc 0.409091\
1591273644: step 251, loss 1.00403, acc 0.636364\
1591273645: step 252, loss 1.23259, acc 0.409091\
1591273646: step 253, loss 0.961525, acc 0.636364\
1591273647: step 254, loss 0.808669, acc 0.727273\
1591273648: step 255, loss 1.01011, acc 0.545455\
1591273649: step 256, loss 1.03559, acc 0.5\
1591273650: step 257, loss 0.78314, acc 0.772727\
1591273651: step 258, loss 1.1305, acc 0.5\
1591273652: step 259, loss 1.25027, acc 0.5\
1591273653: step 260, loss 0.997851, acc 0.590909\
1591273654: step 261, loss 1.02223, acc 0.590909\
1591273655: step 262, loss 1.21745, acc 0.454545\
1591273656: step 263, loss 0.98243, acc 0.590909\
1591273657: step 264, loss 1.04104, acc 0.545455\
1591273658: step 265, loss 0.918595, acc 0.545455\
1591273659: step 266, loss 0.894947, acc 0.681818\
1591273660: step 267, loss 0.77354, acc 0.590909\
1591273661: step 268, loss 1.18553, acc 0.5\
1591273662: step 269, loss 0.719391, acc 0.727273\
1591273664: step 270, loss 1.04536, acc 0.5\
1591273665: step 271, loss 0.803795, acc 0.636364\
1591273666: step 272, loss 0.927916, acc 0.636364\
1591273667: step 273, loss 1.09114, acc 0.5\
1591273668: step 274, loss 0.980812, acc 0.545455\
1591273669: step 275, loss 0.660366, acc 0.818182\
1591273670: step 276, loss 1.09958, acc 0.454545\
1591273671: step 277, loss 0.736085, acc 0.727273\
1591273672: step 278, loss 1.27656, acc 0.363636\
1591273673: step 279, loss 1.02611, acc 0.636364\
1591273674: step 280, loss 1.13092, acc 0.454545\
1591273675: step 281, loss 0.675644, acc 0.772727\
1591273676: step 282, loss 1.06351, acc 0.545455\
1591273677: step 283, loss 0.621479, acc 0.727273\
1591273678: step 284, loss 1.01724, acc 0.590909\
1591273679: step 285, loss 0.743409, acc 0.590909\
1591273680: step 286, loss 0.857071, acc 0.818182\
1591273681: step 287, loss 0.916938, acc 0.545455\
1591273682: step 288, loss 0.600968, acc 0.772727\
1591273683: step 289, loss 0.72198, acc 0.727273\
1591273684: step 290, loss 0.747125, acc 0.772727\
1591273685: step 291, loss 0.943875, acc 0.545455\
1591273686: step 292, loss 0.732946, acc 0.727273\
1591273687: step 293, loss 0.860188, acc 0.590909\
1591273688: step 294, loss 0.793989, acc 0.636364\
1591273689: step 295, loss 0.710907, acc 0.772727\
1591273690: step 296, loss 0.686016, acc 0.727273\
1591273691: step 297, loss 0.825514, acc 0.545455\
1591273692: step 298, loss 0.826174, acc 0.590909\
1591273693: step 299, loss 0.551226, acc 0.818182\
1591273694: step 300, loss 0.814835, acc 0.772727\
++++++++++++++++++dev++++++++++++++1591273702: step 300, loss 0.817294, acc 0.65996\
1591273703: step 301, loss 0.65545, acc 0.727273\
1591273704: step 302, loss 0.822712, acc 0.590909\
1591273705: step 303, loss 0.791772, acc 0.590909\
1591273706: step 304, loss 0.870064, acc 0.590909\
1591273707: step 305, loss 1.02003, acc 0.5\
1591273708: step 306, loss 0.777828, acc 0.772727\
1591273709: step 307, loss 0.790989, acc 0.590909\
1591273710: step 308, loss 1.07668, acc 0.636364\
1591273711: step 309, loss 0.615621, acc 0.727273\
1591273712: step 310, loss 1.22514, acc 0.409091\
1591273713: step 311, loss 0.689252, acc 0.590909\
1591273714: step 312, loss 0.705822, acc 0.681818\
1591273715: step 313, loss 0.782498, acc 0.681818\
1591273716: step 314, loss 1.07427, acc 0.590909\
1591273717: step 315, loss 0.84432, acc 0.545455\
1591273718: step 316, loss 0.89249, acc 0.636364\
1591273719: step 317, loss 0.878032, acc 0.636364\
1591273720: step 318, loss 0.866612, acc 0.545455\
1591273721: step 319, loss 0.854054, acc 0.545455\
1591273722: step 320, loss 0.63791, acc 0.772727\
1591273723: step 321, loss 0.959016, acc 0.681818\
1591273724: step 322, loss 0.8109, acc 0.636364\
1591273725: step 323, loss 0.868497, acc 0.590909\
1591273726: step 324, loss 0.778475, acc 0.590909\
1591273727: step 325, loss 1.08384, acc 0.545455\
1591273728: step 326, loss 0.683831, acc 0.636364\
1591273729: step 327, loss 0.91505, acc 0.727273\
1591273730: step 328, loss 0.985708, acc 0.5\
1591273731: step 329, loss 0.657834, acc 0.772727\
1591273732: step 330, loss 0.884454, acc 0.590909\
1591273733: step 331, loss 0.766434, acc 0.681818\
1591273734: step 332, loss 0.915914, acc 0.727273\
1591273735: step 333, loss 1.11638, acc 0.545455\
1591273736: step 334, loss 1.00744, acc 0.681818\
1591273737: step 335, loss 0.539361, acc 0.727273\
1591273738: step 336, loss 0.605488, acc 0.772727\
1591273739: step 337, loss 0.567103, acc 0.727273\
1591273740: step 338, loss 0.430536, acc 0.909091\
1591273741: step 339, loss 0.766805, acc 0.772727\
1591273742: step 340, loss 0.865526, acc 0.636364\
1591273743: step 341, loss 0.906749, acc 0.636364\
1591273744: step 342, loss 0.991675, acc 0.590909\
1591273745: step 343, loss 0.875473, acc 0.727273\
1591273746: step 344, loss 0.630948, acc 0.727273\
1591273747: step 345, loss 0.649919, acc 0.818182\
1591273748: step 346, loss 0.677173, acc 0.727273\
1591273749: step 347, loss 0.468367, acc 0.818182\
1591273750: step 348, loss 0.802939, acc 0.636364\
1591273751: step 349, loss 0.39674, acc 0.818182\
1591273752: step 350, loss 0.970747, acc 0.590909\
1591273753: step 351, loss 0.704579, acc 0.681818\
1591273754: step 352, loss 0.72301, acc 0.681818\
1591273755: step 353, loss 0.729211, acc 0.727273\
1591273756: step 354, loss 0.534052, acc 0.818182\
1591273757: step 355, loss 1.06886, acc 0.590909\
1591273758: step 356, loss 0.540479, acc 0.727273\
1591273759: step 357, loss 0.828166, acc 0.636364\
1591273760: step 358, loss 0.932291, acc 0.681818\
1591273761: step 359, loss 1.08004, acc 0.545455\
1591273762: step 360, loss 0.658437, acc 0.772727\
1591273763: step 361, loss 0.863104, acc 0.545455\
1591273764: step 362, loss 0.834644, acc 0.772727\
1591273765: step 363, loss 0.837507, acc 0.681818\
1591273766: step 364, loss 0.504712, acc 0.818182\
1591273767: step 365, loss 0.734735, acc 0.636364\
1591273768: step 366, loss 0.890628, acc 0.772727\
1591273769: step 367, loss 0.569308, acc 0.727273\
1591273770: step 368, loss 1.09057, acc 0.545455\
1591273771: step 369, loss 0.684464, acc 0.681818\
1591273772: step 370, loss 0.922265, acc 0.590909\
1591273773: step 371, loss 0.465881, acc 0.772727\
1591273774: step 372, loss 0.430917, acc 0.863636\
1591273775: step 373, loss 0.73725, acc 0.636364\
1591273776: step 374, loss 0.796093, acc 0.681818\
1591273777: step 375, loss 0.738025, acc 0.727273\
1591273778: step 376, loss 0.738564, acc 0.681818\
1591273779: step 377, loss 0.526314, acc 0.727273\
1591273780: step 378, loss 0.718368, acc 0.727273\
1591273781: step 379, loss 0.68927, acc 0.772727\
1591273782: step 380, loss 1.04269, acc 0.590909\
1591273783: step 381, loss 0.485688, acc 0.818182\
1591273784: step 382, loss 0.884611, acc 0.590909\
1591273785: step 383, loss 0.744336, acc 0.772727\
1591273786: step 384, loss 0.644886, acc 0.681818\
1591273787: step 385, loss 0.714976, acc 0.681818\
1591273788: step 386, loss 0.70821, acc 0.681818\
1591273789: step 387, loss 0.494646, acc 0.818182\
1591273790: step 388, loss 0.67496, acc 0.681818\
1591273791: step 389, loss 1.05394, acc 0.545455\
1591273792: step 390, loss 0.466149, acc 0.727273\
1591273793: step 391, loss 0.781911, acc 0.636364\
1591273794: step 392, loss 0.873062, acc 0.590909\
1591273795: step 393, loss 0.351578, acc 0.954545\
1591273796: step 394, loss 0.899451, acc 0.590909\
1591273797: step 395, loss 0.648829, acc 0.727273\
1591273798: step 396, loss 0.63318, acc 0.772727\
1591273800: step 397, loss 0.829902, acc 0.727273\
1591273801: step 398, loss 1.22537, acc 0.363636\
1591273802: step 399, loss 0.391506, acc 0.863636\
1591273803: step 400, loss 0.711622, acc 0.681818\
++++++++++++++++++dev++++++++++++++1591273810: step 400, loss 0.760837, acc 0.710262\
1591273811: step 401, loss 0.638647, acc 0.727273\
1591273812: step 402, loss 0.940618, acc 0.636364\
1591273813: step 403, loss 1.06391, acc 0.590909\
1591273814: step 404, loss 0.6774, acc 0.636364\
1591273815: step 405, loss 0.442416, acc 0.909091\
1591273816: step 406, loss 0.699405, acc 0.636364\
1591273817: step 407, loss 0.495345, acc 0.863636\
1591273818: step 408, loss 0.487005, acc 0.714286\
current epoch 3\
1591273819: step 409, loss 0.448284, acc 0.818182\
1591273820: step 410, loss 0.678399, acc 0.681818\
1591273821: step 411, loss 0.702957, acc 0.681818\
1591273822: step 412, loss 0.725052, acc 0.636364\
1591273823: step 413, loss 0.522023, acc 0.772727\
1591273824: step 414, loss 0.448941, acc 0.818182\
1591273825: step 415, loss 0.455259, acc 0.818182\
1591273826: step 416, loss 0.463746, acc 0.818182\
1591273827: step 417, loss 0.433357, acc 0.863636\
1591273828: step 418, loss 0.75691, acc 0.545455\
1591273829: step 419, loss 0.442886, acc 0.818182\
1591273830: step 420, loss 0.909602, acc 0.681818\
1591273831: step 421, loss 0.643826, acc 0.772727\
1591273832: step 422, loss 0.675349, acc 0.636364\
1591273833: step 423, loss 0.476253, acc 0.863636\
1591273834: step 424, loss 0.4187, acc 0.818182\
1591273835: step 425, loss 0.594061, acc 0.772727\
1591273836: step 426, loss 0.587249, acc 0.727273\
1591273837: step 427, loss 0.427647, acc 0.909091\
1591273838: step 428, loss 0.55039, acc 0.818182\
1591273839: step 429, loss 0.970829, acc 0.636364\
1591273840: step 430, loss 0.583157, acc 0.772727\
1591273841: step 431, loss 0.342881, acc 0.818182\
1591273842: step 432, loss 0.479599, acc 0.772727\
1591273843: step 433, loss 0.849787, acc 0.590909\
1591273844: step 434, loss 0.558662, acc 0.727273\
1591273845: step 435, loss 0.432973, acc 0.772727\
1591273846: step 436, loss 0.532326, acc 0.727273\
1591273847: step 437, loss 0.570577, acc 0.636364\
1591273848: step 438, loss 0.730619, acc 0.636364\
1591273849: step 439, loss 0.841013, acc 0.636364\
1591273850: step 440, loss 1.01436, acc 0.545455\
1591273851: step 441, loss 0.511144, acc 0.772727\
1591273852: step 442, loss 0.58315, acc 0.818182\
1591273853: step 443, loss 0.434637, acc 0.818182\
1591273854: step 444, loss 0.564767, acc 0.818182\
1591273855: step 445, loss 0.700216, acc 0.818182\
1591273856: step 446, loss 0.583728, acc 0.727273\
1591273857: step 447, loss 0.779921, acc 0.681818\
1591273858: step 448, loss 0.572042, acc 0.818182\
1591273859: step 449, loss 0.940762, acc 0.681818\
1591273860: step 450, loss 0.691674, acc 0.681818\
1591273861: step 451, loss 0.409774, acc 0.818182\
1591273862: step 452, loss 0.496724, acc 0.863636\
1591273863: step 453, loss 0.79768, acc 0.636364\
1591273864: step 454, loss 0.545268, acc 0.772727\
1591273865: step 455, loss 0.542111, acc 0.818182\
1591273866: step 456, loss 0.743653, acc 0.772727\
1591273867: step 457, loss 0.548297, acc 0.818182\
1591273868: step 458, loss 0.402629, acc 0.863636\
1591273869: step 459, loss 0.649288, acc 0.818182\
1591273870: step 460, loss 0.966554, acc 0.636364\
1591273871: step 461, loss 0.330846, acc 0.818182\
1591273872: step 462, loss 0.576815, acc 0.818182\
1591273872: step 463, loss 0.723067, acc 0.727273\
1591273873: step 464, loss 0.300463, acc 0.954545\
1591273874: step 465, loss 0.647561, acc 0.772727\
1591273875: step 466, loss 1.02286, acc 0.636364\
1591273876: step 467, loss 0.643215, acc 0.772727\
1591273877: step 468, loss 0.459732, acc 0.909091\
1591273878: step 469, loss 0.34673, acc 0.863636\
1591273879: step 470, loss 0.539816, acc 0.772727\
1591273880: step 471, loss 0.475793, acc 0.727273\
1591273881: step 472, loss 0.550646, acc 0.727273\
1591273882: step 473, loss 0.455432, acc 0.863636\
1591273883: step 474, loss 0.594991, acc 0.681818\
1591273884: step 475, loss 0.470264, acc 0.863636\
1591273885: step 476, loss 0.230402, acc 0.954545\
1591273886: step 477, loss 0.720384, acc 0.818182\
1591273887: step 478, loss 0.562928, acc 0.818182\
1591273888: step 479, loss 0.199785, acc 0.954545\
1591273889: step 480, loss 0.87409, acc 0.590909\
1591273890: step 481, loss 0.48558, acc 0.727273\
1591273891: step 482, loss 0.617177, acc 0.863636\
1591273892: step 483, loss 0.483315, acc 0.818182\
1591273893: step 484, loss 0.896232, acc 0.636364\
1591273894: step 485, loss 0.339164, acc 0.909091\
1591273895: step 486, loss 0.471332, acc 0.818182\
1591273896: step 487, loss 0.437412, acc 0.818182\
1591273897: step 488, loss 0.72325, acc 0.681818\
1591273898: step 489, loss 0.705593, acc 0.772727\
1591273899: step 490, loss 0.349919, acc 0.954545\
1591273901: step 491, loss 0.2622, acc 0.909091\
1591273902: step 492, loss 0.24008, acc 0.909091\
1591273902: step 493, loss 0.442764, acc 0.818182\
1591273903: step 494, loss 0.362259, acc 0.772727\
1591273904: step 495, loss 0.408189, acc 0.954545\
1591273905: step 496, loss 0.597541, acc 0.818182\
1591273906: step 497, loss 0.371487, acc 0.818182\
1591273907: step 498, loss 0.590185, acc 0.636364\
1591273908: step 499, loss 0.520816, acc 0.909091\
1591273909: step 500, loss 0.431588, acc 0.818182\
++++++++++++++++++dev++++++++++++++1591273917: step 500, loss 0.737854, acc 0.726358\
1591273917: step 501, loss 0.577015, acc 0.772727\
1591273918: step 502, loss 0.466086, acc 0.727273\
1591273919: step 503, loss 0.647647, acc 0.681818\
1591273920: step 504, loss 0.611728, acc 0.909091\
1591273921: step 505, loss 0.490901, acc 0.818182\
1591273922: step 506, loss 0.290668, acc 0.954545\
1591273923: step 507, loss 0.315346, acc 0.909091\
1591273924: step 508, loss 0.423476, acc 0.863636\
1591273925: step 509, loss 0.932021, acc 0.681818\
1591273926: step 510, loss 0.504147, acc 0.818182\
1591273927: step 511, loss 0.379899, acc 0.818182\
1591273928: step 512, loss 0.591893, acc 0.863636\
1591273929: step 513, loss 0.400189, acc 0.863636\
1591273930: step 514, loss 0.546755, acc 0.772727\
1591273931: step 515, loss 0.375359, acc 0.818182\
1591273932: step 516, loss 0.21192, acc 0.954545\
1591273933: step 517, loss 0.631786, acc 0.636364\
1591273934: step 518, loss 0.913321, acc 0.545455\
1591273935: step 519, loss 0.413999, acc 0.818182\
1591273935: step 520, loss 0.573089, acc 0.772727\
1591273936: step 521, loss 0.773431, acc 0.681818\
1591273937: step 522, loss 0.549841, acc 0.772727\
1591273938: step 523, loss 0.555049, acc 0.772727\
1591273939: step 524, loss 0.352139, acc 0.863636\
1591273940: step 525, loss 0.309245, acc 0.863636\
1591273941: step 526, loss 0.444095, acc 0.818182\
1591273942: step 527, loss 0.811645, acc 0.681818\
1591273943: step 528, loss 0.694924, acc 0.772727\
1591273944: step 529, loss 0.79401, acc 0.772727\
1591273945: step 530, loss 0.704561, acc 0.772727\
1591273946: step 531, loss 0.405878, acc 0.863636\
1591273947: step 532, loss 0.621614, acc 0.681818\
1591273948: step 533, loss 0.286758, acc 0.818182\
1591273949: step 534, loss 0.435406, acc 0.818182\
1591273950: step 535, loss 0.48538, acc 0.772727\
1591273951: step 536, loss 0.35222, acc 0.863636\
1591273952: step 537, loss 0.895589, acc 0.681818\
1591273953: step 538, loss 0.405321, acc 0.863636\
1591273954: step 539, loss 0.425999, acc 0.818182\
1591273954: step 540, loss 0.192655, acc 0.954545\
1591273955: step 541, loss 0.260073, acc 0.909091\
1591273956: step 542, loss 0.20813, acc 0.909091\
1591273957: step 543, loss 0.582106, acc 0.727273\
1591273958: step 544, loss 0.594614, acc 0.681818\
1591273959: step 545, loss 0.511956, acc 0.727273\
1591273960: step 546, loss 0.276275, acc 0.954545\
1591273961: step 547, loss 0.532517, acc 0.772727\
1591273962: step 548, loss 0.447605, acc 0.818182\
1591273963: step 549, loss 0.417981, acc 0.772727\
1591273964: step 550, loss 0.490636, acc 0.772727\
1591273965: step 551, loss 0.441408, acc 0.818182\
1591273966: step 552, loss 0.547309, acc 0.818182\
1591273967: step 553, loss 0.287469, acc 0.863636\
1591273968: step 554, loss 0.652885, acc 0.818182\
1591273969: step 555, loss 0.552542, acc 0.727273\
1591273970: step 556, loss 0.997792, acc 0.681818\
1591273971: step 557, loss 0.48171, acc 0.818182\
1591273972: step 558, loss 0.264305, acc 0.909091\
1591273973: step 559, loss 0.710817, acc 0.772727\
1591273974: step 560, loss 0.265615, acc 0.954545\
1591273975: step 561, loss 0.576692, acc 0.772727\
1591273976: step 562, loss 0.294154, acc 0.863636\
1591273977: step 563, loss 0.71225, acc 0.681818\
1591273978: step 564, loss 0.271334, acc 0.909091\
1591273979: step 565, loss 0.132963, acc 0.954545\
1591273980: step 566, loss 0.236193, acc 0.909091\
1591273981: step 567, loss 0.442436, acc 0.727273\
1591273982: step 568, loss 0.115656, acc 1\
1591273983: step 569, loss 0.776368, acc 0.681818\
1591273984: step 570, loss 0.446748, acc 0.772727\
1591273985: step 571, loss 0.189307, acc 0.954545\
1591273986: step 572, loss 0.736706, acc 0.772727\
1591273987: step 573, loss 0.47873, acc 0.727273\
1591273987: step 574, loss 0.306296, acc 0.818182\
1591273988: step 575, loss 0.241125, acc 0.909091\
1591273989: step 576, loss 0.224642, acc 0.909091\
1591273990: step 577, loss 0.463222, acc 0.818182\
1591273991: step 578, loss 0.241396, acc 0.909091\
1591273992: step 579, loss 0.317343, acc 0.909091\
1591273993: step 580, loss 0.635141, acc 0.727273\
1591273994: step 581, loss 0.149541, acc 0.909091\
1591273995: step 582, loss 0.158877, acc 0.954545\
1591273996: step 583, loss 0.622179, acc 0.772727\
1591273997: step 584, loss 0.539099, acc 0.727273\
1591273998: step 585, loss 0.678634, acc 0.818182\
1591273999: step 586, loss 0.563204, acc 0.818182\
1591274000: step 587, loss 0.644093, acc 0.818182\
1591274001: step 588, loss 0.445248, acc 0.863636\
1591274002: step 589, loss 0.491032, acc 0.863636\
1591274003: step 590, loss 0.375826, acc 0.863636\
1591274004: step 591, loss 0.390093, acc 0.818182\
1591274005: step 592, loss 0.428726, acc 0.818182\
1591274006: step 593, loss 0.810006, acc 0.681818\
1591274007: step 594, loss 0.278204, acc 0.863636\
1591274008: step 595, loss 0.448807, acc 0.909091\
1591274009: step 596, loss 0.481537, acc 0.863636\
1591274010: step 597, loss 0.188885, acc 1\
1591274011: step 598, loss 0.669596, acc 0.681818\
1591274012: step 599, loss 0.420787, acc 0.863636\
1591274013: step 600, loss 0.418213, acc 0.863636\
++++++++++++++++++dev++++++++++++++1591274021: step 600, loss 0.661909, acc 0.750503\
1591274022: step 601, loss 0.416425, acc 0.818182\
1591274023: step 602, loss 0.607383, acc 0.863636\
1591274024: step 603, loss 0.182518, acc 0.909091\
1591274025: step 604, loss 0.692589, acc 0.727273\
1591274026: step 605, loss 0.404601, acc 0.818182\
1591274027: step 606, loss 0.50043, acc 0.818182\
1591274028: step 607, loss 0.673727, acc 0.727273\
1591274029: step 608, loss 0.395791, acc 0.772727\
1591274030: step 609, loss 0.288222, acc 0.954545\
1591274031: step 610, loss 0.507115, acc 0.727273\
1591274032: step 611, loss 0.351349, acc 0.909091\
1591274032: step 612, loss 0.111502, acc 1\
current epoch 4\
1591274033: step 613, loss 0.531174, acc 0.818182\
1591274034: step 614, loss 0.421863, acc 0.772727\
1591274035: step 615, loss 0.418523, acc 0.863636\
1591274036: step 616, loss 0.553814, acc 0.636364\
1591274037: step 617, loss 0.382964, acc 0.863636\
1591274038: step 618, loss 0.309027, acc 0.863636\
1591274039: step 619, loss 0.477169, acc 0.909091\
1591274040: step 620, loss 0.166935, acc 0.954545\
1591274041: step 621, loss 0.382388, acc 0.818182\
1591274042: step 622, loss 0.455249, acc 0.818182\
1591274043: step 623, loss 0.268881, acc 0.909091\
1591274044: step 624, loss 0.458457, acc 0.863636\
1591274045: step 625, loss 0.334705, acc 0.772727\
1591274046: step 626, loss 0.357468, acc 0.863636\
1591274047: step 627, loss 0.301122, acc 0.909091\
1591274049: step 628, loss 0.255406, acc 0.863636\
1591274050: step 629, loss 0.196715, acc 0.954545\
1591274051: step 630, loss 0.326682, acc 0.863636\
1591274052: step 631, loss 0.354759, acc 0.863636\
1591274053: step 632, loss 0.377593, acc 0.863636\
1591274054: step 633, loss 0.341618, acc 0.863636\
1591274055: step 634, loss 0.392188, acc 0.909091\
1591274056: step 635, loss 0.172116, acc 0.909091\
1591274057: step 636, loss 0.212349, acc 0.909091\
1591274058: step 637, loss 0.622518, acc 0.772727\
1591274059: step 638, loss 0.231883, acc 0.909091\
1591274060: step 639, loss 0.12713, acc 0.954545\
1591274061: step 640, loss 0.350712, acc 0.818182\
1591274062: step 641, loss 0.188855, acc 0.954545\
1591274063: step 642, loss 0.228648, acc 0.909091\
1591274064: step 643, loss 0.288859, acc 0.863636\
1591274065: step 644, loss 0.54988, acc 0.818182\
1591274066: step 645, loss 0.450471, acc 0.818182\
1591274067: step 646, loss 0.365109, acc 0.909091\
1591274068: step 647, loss 0.19283, acc 0.909091\
1591274069: step 648, loss 0.435686, acc 0.863636\
1591274070: step 649, loss 0.420506, acc 0.863636\
1591274070: step 650, loss 0.21292, acc 0.909091\
1591274071: step 651, loss 0.309459, acc 0.863636\
1591274072: step 652, loss 0.449897, acc 0.772727\
1591274073: step 653, loss 0.299677, acc 0.954545\
1591274074: step 654, loss 0.319778, acc 0.909091\
1591274075: step 655, loss 0.311865, acc 0.863636\
1591274076: step 656, loss 0.218989, acc 0.863636\
1591274077: step 657, loss 0.339373, acc 0.863636\
1591274078: step 658, loss 0.336818, acc 0.863636\
1591274079: step 659, loss 0.375069, acc 0.909091\
1591274080: step 660, loss 0.120907, acc 1\
1591274081: step 661, loss 0.317306, acc 0.863636\
1591274082: step 662, loss 0.277123, acc 0.818182\
1591274083: step 663, loss 0.310753, acc 0.863636\
1591274084: step 664, loss 0.355326, acc 0.909091\
1591274085: step 665, loss 0.225833, acc 0.863636\
1591274086: step 666, loss 0.457606, acc 0.863636\
1591274087: step 667, loss 0.443921, acc 0.909091\
1591274088: step 668, loss 0.308666, acc 0.863636\
1591274089: step 669, loss 0.354018, acc 0.909091\
1591274089: step 670, loss 0.403687, acc 0.772727\
1591274090: step 671, loss 0.321426, acc 0.909091\
1591274091: step 672, loss 0.2213, acc 0.954545\
1591274092: step 673, loss 0.187415, acc 0.863636\
1591274093: step 674, loss 0.184963, acc 0.909091\
1591274094: step 675, loss 0.217816, acc 0.909091\
1591274095: step 676, loss 0.317545, acc 0.863636\
1591274096: step 677, loss 0.190463, acc 0.909091\
1591274097: step 678, loss 0.354471, acc 0.863636\
1591274098: step 679, loss 0.388781, acc 0.863636\
1591274099: step 680, loss 0.194957, acc 0.954545\
1591274100: step 681, loss 0.740501, acc 0.727273\
1591274101: step 682, loss 0.371117, acc 0.909091\
1591274102: step 683, loss 0.351558, acc 0.909091\
1591274103: step 684, loss 0.181334, acc 0.954545\
1591274104: step 685, loss 0.223698, acc 0.909091\
1591274105: step 686, loss 0.402062, acc 0.909091\
1591274106: step 687, loss 0.360637, acc 0.772727\
1591274107: step 688, loss 0.93755, acc 0.681818\
1591274108: step 689, loss 0.20664, acc 0.954545\
1591274109: step 690, loss 0.26383, acc 0.909091\
1591274110: step 691, loss 0.138377, acc 0.954545\
1591274111: step 692, loss 0.592775, acc 0.818182\
1591274111: step 693, loss 0.201914, acc 0.909091\
1591274112: step 694, loss 0.26232, acc 0.909091\
1591274113: step 695, loss 0.21149, acc 0.909091\
1591274114: step 696, loss 0.136455, acc 0.909091\
1591274115: step 697, loss 0.318526, acc 0.863636\
1591274116: step 698, loss 0.40019, acc 0.818182\
1591274117: step 699, loss 0.237487, acc 0.909091\
1591274118: step 700, loss 0.385135, acc 0.818182\
++++++++++++++++++dev++++++++++++++1591274126: step 700, loss 0.703087, acc 0.754527\
1591274127: step 701, loss 0.316168, acc 0.954545\
1591274128: step 702, loss 0.218705, acc 0.863636\
1591274128: step 703, loss 0.029296, acc 1\
1591274129: step 704, loss 0.0658348, acc 0.954545\
1591274130: step 705, loss 0.228667, acc 0.909091\
1591274131: step 706, loss 0.372069, acc 0.818182\
1591274132: step 707, loss 0.282781, acc 0.863636\
1591274133: step 708, loss 0.214023, acc 0.954545\
1591274134: step 709, loss 0.364905, acc 0.863636\
1591274135: step 710, loss 0.417332, acc 0.818182\
1591274136: step 711, loss 0.209665, acc 0.909091\
1591274137: step 712, loss 0.268156, acc 0.954545\
1591274138: step 713, loss 0.29277, acc 0.818182\
1591274139: step 714, loss 0.183693, acc 0.909091\
1591274140: step 715, loss 0.364564, acc 0.818182\
1591274141: step 716, loss 0.235112, acc 0.954545\
1591274142: step 717, loss 0.284366, acc 0.863636\
1591274143: step 718, loss 0.144308, acc 0.954545\
1591274144: step 719, loss 0.365392, acc 0.818182\
1591274145: step 720, loss 0.262754, acc 0.909091\
1591274146: step 721, loss 0.275906, acc 0.863636\
1591274147: step 722, loss 0.358563, acc 0.909091\
1591274148: step 723, loss 0.2454, acc 0.863636\
1591274148: step 724, loss 0.165531, acc 0.954545\
1591274149: step 725, loss 0.354661, acc 0.909091\
1591274150: step 726, loss 0.104374, acc 0.954545\
1591274151: step 727, loss 0.183452, acc 0.863636\
1591274152: step 728, loss 0.145669, acc 0.954545\
1591274153: step 729, loss 0.246121, acc 0.909091\
1591274154: step 730, loss 0.503949, acc 0.772727\
1591274155: step 731, loss 0.360927, acc 0.818182\
1591274156: step 732, loss 0.650533, acc 0.727273\
1591274157: step 733, loss 0.252466, acc 0.863636\
1591274158: step 734, loss 0.311469, acc 0.954545\
1591274159: step 735, loss 0.132841, acc 1\
1591274160: step 736, loss 0.394373, acc 0.863636\
1591274161: step 737, loss 0.0425178, acc 1\
1591274162: step 738, loss 0.288662, acc 0.909091\
1591274163: step 739, loss 0.323779, acc 0.863636\
1591274164: step 740, loss 0.195778, acc 0.909091\
1591274165: step 741, loss 0.380394, acc 0.863636\
1591274166: step 742, loss 0.251895, acc 0.863636\
1591274167: step 743, loss 0.204806, acc 0.954545\
1591274168: step 744, loss 0.320318, acc 0.909091\
1591274168: step 745, loss 0.134626, acc 0.909091\
1591274169: step 746, loss 0.262671, acc 0.954545\
1591274170: step 747, loss 0.616619, acc 0.772727\
1591274171: step 748, loss 0.378305, acc 0.818182\
1591274172: step 749, loss 0.275774, acc 0.863636\
1591274173: step 750, loss 0.432897, acc 0.863636\
1591274174: step 751, loss 0.154963, acc 0.909091\
1591274175: step 752, loss 0.185547, acc 0.954545\
1591274176: step 753, loss 0.140742, acc 0.954545\
1591274177: step 754, loss 0.314966, acc 0.909091\
1591274178: step 755, loss 0.250154, acc 0.954545\
1591274179: step 756, loss 0.307156, acc 0.863636\
1591274180: step 757, loss 0.264035, acc 0.909091\
1591274181: step 758, loss 0.692671, acc 0.772727\
1591274182: step 759, loss 0.164303, acc 0.863636\
1591274183: step 760, loss 0.653243, acc 0.818182\
1591274184: step 761, loss 0.263293, acc 0.863636\
1591274185: step 762, loss 0.10222, acc 0.954545\
1591274186: step 763, loss 0.293278, acc 0.909091\
1591274187: step 764, loss 0.0825202, acc 1\
1591274188: step 765, loss 0.466428, acc 0.818182\
1591274188: step 766, loss 0.231731, acc 0.909091\
1591274189: step 767, loss 0.404694, acc 0.818182\
1591274190: step 768, loss 0.438393, acc 0.909091\
1591274191: step 769, loss 0.377536, acc 0.863636\
1591274192: step 770, loss 0.156834, acc 0.954545\
1591274193: step 771, loss 0.0988033, acc 1\
1591274194: step 772, loss 0.0936438, acc 1\
1591274195: step 773, loss 0.125158, acc 1\
1591274196: step 774, loss 0.169494, acc 0.954545\
1591274197: step 775, loss 0.137835, acc 0.954545\
1591274198: step 776, loss 0.363107, acc 0.863636\
1591274199: step 777, loss 0.240433, acc 0.909091\
1591274200: step 778, loss 0.0976316, acc 0.954545\
1591274201: step 779, loss 0.0942168, acc 1\
1591274202: step 780, loss 0.134451, acc 0.954545\
1591274203: step 781, loss 0.112965, acc 0.954545\
1591274204: step 782, loss 0.112201, acc 1\
1591274205: step 783, loss 0.0939662, acc 1\
1591274206: step 784, loss 0.383754, acc 0.772727\
1591274207: step 785, loss 0.223357, acc 0.909091\
1591274208: step 786, loss 0.0342426, acc 1\
1591274208: step 787, loss 0.277862, acc 0.909091\
1591274209: step 788, loss 0.332554, acc 0.863636\
1591274210: step 789, loss 0.22114, acc 0.909091\
1591274211: step 790, loss 0.268301, acc 0.863636\
1591274212: step 791, loss 0.424769, acc 0.909091\
1591274213: step 792, loss 0.406781, acc 0.863636\
1591274214: step 793, loss 0.166564, acc 0.863636\
1591274215: step 794, loss 0.485257, acc 0.863636\
1591274216: step 795, loss 0.150771, acc 0.954545\
1591274217: step 796, loss 0.123569, acc 0.954545\
1591274218: step 797, loss 0.719732, acc 0.772727\
1591274219: step 798, loss 0.19471, acc 0.909091\
1591274220: step 799, loss 0.45428, acc 0.818182\
1591274221: step 800, loss 0.417743, acc 0.818182\
++++++++++++++++++dev++++++++++++++1591274228: step 800, loss 0.715304, acc 0.770624\
1591274229: step 801, loss 0.100093, acc 0.954545\
1591274230: step 802, loss 0.33132, acc 0.863636\
1591274231: step 803, loss 0.126266, acc 0.954545\
1591274232: step 804, loss 0.0866507, acc 1\
1591274233: step 805, loss 0.160921, acc 0.954545\
1591274234: step 806, loss 0.533639, acc 0.772727\
1591274235: step 807, loss 0.293884, acc 0.863636\
1591274236: step 808, loss 0.281907, acc 0.909091\
1591274237: step 809, loss 0.291633, acc 0.954545\
1591274238: step 810, loss 0.370776, acc 0.863636\
1591274239: step 811, loss 0.348519, acc 0.863636\
1591274240: step 812, loss 0.17941, acc 0.909091\
1591274241: step 813, loss 0.194992, acc 0.954545\
1591274242: step 814, loss 0.484984, acc 0.818182\
1591274242: step 815, loss 0.114051, acc 0.954545\
1591274243: step 816, loss 0.0580267, acc 1\
current epoch 5\
1591274244: step 817, loss 0.279757, acc 0.909091\
1591274245: step 818, loss 0.178324, acc 1\
1591274246: step 819, loss 0.419218, acc 0.909091\
1591274247: step 820, loss 0.73484, acc 0.818182\
1591274248: step 821, loss 0.0523699, acc 1\
1591274249: step 822, loss 0.11548, acc 0.954545\
1591274250: step 823, loss 0.203759, acc 0.909091\
1591274251: step 824, loss 0.209417, acc 0.954545\
1591274252: step 825, loss 0.192241, acc 0.909091\
1591274253: step 826, loss 0.238817, acc 0.909091\
1591274254: step 827, loss 0.124283, acc 0.954545\
1591274255: step 828, loss 0.372231, acc 0.772727\
1591274256: step 829, loss 0.240815, acc 0.954545\
1591274257: step 830, loss 0.243895, acc 0.909091\
1591274257: step 831, loss 0.15639, acc 0.909091\
1591274258: step 832, loss 0.0507072, acc 1\
1591274259: step 833, loss 0.161073, acc 0.954545\
1591274260: step 834, loss 0.161438, acc 0.954545\
1591274261: step 835, loss 0.0926366, acc 0.954545\
1591274262: step 836, loss 0.085873, acc 1\
1591274263: step 837, loss 0.0541767, acc 1\
1591274264: step 838, loss 0.153023, acc 0.954545\
1591274265: step 839, loss 0.176439, acc 0.863636\
1591274266: step 840, loss 0.0950637, acc 0.954545\
1591274267: step 841, loss 0.131183, acc 0.954545\
1591274268: step 842, loss 0.0866931, acc 0.954545\
1591274269: step 843, loss 0.167228, acc 0.909091\
1591274270: step 844, loss 0.115435, acc 0.909091\
1591274271: step 845, loss 0.151266, acc 0.954545\
1591274272: step 846, loss 0.140215, acc 0.909091\
1591274273: step 847, loss 0.0262492, acc 1\
1591274274: step 848, loss 0.251329, acc 0.863636\
1591274275: step 849, loss 0.315131, acc 0.909091\
1591274276: step 850, loss 0.269977, acc 0.909091\
1591274277: step 851, loss 0.052149, acc 1\
1591274277: step 852, loss 0.180255, acc 0.954545\
1591274278: step 853, loss 0.450118, acc 0.818182\
1591274279: step 854, loss 0.0448974, acc 1\
1591274280: step 855, loss 0.0976149, acc 1\
1591274281: step 856, loss 0.404661, acc 0.909091\
1591274282: step 857, loss 0.446689, acc 0.909091\
1591274283: step 858, loss 0.184095, acc 0.954545\
1591274284: step 859, loss 0.165961, acc 0.909091\
1591274285: step 860, loss 0.0977302, acc 0.954545\
1591274286: step 861, loss 0.21218, acc 0.909091\
1591274287: step 862, loss 0.181413, acc 0.954545\
1591274288: step 863, loss 0.600164, acc 0.818182\
1591274289: step 864, loss 0.0987857, acc 1\
1591274290: step 865, loss 0.33527, acc 0.909091\
1591274291: step 866, loss 0.120537, acc 0.954545\
1591274292: step 867, loss 0.172364, acc 0.909091\
1591274293: step 868, loss 0.198483, acc 0.909091\
1591274294: step 869, loss 0.0978452, acc 0.954545\
1591274295: step 870, loss 0.166481, acc 0.954545\
1591274296: step 871, loss 0.173756, acc 0.954545\
1591274296: step 872, loss 0.0409502, acc 1\
1591274297: step 873, loss 0.293374, acc 0.909091\
1591274298: step 874, loss 0.329599, acc 0.909091\
1591274299: step 875, loss 0.292166, acc 0.909091\
1591274300: step 876, loss 0.155528, acc 0.954545\
1591274301: step 877, loss 0.0604776, acc 1\
1591274302: step 878, loss 0.159561, acc 0.954545\
1591274303: step 879, loss 0.219201, acc 0.909091\
1591274304: step 880, loss 0.23919, acc 0.909091\
1591274305: step 881, loss 0.16001, acc 0.954545\
1591274306: step 882, loss 0.314357, acc 0.863636\
1591274307: step 883, loss 0.101222, acc 0.954545\
1591274308: step 884, loss 0.273785, acc 0.909091\
1591274309: step 885, loss 0.380317, acc 0.909091\
1591274310: step 886, loss 0.376753, acc 0.909091\
1591274311: step 887, loss 0.175173, acc 0.954545\
1591274312: step 888, loss 0.121506, acc 0.954545\
1591274313: step 889, loss 0.255238, acc 0.863636\
1591274314: step 890, loss 0.259075, acc 0.954545\
1591274315: step 891, loss 0.223514, acc 0.863636\
1591274316: step 892, loss 0.207979, acc 0.954545\
1591274317: step 893, loss 0.0960025, acc 0.954545\
1591274318: step 894, loss 0.387625, acc 0.863636\
1591274319: step 895, loss 0.121031, acc 0.954545\
1591274320: step 896, loss 0.187046, acc 0.909091\
1591274321: step 897, loss 0.0359467, acc 1\
1591274322: step 898, loss 0.100597, acc 1\
1591274322: step 899, loss 0.128701, acc 0.954545\
1591274323: step 900, loss 0.138619, acc 0.954545\
++++++++++++++++++dev++++++++++++++1591274331: step 900, loss 0.790713, acc 0.774648\
1591274332: step 901, loss 0.378368, acc 0.818182\
1591274333: step 902, loss 0.325661, acc 0.818182\
1591274334: step 903, loss 0.119909, acc 0.909091\
1591274335: step 904, loss 0.249738, acc 0.954545\
1591274336: step 905, loss 0.173282, acc 0.909091\
1591274337: step 906, loss 0.380634, acc 0.863636\
1591274338: step 907, loss 0.18392, acc 0.954545\
1591274339: step 908, loss 0.0149894, acc 1\
1591274340: step 909, loss 0.140077, acc 0.954545\
1591274341: step 910, loss 0.314406, acc 0.909091\
1591274342: step 911, loss 0.066026, acc 1\
1591274343: step 912, loss 0.131623, acc 0.954545\
1591274344: step 913, loss 0.132354, acc 0.954545\
1591274345: step 914, loss 0.21678, acc 0.863636\
1591274345: step 915, loss 0.181579, acc 0.954545\
1591274346: step 916, loss 0.191932, acc 0.954545\
1591274347: step 917, loss 0.0650471, acc 1\
1591274348: step 918, loss 0.142554, acc 0.954545\
1591274349: step 919, loss 0.172652, acc 0.909091\
1591274350: step 920, loss 0.294274, acc 0.909091\
1591274351: step 921, loss 0.347222, acc 0.909091\
1591274352: step 922, loss 0.368273, acc 0.909091\
1591274353: step 923, loss 0.126399, acc 0.909091\
1591274354: step 924, loss 0.106498, acc 0.954545\
1591274355: step 925, loss 0.064927, acc 1\
1591274356: step 926, loss 0.213594, acc 0.909091\
1591274357: step 927, loss 0.104631, acc 0.954545\
1591274358: step 928, loss 0.208493, acc 0.954545\
1591274359: step 929, loss 0.213525, acc 0.909091\
1591274360: step 930, loss 0.184489, acc 0.909091\
1591274361: step 931, loss 0.139788, acc 0.954545\
1591274362: step 932, loss 0.227639, acc 0.863636\
1591274363: step 933, loss 0.289188, acc 0.909091\
1591274364: step 934, loss 0.108113, acc 0.954545\
1591274365: step 935, loss 0.39623, acc 0.863636\
1591274366: step 936, loss 0.133613, acc 0.954545\
1591274366: step 937, loss 0.106464, acc 0.954545\
1591274367: step 938, loss 0.321418, acc 0.909091\
1591274368: step 939, loss 0.118348, acc 0.954545\
1591274369: step 940, loss 0.208322, acc 0.863636\
1591274370: step 941, loss 0.0693948, acc 0.954545\
1591274371: step 942, loss 0.414597, acc 0.909091\
1591274372: step 943, loss 0.143857, acc 0.909091\
1591274373: step 944, loss 0.181282, acc 0.954545\
1591274374: step 945, loss 0.232924, acc 0.863636\
1591274375: step 946, loss 0.0529343, acc 1\
1591274376: step 947, loss 0.0536721, acc 1\
1591274377: step 948, loss 0.1945, acc 0.909091\
1591274378: step 949, loss 0.122114, acc 0.954545\
1591274379: step 950, loss 0.0169166, acc 1\
1591274380: step 951, loss 0.317786, acc 0.863636\
1591274381: step 952, loss 0.1398, acc 0.954545\
1591274382: step 953, loss 0.252054, acc 0.863636\
1591274383: step 954, loss 0.219445, acc 0.909091\
1591274384: step 955, loss 0.0874017, acc 0.954545\
1591274385: step 956, loss 0.100914, acc 1\
1591274386: step 957, loss 0.0689531, acc 1\
1591274387: step 958, loss 0.0733081, acc 0.954545\
1591274387: step 959, loss 0.0422599, acc 1\
1591274388: step 960, loss 0.313435, acc 0.909091\
1591274389: step 961, loss 0.143687, acc 0.909091\
1591274390: step 962, loss 0.398682, acc 0.909091\
1591274391: step 963, loss 0.120561, acc 0.909091\
1591274392: step 964, loss 0.430308, acc 0.863636\
1591274393: step 965, loss 0.107996, acc 0.954545\
1591274394: step 966, loss 0.0696539, acc 0.954545\
1591274395: step 967, loss 0.0905492, acc 0.954545\
1591274396: step 968, loss 0.0280321, acc 1\
1591274397: step 969, loss 0.160428, acc 0.954545\
1591274398: step 970, loss 0.0635743, acc 1\
1591274399: step 971, loss 0.273253, acc 0.863636\
1591274400: step 972, loss 0.401298, acc 0.954545\
1591274401: step 973, loss 0.175146, acc 0.909091\
1591274402: step 974, loss 0.106088, acc 0.954545\
1591274403: step 975, loss 0.0909662, acc 0.954545\
1591274404: step 976, loss 0.0883551, acc 0.954545\
1591274405: step 977, loss 0.077619, acc 0.954545\
1591274406: step 978, loss 0.0360041, acc 1\
1591274407: step 979, loss 0.0319122, acc 1\
1591274408: step 980, loss 0.215259, acc 0.909091\
1591274409: step 981, loss 0.121785, acc 0.954545\
1591274409: step 982, loss 0.114406, acc 0.954545\
1591274410: step 983, loss 0.158109, acc 0.909091\
1591274411: step 984, loss 0.0633687, acc 0.954545\
1591274412: step 985, loss 0.0237086, acc 1\
1591274413: step 986, loss 0.0751202, acc 0.954545\
1591274414: step 987, loss 0.035152, acc 1\
1591274415: step 988, loss 0.292433, acc 0.909091\
1591274416: step 989, loss 0.0413174, acc 1\
1591274417: step 990, loss 0.0166033, acc 1\
1591274418: step 991, loss 0.184178, acc 0.954545\
1591274419: step 992, loss 0.124924, acc 0.954545\
1591274420: step 993, loss 0.0277857, acc 1\
1591274421: step 994, loss 0.262408, acc 0.863636\
1591274422: step 995, loss 0.255843, acc 0.818182\
1591274423: step 996, loss 0.184226, acc 0.909091\
1591274424: step 997, loss 0.0273741, acc 1\
1591274425: step 998, loss 0.428276, acc 0.863636\
1591274426: step 999, loss 0.0158561, acc 1\
1591274427: step 1000, loss 0.267471, acc 0.909091\
++++++++++++++++++dev++++++++++++++1591274434: step 1000, loss 0.809328, acc 0.78672\
1591274435: step 1001, loss 0.24971, acc 0.909091\
1591274436: step 1002, loss 0.0946595, acc 1\
1591274437: step 1003, loss 0.253496, acc 0.954545\
1591274438: step 1004, loss 0.16797, acc 0.909091\
1591274439: step 1005, loss 0.0598322, acc 1\
1591274440: step 1006, loss 0.188474, acc 0.909091\
1591274441: step 1007, loss 0.043483, acc 1\
1591274442: step 1008, loss 0.00849706, acc 1\
1591274443: step 1009, loss 0.0980339, acc 0.954545\
1591274444: step 1010, loss 0.0765613, acc 1\
1591274445: step 1011, loss 0.184832, acc 0.909091\
1591274446: step 1012, loss 0.0573648, acc 1\
1591274447: step 1013, loss 0.0530291, acc 1\
1591274448: step 1014, loss 0.130515, acc 0.954545\
1591274449: step 1015, loss 0.445733, acc 0.863636\
1591274450: step 1016, loss 0.181744, acc 0.909091\
1591274451: step 1017, loss 0.180047, acc 0.954545\
1591274452: step 1018, loss 0.239133, acc 0.863636\
1591274453: step 1019, loss 0.300883, acc 0.909091\
1591274453: step 1020, loss 0.102534, acc 0.928571}