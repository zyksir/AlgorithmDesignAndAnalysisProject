{\rtf1\ansi\ansicpg936\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \CocoaLigature0 current epoch 1\
1591280817: step 1, loss 1.83002, acc 0.0909091\
1591280818: step 2, loss 2.95597, acc 0.272727\
1591280819: step 3, loss 2.21967, acc 0.227273\
1591280820: step 4, loss 1.59835, acc 0.227273\
1591280821: step 5, loss 1.75667, acc 0.227273\
1591280822: step 6, loss 1.68438, acc 0.181818\
1591280823: step 7, loss 1.62662, acc 0.409091\
1591280823: step 8, loss 1.59157, acc 0.363636\
1591280824: step 9, loss 1.57879, acc 0.272727\
1591280825: step 10, loss 1.5923, acc 0.363636\
1591280826: step 11, loss 1.48284, acc 0.227273\
1591280827: step 12, loss 1.72078, acc 0.181818\
1591280828: step 13, loss 1.48977, acc 0.363636\
1591280829: step 14, loss 1.67928, acc 0.318182\
1591280829: step 15, loss 1.71313, acc 0.227273\
1591280830: step 16, loss 1.49149, acc 0.454545\
1591280831: step 17, loss 1.69395, acc 0.272727\
1591280832: step 18, loss 1.48655, acc 0.363636\
1591280833: step 19, loss 1.49961, acc 0.318182\
1591280834: step 20, loss 1.65142, acc 0.363636\
1591280834: step 21, loss 1.64423, acc 0.318182\
1591280835: step 22, loss 1.50625, acc 0.318182\
1591280836: step 23, loss 1.60651, acc 0.227273\
1591280837: step 24, loss 1.37103, acc 0.454545\
1591280838: step 25, loss 1.55682, acc 0.409091\
1591280839: step 26, loss 1.53302, acc 0.272727\
1591280840: step 27, loss 1.70214, acc 0.318182\
1591280840: step 28, loss 1.63754, acc 0.227273\
1591280841: step 29, loss 1.40842, acc 0.363636\
1591280842: step 30, loss 1.66419, acc 0.181818\
1591280843: step 31, loss 1.64699, acc 0.136364\
1591280844: step 32, loss 1.76366, acc 0.0909091\
1591280845: step 33, loss 1.52953, acc 0.318182\
1591280846: step 34, loss 1.56851, acc 0.318182\
1591280846: step 35, loss 1.54765, acc 0.454545\
1591280847: step 36, loss 1.44854, acc 0.318182\
1591280848: step 37, loss 1.37091, acc 0.454545\
1591280849: step 38, loss 1.41015, acc 0.363636\
1591280850: step 39, loss 1.49091, acc 0.318182\
1591280851: step 40, loss 1.34163, acc 0.409091\
1591280852: step 41, loss 1.44793, acc 0.318182\
1591280852: step 42, loss 1.40421, acc 0.454545\
1591280853: step 43, loss 1.47401, acc 0.409091\
1591280854: step 44, loss 1.55733, acc 0.409091\
1591280855: step 45, loss 1.57945, acc 0.318182\
1591280856: step 46, loss 1.61855, acc 0.409091\
1591280857: step 47, loss 1.43109, acc 0.363636\
1591280858: step 48, loss 1.41223, acc 0.5\
1591280858: step 49, loss 1.54968, acc 0.272727\
1591280859: step 50, loss 1.44716, acc 0.363636\
1591280860: step 51, loss 1.39314, acc 0.5\
1591280861: step 52, loss 1.33603, acc 0.409091\
1591280862: step 53, loss 1.30926, acc 0.454545\
1591280863: step 54, loss 1.74821, acc 0.181818\
1591280864: step 55, loss 1.56397, acc 0.318182\
1591280864: step 56, loss 1.38833, acc 0.318182\
1591280865: step 57, loss 1.50009, acc 0.363636\
1591280866: step 58, loss 1.56185, acc 0.272727\
1591280867: step 59, loss 1.59852, acc 0.227273\
1591280868: step 60, loss 1.23279, acc 0.454545\
1591280869: step 61, loss 1.409, acc 0.272727\
1591280870: step 62, loss 1.27096, acc 0.454545\
1591280870: step 63, loss 1.31239, acc 0.454545\
1591280871: step 64, loss 1.45668, acc 0.272727\
1591280872: step 65, loss 1.39763, acc 0.409091\
1591280873: step 66, loss 1.39573, acc 0.363636\
1591280874: step 67, loss 1.3946, acc 0.181818\
1591280875: step 68, loss 1.33032, acc 0.363636\
1591280876: step 69, loss 1.09099, acc 0.545455\
1591280876: step 70, loss 1.19619, acc 0.454545\
1591280877: step 71, loss 1.38798, acc 0.454545\
1591280878: step 72, loss 1.40531, acc 0.409091\
1591280879: step 73, loss 1.47674, acc 0.181818\
1591280880: step 74, loss 1.21234, acc 0.5\
1591280881: step 75, loss 1.31, acc 0.545455\
1591280882: step 76, loss 1.43594, acc 0.409091\
1591280882: step 77, loss 1.01977, acc 0.5\
1591280883: step 78, loss 1.37306, acc 0.5\
1591280884: step 79, loss 1.04602, acc 0.681818\
1591280885: step 80, loss 1.5169, acc 0.318182\
1591280886: step 81, loss 1.26429, acc 0.454545\
1591280887: step 82, loss 1.16131, acc 0.590909\
1591280888: step 83, loss 1.14655, acc 0.681818\
1591280889: step 84, loss 1.05018, acc 0.636364\
1591280889: step 85, loss 1.37322, acc 0.363636\
1591280890: step 86, loss 1.40119, acc 0.227273\
1591280891: step 87, loss 1.35829, acc 0.318182\
1591280892: step 88, loss 1.01967, acc 0.545455\
1591280893: step 89, loss 1.1637, acc 0.590909\
1591280894: step 90, loss 1.40819, acc 0.363636\
1591280895: step 91, loss 1.12883, acc 0.590909\
1591280895: step 92, loss 1.1965, acc 0.545455\
1591280896: step 93, loss 1.42771, acc 0.409091\
1591280897: step 94, loss 1.13336, acc 0.454545\
1591280898: step 95, loss 1.04054, acc 0.5\
1591280899: step 96, loss 1.24769, acc 0.545455\
1591280900: step 97, loss 0.8978, acc 0.5\
1591280901: step 98, loss 1.32052, acc 0.318182\
1591280902: step 99, loss 1.13198, acc 0.5\
1591280902: step 100, loss 1.38048, acc 0.363636\
++++++++++++++++++dev++++++++++++++1591280911: step 100, loss 1.07866, acc 0.541247\
1591280912: step 101, loss 1.44642, acc 0.454545\
1591280912: step 102, loss 1.18486, acc 0.590909\
1591280913: step 103, loss 1.03295, acc 0.5\
1591280914: step 104, loss 1.2693, acc 0.454545\
1591280915: step 105, loss 1.02171, acc 0.590909\
1591280916: step 106, loss 1.0242, acc 0.636364\
1591280917: step 107, loss 1.15448, acc 0.5\
1591280917: step 108, loss 1.1869, acc 0.545455\
1591280918: step 109, loss 0.975894, acc 0.5\
1591280919: step 110, loss 1.26836, acc 0.409091\
1591280920: step 111, loss 1.16919, acc 0.363636\
1591280921: step 112, loss 1.20068, acc 0.636364\
1591280922: step 113, loss 1.5055, acc 0.409091\
1591280923: step 114, loss 0.978737, acc 0.5\
1591280924: step 115, loss 1.14026, acc 0.5\
1591280925: step 116, loss 1.23642, acc 0.545455\
1591280926: step 117, loss 1.23554, acc 0.454545\
1591280926: step 118, loss 1.07129, acc 0.454545\
1591280927: step 119, loss 1.1259, acc 0.545455\
1591280928: step 120, loss 1.22099, acc 0.409091\
1591280929: step 121, loss 1.50412, acc 0.5\
1591280930: step 122, loss 1.06531, acc 0.409091\
1591280931: step 123, loss 1.05429, acc 0.545455\
1591280932: step 124, loss 1.06692, acc 0.454545\
1591280933: step 125, loss 0.905694, acc 0.727273\
1591280933: step 126, loss 0.998281, acc 0.590909\
1591280934: step 127, loss 0.866442, acc 0.636364\
1591280935: step 128, loss 1.18491, acc 0.545455\
1591280936: step 129, loss 1.08494, acc 0.636364\
1591280937: step 130, loss 1.08088, acc 0.545455\
1591280938: step 131, loss 1.11605, acc 0.590909\
1591280939: step 132, loss 0.947181, acc 0.545455\
1591280939: step 133, loss 0.74143, acc 0.681818\
1591280940: step 134, loss 1.0119, acc 0.545455\
1591280941: step 135, loss 1.03396, acc 0.5\
1591280942: step 136, loss 0.903599, acc 0.454545\
1591280943: step 137, loss 0.965428, acc 0.590909\
1591280944: step 138, loss 1.24784, acc 0.5\
1591280944: step 139, loss 1.55094, acc 0.318182\
1591280945: step 140, loss 1.02486, acc 0.681818\
1591280946: step 141, loss 1.06721, acc 0.5\
1591280947: step 142, loss 1.10648, acc 0.681818\
1591280948: step 143, loss 0.729962, acc 0.727273\
1591280949: step 144, loss 1.07516, acc 0.590909\
1591280950: step 145, loss 0.774479, acc 0.727273\
1591280950: step 146, loss 0.971281, acc 0.636364\
1591280951: step 147, loss 0.775455, acc 0.772727\
1591280952: step 148, loss 1.05975, acc 0.545455\
1591280953: step 149, loss 1.31048, acc 0.545455\
1591280954: step 150, loss 1.13478, acc 0.454545\
1591280954: step 151, loss 1.27373, acc 0.454545\
1591280955: step 152, loss 1.02873, acc 0.590909\
1591280956: step 153, loss 1.0494, acc 0.5\
1591280957: step 154, loss 0.992234, acc 0.636364\
1591280958: step 155, loss 1.10377, acc 0.545455\
1591280959: step 156, loss 0.905106, acc 0.590909\
1591280959: step 157, loss 1.14243, acc 0.5\
1591280960: step 158, loss 1.10205, acc 0.5\
1591280961: step 159, loss 0.863353, acc 0.681818\
1591280962: step 160, loss 0.642123, acc 0.772727\
1591280963: step 161, loss 1.05205, acc 0.454545\
1591280964: step 162, loss 0.984388, acc 0.636364\
1591280964: step 163, loss 0.723621, acc 0.772727\
1591280965: step 164, loss 1.03577, acc 0.681818\
1591280966: step 165, loss 0.78873, acc 0.681818\
1591280967: step 166, loss 0.747733, acc 0.772727\
1591280968: step 167, loss 1.11284, acc 0.5\
1591280968: step 168, loss 0.688411, acc 0.772727\
1591280969: step 169, loss 1.14906, acc 0.5\
1591280970: step 170, loss 1.34429, acc 0.5\
1591280971: step 171, loss 1.37053, acc 0.545455\
1591280972: step 172, loss 1.07616, acc 0.636364\
1591280973: step 173, loss 0.813614, acc 0.681818\
1591280973: step 174, loss 0.833813, acc 0.681818\
1591280974: step 175, loss 1.33005, acc 0.454545\
1591280975: step 176, loss 1.00183, acc 0.636364\
1591280976: step 177, loss 0.738123, acc 0.772727\
1591280977: step 178, loss 0.969691, acc 0.636364\
1591280978: step 179, loss 1.25863, acc 0.454545\
1591280978: step 180, loss 0.834332, acc 0.636364\
1591280979: step 181, loss 0.848444, acc 0.681818\
1591280980: step 182, loss 0.964352, acc 0.590909\
1591280981: step 183, loss 0.686306, acc 0.727273\
1591280982: step 184, loss 0.829967, acc 0.681818\
1591280983: step 185, loss 1.56565, acc 0.409091\
1591280983: step 186, loss 0.772287, acc 0.681818\
1591280984: step 187, loss 1.33834, acc 0.454545\
1591280985: step 188, loss 1.18013, acc 0.454545\
1591280986: step 189, loss 0.519065, acc 0.818182\
1591280987: step 190, loss 1.17256, acc 0.454545\
1591280988: step 191, loss 1.0833, acc 0.545455\
1591280988: step 192, loss 0.889721, acc 0.772727\
1591280989: step 193, loss 0.840619, acc 0.681818\
1591280990: step 194, loss 1.31595, acc 0.409091\
1591280991: step 195, loss 0.76504, acc 0.727273\
1591280992: step 196, loss 0.994107, acc 0.636364\
1591280992: step 197, loss 1.04407, acc 0.545455\
1591280993: step 198, loss 1.02635, acc 0.454545\
1591280994: step 199, loss 1.21514, acc 0.545455\
1591280995: step 200, loss 0.910308, acc 0.590909\
++++++++++++++++++dev++++++++++++++1591281002: step 200, loss 0.868759, acc 0.668008\
1591281002: step 201, loss 0.899408, acc 0.727273\
1591281003: step 202, loss 1.15468, acc 0.545455\
1591281004: step 203, loss 1.07767, acc 0.545455\
1591281005: step 204, loss 0.736173, acc 0.642857\
current epoch 2\
1591281006: step 205, loss 0.705809, acc 0.727273\
1591281006: step 206, loss 0.703439, acc 0.681818\
1591281007: step 207, loss 1.03282, acc 0.5\
1591281008: step 208, loss 0.737225, acc 0.727273\
1591281009: step 209, loss 1.12321, acc 0.636364\
1591281010: step 210, loss 0.811376, acc 0.727273\
1591281010: step 211, loss 0.913236, acc 0.590909\
1591281011: step 212, loss 0.892743, acc 0.5\
1591281012: step 213, loss 0.589887, acc 0.772727\
1591281013: step 214, loss 0.946502, acc 0.545455\
1591281014: step 215, loss 0.889436, acc 0.636364\
1591281015: step 216, loss 1.04036, acc 0.590909\
1591281015: step 217, loss 0.857899, acc 0.681818\
1591281016: step 218, loss 0.789152, acc 0.681818\
1591281017: step 219, loss 0.845782, acc 0.681818\
1591281018: step 220, loss 0.844755, acc 0.772727\
1591281019: step 221, loss 0.895374, acc 0.727273\
1591281020: step 222, loss 0.636374, acc 0.772727\
1591281020: step 223, loss 0.745167, acc 0.727273\
1591281021: step 224, loss 0.772162, acc 0.681818\
1591281022: step 225, loss 1.09047, acc 0.590909\
1591281023: step 226, loss 0.700393, acc 0.636364\
1591281024: step 227, loss 0.613146, acc 0.727273\
1591281024: step 228, loss 0.570709, acc 0.772727\
1591281025: step 229, loss 0.678616, acc 0.772727\
1591281026: step 230, loss 1.07605, acc 0.545455\
1591281027: step 231, loss 0.608097, acc 0.727273\
1591281028: step 232, loss 0.976877, acc 0.590909\
1591281029: step 233, loss 0.585251, acc 0.772727\
1591281029: step 234, loss 0.741541, acc 0.727273\
1591281030: step 235, loss 0.698669, acc 0.681818\
1591281031: step 236, loss 0.813111, acc 0.681818\
1591281032: step 237, loss 0.606009, acc 0.772727\
1591281033: step 238, loss 0.770376, acc 0.636364\
1591281034: step 239, loss 0.76512, acc 0.727273\
1591281034: step 240, loss 0.953283, acc 0.636364\
1591281035: step 241, loss 0.490527, acc 0.863636\
1591281036: step 242, loss 0.761565, acc 0.636364\
1591281037: step 243, loss 0.665728, acc 0.727273\
1591281038: step 244, loss 0.765374, acc 0.772727\
1591281039: step 245, loss 0.756702, acc 0.681818\
1591281039: step 246, loss 0.569144, acc 0.681818\
1591281040: step 247, loss 0.894025, acc 0.727273\
1591281041: step 248, loss 0.675072, acc 0.772727\
1591281042: step 249, loss 1.10581, acc 0.545455\
1591281043: step 250, loss 0.850695, acc 0.681818\
1591281043: step 251, loss 0.778244, acc 0.727273\
1591281044: step 252, loss 0.806497, acc 0.636364\
1591281045: step 253, loss 0.733395, acc 0.727273\
1591281046: step 254, loss 0.816081, acc 0.590909\
1591281047: step 255, loss 0.636041, acc 0.772727\
1591281048: step 256, loss 0.747788, acc 0.636364\
1591281048: step 257, loss 0.60882, acc 0.772727\
1591281049: step 258, loss 0.971833, acc 0.681818\
1591281050: step 259, loss 0.869657, acc 0.590909\
1591281051: step 260, loss 0.543955, acc 0.772727\
1591281052: step 261, loss 0.756839, acc 0.681818\
1591281052: step 262, loss 0.95428, acc 0.681818\
1591281053: step 263, loss 0.824103, acc 0.681818\
1591281054: step 264, loss 0.87118, acc 0.727273\
1591281055: step 265, loss 0.602881, acc 0.818182\
1591281056: step 266, loss 0.500628, acc 0.727273\
1591281057: step 267, loss 0.603755, acc 0.772727\
1591281057: step 268, loss 0.760356, acc 0.727273\
1591281058: step 269, loss 0.61941, acc 0.818182\
1591281059: step 270, loss 0.8849, acc 0.681818\
1591281060: step 271, loss 0.532336, acc 0.818182\
1591281061: step 272, loss 0.509931, acc 0.772727\
1591281062: step 273, loss 0.482948, acc 0.818182\
1591281062: step 274, loss 0.768061, acc 0.636364\
1591281063: step 275, loss 0.791826, acc 0.727273\
1591281064: step 276, loss 0.854672, acc 0.681818\
1591281065: step 277, loss 0.75667, acc 0.681818\
1591281066: step 278, loss 0.634294, acc 0.772727\
1591281066: step 279, loss 0.655569, acc 0.681818\
1591281067: step 280, loss 0.892698, acc 0.681818\
1591281068: step 281, loss 0.440791, acc 0.863636\
1591281069: step 282, loss 0.762242, acc 0.636364\
1591281070: step 283, loss 0.503834, acc 0.818182\
1591281071: step 284, loss 0.71397, acc 0.590909\
1591281071: step 285, loss 0.677321, acc 0.727273\
1591281072: step 286, loss 0.571252, acc 0.818182\
1591281073: step 287, loss 0.356736, acc 0.863636\
1591281074: step 288, loss 0.670435, acc 0.772727\
1591281075: step 289, loss 0.665316, acc 0.636364\
1591281075: step 290, loss 0.587818, acc 0.681818\
1591281076: step 291, loss 0.607027, acc 0.818182\
1591281077: step 292, loss 0.583885, acc 0.772727\
1591281078: step 293, loss 0.835211, acc 0.681818\
1591281079: step 294, loss 0.741885, acc 0.636364\
1591281080: step 295, loss 0.352093, acc 0.863636\
1591281080: step 296, loss 0.505596, acc 0.863636\
1591281081: step 297, loss 0.671555, acc 0.727273\
1591281082: step 298, loss 0.728109, acc 0.636364\
1591281083: step 299, loss 0.610513, acc 0.772727\
1591281084: step 300, loss 0.456477, acc 0.772727\
++++++++++++++++++dev++++++++++++++1591281090: step 300, loss 0.768433, acc 0.716298\
1591281091: step 301, loss 0.847283, acc 0.590909\
1591281092: step 302, loss 0.760993, acc 0.727273\
1591281093: step 303, loss 0.728655, acc 0.772727\
1591281094: step 304, loss 0.845611, acc 0.590909\
1591281095: step 305, loss 0.80275, acc 0.772727\
1591281095: step 306, loss 0.717746, acc 0.727273\
1591281096: step 307, loss 0.693685, acc 0.727273\
1591281097: step 308, loss 0.824198, acc 0.727273\
1591281098: step 309, loss 0.582548, acc 0.727273\
1591281099: step 310, loss 0.71554, acc 0.681818\
1591281099: step 311, loss 0.507593, acc 0.772727\
1591281100: step 312, loss 0.549551, acc 0.727273\
1591281101: step 313, loss 0.585088, acc 0.772727\
1591281102: step 314, loss 1.08506, acc 0.636364\
1591281103: step 315, loss 0.652164, acc 0.681818\
1591281104: step 316, loss 0.600245, acc 0.681818\
1591281104: step 317, loss 1.11476, acc 0.636364\
1591281105: step 318, loss 0.402571, acc 0.863636\
1591281106: step 319, loss 0.851853, acc 0.681818\
1591281107: step 320, loss 1.098, acc 0.590909\
1591281108: step 321, loss 0.991915, acc 0.545455\
1591281109: step 322, loss 0.448991, acc 0.818182\
1591281109: step 323, loss 0.973984, acc 0.545455\
1591281110: step 324, loss 0.556605, acc 0.727273\
1591281111: step 325, loss 1.06182, acc 0.545455\
1591281112: step 326, loss 0.57364, acc 0.772727\
1591281113: step 327, loss 0.744054, acc 0.636364\
1591281113: step 328, loss 0.724552, acc 0.727273\
1591281114: step 329, loss 0.720115, acc 0.727273\
1591281115: step 330, loss 1.21959, acc 0.545455\
1591281116: step 331, loss 0.950828, acc 0.590909\
1591281117: step 332, loss 0.67714, acc 0.818182\
1591281118: step 333, loss 0.725693, acc 0.681818\
1591281118: step 334, loss 0.624948, acc 0.772727\
1591281119: step 335, loss 0.761039, acc 0.772727\
1591281120: step 336, loss 0.533404, acc 0.818182\
1591281121: step 337, loss 0.4351, acc 0.772727\
1591281122: step 338, loss 0.424515, acc 0.818182\
1591281122: step 339, loss 0.515561, acc 0.818182\
1591281123: step 340, loss 0.566928, acc 0.727273\
1591281124: step 341, loss 0.636195, acc 0.772727\
1591281125: step 342, loss 0.861412, acc 0.636364\
1591281126: step 343, loss 0.711226, acc 0.772727\
1591281126: step 344, loss 0.437482, acc 0.818182\
1591281127: step 345, loss 0.439465, acc 0.818182\
1591281128: step 346, loss 0.602277, acc 0.727273\
1591281129: step 347, loss 0.369917, acc 0.909091\
1591281130: step 348, loss 0.448026, acc 0.818182\
1591281131: step 349, loss 0.344426, acc 0.863636\
1591281131: step 350, loss 0.64897, acc 0.772727\
1591281132: step 351, loss 0.425624, acc 0.772727\
1591281133: step 352, loss 0.80427, acc 0.681818\
1591281134: step 353, loss 0.61094, acc 0.818182\
1591281135: step 354, loss 0.936177, acc 0.727273\
1591281136: step 355, loss 0.598726, acc 0.818182\
1591281136: step 356, loss 0.4042, acc 0.909091\
1591281137: step 357, loss 0.597428, acc 0.772727\
1591281138: step 358, loss 0.684747, acc 0.772727\
1591281139: step 359, loss 0.908227, acc 0.636364\
1591281140: step 360, loss 0.542882, acc 0.727273\
1591281141: step 361, loss 0.677918, acc 0.727273\
1591281141: step 362, loss 0.512047, acc 0.863636\
1591281142: step 363, loss 0.471458, acc 0.818182\
1591281143: step 364, loss 0.258692, acc 0.909091\
1591281144: step 365, loss 0.536644, acc 0.772727\
1591281145: step 366, loss 0.518356, acc 0.818182\
1591281145: step 367, loss 0.326138, acc 0.863636\
1591281146: step 368, loss 0.756406, acc 0.727273\
1591281147: step 369, loss 0.541052, acc 0.863636\
1591281148: step 370, loss 0.278463, acc 0.909091\
1591281149: step 371, loss 0.630467, acc 0.727273\
1591281150: step 372, loss 0.337265, acc 0.863636\
1591281150: step 373, loss 0.469507, acc 0.772727\
1591281151: step 374, loss 0.584114, acc 0.909091\
1591281152: step 375, loss 0.368335, acc 0.863636\
1591281153: step 376, loss 0.705498, acc 0.772727\
1591281154: step 377, loss 0.334702, acc 0.863636\
1591281154: step 378, loss 0.288626, acc 0.954545\
1591281155: step 379, loss 0.819235, acc 0.590909\
1591281156: step 380, loss 0.560428, acc 0.863636\
1591281157: step 381, loss 0.258728, acc 0.909091\
1591281158: step 382, loss 0.828074, acc 0.590909\
1591281159: step 383, loss 0.768802, acc 0.772727\
1591281159: step 384, loss 0.399292, acc 0.863636\
1591281160: step 385, loss 0.210226, acc 0.954545\
1591281161: step 386, loss 0.851385, acc 0.681818\
1591281162: step 387, loss 0.335457, acc 0.863636\
1591281163: step 388, loss 0.616001, acc 0.818182\
1591281163: step 389, loss 0.960036, acc 0.727273\
1591281164: step 390, loss 0.27505, acc 0.909091\
1591281165: step 391, loss 0.791375, acc 0.681818\
1591281166: step 392, loss 0.643747, acc 0.636364\
1591281167: step 393, loss 0.27136, acc 0.954545\
1591281168: step 394, loss 0.647938, acc 0.681818\
1591281168: step 395, loss 0.627748, acc 0.772727\
1591281169: step 396, loss 0.445999, acc 0.818182\
1591281170: step 397, loss 0.51166, acc 0.818182\
1591281171: step 398, loss 1.0073, acc 0.590909\
1591281172: step 399, loss 0.432008, acc 0.863636\
1591281173: step 400, loss 0.562576, acc 0.772727\
++++++++++++++++++dev++++++++++++++1591281181: step 400, loss 0.675815, acc 0.760563\
1591281181: step 401, loss 0.73121, acc 0.727273\
1591281182: step 402, loss 0.703123, acc 0.863636\
1591281183: step 403, loss 0.479339, acc 0.818182\
1591281184: step 404, loss 0.622461, acc 0.681818\
1591281185: step 405, loss 0.357289, acc 0.863636\
1591281186: step 406, loss 0.899172, acc 0.590909\
1591281186: step 407, loss 0.402942, acc 0.909091\
1591281187: step 408, loss 0.2648, acc 0.928571\
current epoch 3\
1591281188: step 409, loss 0.71315, acc 0.727273\
1591281189: step 410, loss 0.51054, acc 0.818182\
1591281189: step 411, loss 0.864358, acc 0.727273\
1591281190: step 412, loss 0.576426, acc 0.772727\
1591281191: step 413, loss 0.42665, acc 0.772727\
1591281192: step 414, loss 0.336885, acc 0.909091\
1591281193: step 415, loss 0.479518, acc 0.818182\
1591281194: step 416, loss 0.168949, acc 0.954545\
1591281194: step 417, loss 0.577362, acc 0.818182\
1591281195: step 418, loss 0.570175, acc 0.863636\
1591281196: step 419, loss 0.348692, acc 0.818182\
1591281197: step 420, loss 0.686916, acc 0.818182\
1591281198: step 421, loss 0.391506, acc 0.772727\
1591281199: step 422, loss 0.288462, acc 0.909091\
1591281200: step 423, loss 0.377016, acc 0.909091\
1591281200: step 424, loss 0.417362, acc 0.818182\
1591281201: step 425, loss 0.319053, acc 0.863636\
1591281202: step 426, loss 0.497539, acc 0.818182\
1591281203: step 427, loss 0.280433, acc 0.863636\
1591281204: step 428, loss 0.359109, acc 0.818182\
1591281205: step 429, loss 0.799965, acc 0.636364\
1591281206: step 430, loss 0.369758, acc 0.863636\
1591281207: step 431, loss 0.516378, acc 0.818182\
1591281208: step 432, loss 0.304351, acc 0.909091\
1591281209: step 433, loss 0.40872, acc 0.863636\
1591281210: step 434, loss 0.342519, acc 0.863636\
1591281211: step 435, loss 0.269878, acc 0.863636\
1591281212: step 436, loss 0.348323, acc 0.909091\
1591281212: step 437, loss 0.377467, acc 0.863636\
1591281213: step 438, loss 0.305442, acc 0.909091\
1591281214: step 439, loss 0.24907, acc 0.863636\
1591281215: step 440, loss 0.275817, acc 0.909091\
1591281216: step 441, loss 0.215851, acc 1\
1591281217: step 442, loss 0.636797, acc 0.818182\
1591281217: step 443, loss 0.291521, acc 0.863636\
1591281218: step 444, loss 0.633839, acc 0.727273\
1591281219: step 445, loss 0.4091, acc 0.818182\
1591281220: step 446, loss 0.182609, acc 0.954545\
1591281221: step 447, loss 0.317964, acc 0.863636\
1591281222: step 448, loss 0.281104, acc 0.909091\
1591281223: step 449, loss 0.474761, acc 0.909091\
1591281224: step 450, loss 0.421378, acc 0.818182\
1591281225: step 451, loss 0.470418, acc 0.772727\
1591281225: step 452, loss 0.498431, acc 0.818182\
1591281226: step 453, loss 0.545349, acc 0.772727\
1591281227: step 454, loss 0.403825, acc 0.863636\
1591281228: step 455, loss 0.39227, acc 0.818182\
1591281229: step 456, loss 0.36562, acc 0.772727\
1591281230: step 457, loss 0.3618, acc 0.909091\
1591281231: step 458, loss 0.535443, acc 0.772727\
1591281231: step 459, loss 0.245502, acc 0.909091\
1591281232: step 460, loss 0.460625, acc 0.818182\
1591281233: step 461, loss 0.37473, acc 0.818182\
1591281234: step 462, loss 0.358042, acc 0.863636\
1591281235: step 463, loss 0.585274, acc 0.818182\
1591281236: step 464, loss 0.244298, acc 0.863636\
1591281237: step 465, loss 0.411221, acc 0.863636\
1591281238: step 466, loss 0.448849, acc 0.818182\
1591281239: step 467, loss 0.613379, acc 0.727273\
1591281240: step 468, loss 0.365456, acc 0.863636\
1591281241: step 469, loss 0.265731, acc 0.909091\
1591281241: step 470, loss 0.108036, acc 1\
1591281242: step 471, loss 0.226967, acc 0.954545\
1591281243: step 472, loss 0.276121, acc 0.909091\
1591281244: step 473, loss 0.163472, acc 0.954545\
1591281245: step 474, loss 0.531951, acc 0.818182\
1591281246: step 475, loss 0.303381, acc 0.818182\
1591281247: step 476, loss 0.294114, acc 0.909091\
1591281247: step 477, loss 0.151406, acc 0.954545\
1591281248: step 478, loss 0.530151, acc 0.863636\
1591281249: step 479, loss 0.227234, acc 0.954545\
1591281250: step 480, loss 0.326682, acc 0.954545\
1591281251: step 481, loss 0.424426, acc 0.772727\
1591281252: step 482, loss 0.306392, acc 0.909091\
1591281253: step 483, loss 0.449907, acc 0.772727\
1591281253: step 484, loss 0.472125, acc 0.863636\
1591281254: step 485, loss 0.132417, acc 0.954545\
1591281255: step 486, loss 0.208364, acc 0.954545\
1591281256: step 487, loss 0.173929, acc 0.954545\
1591281257: step 488, loss 0.403238, acc 0.818182\
1591281258: step 489, loss 0.161531, acc 0.954545\
1591281258: step 490, loss 0.0861663, acc 1\
1591281259: step 491, loss 0.238341, acc 0.909091\
1591281260: step 492, loss 0.0921076, acc 1\
1591281261: step 493, loss 0.466446, acc 0.863636\
1591281262: step 494, loss 0.552893, acc 0.727273\
1591281263: step 495, loss 0.172098, acc 0.954545\
1591281264: step 496, loss 0.0870216, acc 1\
1591281264: step 497, loss 0.263596, acc 0.954545\
1591281265: step 498, loss 0.423655, acc 0.863636\
1591281266: step 499, loss 0.23833, acc 0.909091\
1591281267: step 500, loss 0.285016, acc 0.909091\
++++++++++++++++++dev++++++++++++++1591281274: step 500, loss 0.630468, acc 0.792757\
1591281275: step 501, loss 0.374958, acc 0.863636\
1591281275: step 502, loss 0.260151, acc 0.863636\
1591281276: step 503, loss 0.236267, acc 0.909091\
1591281277: step 504, loss 0.185895, acc 0.909091\
1591281278: step 505, loss 0.584833, acc 0.818182\
1591281279: step 506, loss 0.109578, acc 1\
1591281280: step 507, loss 0.0405807, acc 1\
1591281281: step 508, loss 0.325728, acc 0.909091\
1591281282: step 509, loss 0.629206, acc 0.772727\
1591281282: step 510, loss 0.294706, acc 0.909091\
1591281283: step 511, loss 0.267555, acc 0.909091\
1591281284: step 512, loss 0.544356, acc 0.863636\
1591281285: step 513, loss 0.272623, acc 0.909091\
1591281286: step 514, loss 0.366575, acc 0.818182\
1591281287: step 515, loss 0.249157, acc 0.909091\
1591281288: step 516, loss 0.178436, acc 0.954545\
1591281289: step 517, loss 0.389957, acc 0.818182\
1591281290: step 518, loss 0.566104, acc 0.818182\
1591281291: step 519, loss 0.394285, acc 0.818182\
1591281291: step 520, loss 0.235265, acc 0.909091\
1591281292: step 521, loss 0.606129, acc 0.727273\
1591281293: step 522, loss 0.11917, acc 0.954545\
1591281294: step 523, loss 0.406882, acc 0.954545\
1591281295: step 524, loss 0.265344, acc 0.909091\
1591281296: step 525, loss 0.293943, acc 0.818182\
1591281297: step 526, loss 0.113609, acc 0.954545\
1591281297: step 527, loss 0.63327, acc 0.772727\
1591281298: step 528, loss 0.410813, acc 0.818182\
1591281299: step 529, loss 0.277435, acc 0.954545\
1591281300: step 530, loss 0.270525, acc 0.863636\
1591281301: step 531, loss 0.141976, acc 0.954545\
1591281302: step 532, loss 0.326876, acc 0.863636\
1591281303: step 533, loss 0.160194, acc 0.954545\
1591281303: step 534, loss 0.633164, acc 0.772727\
1591281304: step 535, loss 0.204842, acc 0.909091\
1591281305: step 536, loss 0.138571, acc 0.954545\
1591281306: step 537, loss 0.590567, acc 0.772727\
1591281307: step 538, loss 0.49874, acc 0.863636\
1591281308: step 539, loss 0.544995, acc 0.818182\
1591281309: step 540, loss 0.436671, acc 0.818182\
1591281309: step 541, loss 0.0904986, acc 0.954545\
1591281310: step 542, loss 0.140691, acc 0.954545\
1591281311: step 543, loss 0.405867, acc 0.863636\
1591281312: step 544, loss 0.23895, acc 0.954545\
1591281313: step 545, loss 0.274146, acc 0.909091\
1591281314: step 546, loss 0.287623, acc 0.909091\
1591281315: step 547, loss 0.25759, acc 0.909091\
1591281315: step 548, loss 0.335652, acc 0.909091\
1591281316: step 549, loss 0.147485, acc 1\
1591281317: step 550, loss 0.30694, acc 0.863636\
1591281318: step 551, loss 0.257118, acc 0.909091\
1591281319: step 552, loss 0.285915, acc 0.909091\
1591281320: step 553, loss 0.175953, acc 0.954545\
1591281321: step 554, loss 0.591653, acc 0.681818\
1591281321: step 555, loss 0.132989, acc 0.954545\
1591281322: step 556, loss 0.387692, acc 0.863636\
1591281323: step 557, loss 0.268171, acc 0.863636\
1591281324: step 558, loss 0.459589, acc 0.863636\
1591281325: step 559, loss 0.488022, acc 0.772727\
1591281326: step 560, loss 0.101414, acc 0.954545\
1591281327: step 561, loss 0.294517, acc 0.863636\
1591281327: step 562, loss 0.25442, acc 0.954545\
1591281328: step 563, loss 0.306835, acc 0.909091\
1591281329: step 564, loss 0.266855, acc 0.954545\
1591281330: step 565, loss 0.336897, acc 0.863636\
1591281331: step 566, loss 0.173693, acc 0.954545\
1591281332: step 567, loss 0.25074, acc 0.954545\
1591281333: step 568, loss 0.0685352, acc 0.954545\
1591281334: step 569, loss 0.312722, acc 0.909091\
1591281335: step 570, loss 0.146064, acc 0.909091\
1591281335: step 571, loss 0.302564, acc 0.909091\
1591281336: step 572, loss 0.407099, acc 0.818182\
1591281337: step 573, loss 0.15383, acc 0.909091\
1591281338: step 574, loss 0.112662, acc 0.954545\
1591281339: step 575, loss 0.0864635, acc 1\
1591281340: step 576, loss 0.083611, acc 0.954545\
1591281341: step 577, loss 0.130897, acc 0.909091\
1591281341: step 578, loss 0.13959, acc 0.954545\
1591281342: step 579, loss 0.297125, acc 0.863636\
1591281343: step 580, loss 0.345131, acc 0.863636\
1591281344: step 581, loss 0.130391, acc 0.909091\
1591281345: step 582, loss 0.107619, acc 1\
1591281346: step 583, loss 0.130693, acc 0.909091\
1591281347: step 584, loss 0.400233, acc 0.818182\
1591281348: step 585, loss 0.119638, acc 0.954545\
1591281348: step 586, loss 0.390984, acc 0.863636\
1591281349: step 587, loss 0.305289, acc 0.863636\
1591281350: step 588, loss 0.124198, acc 0.954545\
1591281351: step 589, loss 0.0134149, acc 1\
1591281352: step 590, loss 0.507221, acc 0.863636\
1591281353: step 591, loss 0.0621067, acc 1\
1591281354: step 592, loss 0.234044, acc 0.863636\
1591281354: step 593, loss 0.567212, acc 0.818182\
1591281355: step 594, loss 0.172323, acc 0.909091\
1591281356: step 595, loss 0.220457, acc 0.909091\
1591281357: step 596, loss 0.388485, acc 0.863636\
1591281358: step 597, loss 0.134795, acc 0.954545\
1591281359: step 598, loss 0.270375, acc 0.909091\
1591281360: step 599, loss 0.0327161, acc 1\
1591281361: step 600, loss 0.238336, acc 0.863636\
++++++++++++++++++dev++++++++++++++1591281369: step 600, loss 0.624514, acc 0.800805\
1591281369: step 601, loss 0.307822, acc 0.954545\
1591281370: step 602, loss 0.245531, acc 0.909091\
1591281371: step 603, loss 0.0712624, acc 0.954545\
1591281372: step 604, loss 0.336772, acc 0.909091\
1591281373: step 605, loss 0.303491, acc 0.909091\
1591281374: step 606, loss 0.388019, acc 0.818182\
1591281375: step 607, loss 0.403886, acc 0.818182\
1591281375: step 608, loss 0.169272, acc 0.909091\
1591281376: step 609, loss 0.112499, acc 0.954545\
1591281377: step 610, loss 0.328565, acc 0.818182\
1591281378: step 611, loss 0.144745, acc 1\
1591281379: step 612, loss 0.131749, acc 0.857143\
current epoch 4\
1591281379: step 613, loss 0.157045, acc 0.909091\
1591281380: step 614, loss 0.304613, acc 0.863636\
1591281381: step 615, loss 0.072323, acc 1\
1591281382: step 616, loss 0.370503, acc 0.772727\
1591281383: step 617, loss 0.114237, acc 0.954545\
1591281384: step 618, loss 0.160681, acc 0.954545\
1591281385: step 619, loss 0.110283, acc 1\
1591281385: step 620, loss 0.0261741, acc 1\
1591281386: step 621, loss 0.556645, acc 0.727273\
1591281387: step 622, loss 0.350875, acc 0.863636\
1591281388: step 623, loss 0.350959, acc 0.772727\
1591281389: step 624, loss 0.268213, acc 0.954545\
1591281390: step 625, loss 0.222402, acc 0.909091\
1591281391: step 626, loss 0.0397776, acc 1\
1591281392: step 627, loss 0.250692, acc 0.863636\
1591281392: step 628, loss 0.102734, acc 0.954545\
1591281393: step 629, loss 0.354976, acc 0.909091\
1591281394: step 630, loss 0.220865, acc 0.909091\
1591281395: step 631, loss 0.105602, acc 0.954545\
1591281396: step 632, loss 0.326969, acc 0.909091\
1591281397: step 633, loss 0.279156, acc 0.863636\
1591281397: step 634, loss 0.0389642, acc 1\
1591281398: step 635, loss 0.227934, acc 0.909091\
1591281399: step 636, loss 0.331537, acc 0.863636\
1591281400: step 637, loss 0.30274, acc 0.863636\
1591281401: step 638, loss 0.167213, acc 0.954545\
1591281402: step 639, loss 0.100041, acc 0.954545\
1591281403: step 640, loss 0.162785, acc 0.954545\
1591281404: step 641, loss 0.136032, acc 0.954545\
1591281404: step 642, loss 0.0744102, acc 0.954545\
1591281405: step 643, loss 0.106797, acc 0.954545\
1591281406: step 644, loss 0.229949, acc 0.909091\
1591281407: step 645, loss 0.194172, acc 0.954545\
1591281408: step 646, loss 0.446754, acc 0.818182\
1591281409: step 647, loss 0.0465095, acc 1\
1591281410: step 648, loss 0.156236, acc 0.909091\
1591281411: step 649, loss 0.268607, acc 0.954545\
1591281411: step 650, loss 0.139074, acc 0.954545\
1591281412: step 651, loss 0.136683, acc 0.954545\
1591281413: step 652, loss 0.150524, acc 0.909091\
1591281414: step 653, loss 0.451214, acc 0.818182\
1591281415: step 654, loss 0.394212, acc 0.909091\
1591281416: step 655, loss 0.197337, acc 0.954545\
1591281417: step 656, loss 0.148605, acc 0.954545\
1591281418: step 657, loss 0.318946, acc 0.863636\
1591281418: step 658, loss 0.148334, acc 0.954545\
1591281419: step 659, loss 0.296875, acc 0.909091\
1591281420: step 660, loss 0.0705523, acc 1\
1591281421: step 661, loss 0.334116, acc 0.863636\
1591281422: step 662, loss 0.134967, acc 0.954545\
1591281423: step 663, loss 0.218599, acc 0.909091\
1591281424: step 664, loss 0.194993, acc 0.954545\
1591281424: step 665, loss 0.141377, acc 0.954545\
1591281425: step 666, loss 0.026785, acc 1\
1591281426: step 667, loss 0.191624, acc 0.909091\
1591281427: step 668, loss 0.0293039, acc 1\
1591281428: step 669, loss 0.408576, acc 0.863636\
1591281429: step 670, loss 0.318485, acc 0.909091\
1591281430: step 671, loss 0.49533, acc 0.818182\
1591281430: step 672, loss 0.131807, acc 0.954545\
1591281431: step 673, loss 0.0817187, acc 1\
1591281432: step 674, loss 0.103473, acc 0.954545\
1591281433: step 675, loss 0.0672238, acc 1\
1591281434: step 676, loss 0.141771, acc 0.909091\
1591281435: step 677, loss 0.164301, acc 0.909091\
1591281436: step 678, loss 0.424885, acc 0.863636\
1591281436: step 679, loss 0.112858, acc 0.954545\
1591281437: step 680, loss 0.337706, acc 0.818182\
1591281438: step 681, loss 0.18962, acc 0.909091\
1591281439: step 682, loss 0.457982, acc 0.909091\
1591281440: step 683, loss 0.104836, acc 0.909091\
1591281441: step 684, loss 0.478844, acc 0.818182\
1591281441: step 685, loss 0.09223, acc 0.954545\
1591281442: step 686, loss 0.0185312, acc 1\
1591281443: step 687, loss 0.458919, acc 0.818182\
1591281444: step 688, loss 0.420476, acc 0.909091\
1591281445: step 689, loss 0.0393385, acc 1\
1591281446: step 690, loss 0.184539, acc 0.954545\
1591281447: step 691, loss 0.13707, acc 0.909091\
1591281447: step 692, loss 0.225714, acc 0.909091\
1591281448: step 693, loss 0.0360378, acc 1\
1591281449: step 694, loss 0.143886, acc 0.954545\
1591281450: step 695, loss 0.235545, acc 0.863636\
1591281451: step 696, loss 0.205181, acc 0.909091\
1591281452: step 697, loss 0.362754, acc 0.909091\
1591281453: step 698, loss 0.185991, acc 0.909091\
1591281453: step 699, loss 0.0482122, acc 1\
1591281454: step 700, loss 0.0783272, acc 0.954545\
++++++++++++++++++dev++++++++++++++1591281461: step 700, loss 0.578355, acc 0.804829\
1591281462: step 701, loss 0.105276, acc 0.954545\
1591281463: step 702, loss 0.208033, acc 0.909091\
1591281464: step 703, loss 0.00308379, acc 1\
1591281465: step 704, loss 0.0257392, acc 1\
1591281466: step 705, loss 0.25739, acc 0.909091\
1591281466: step 706, loss 0.119531, acc 0.954545\
1591281467: step 707, loss 0.200407, acc 0.909091\
1591281468: step 708, loss 0.087411, acc 1\
1591281469: step 709, loss 0.177932, acc 0.909091\
1591281470: step 710, loss 0.154227, acc 0.954545\
1591281471: step 711, loss 0.13912, acc 0.954545\
1591281472: step 712, loss 0.25887, acc 0.909091\
1591281472: step 713, loss 0.130983, acc 0.909091\
1591281473: step 714, loss 0.200232, acc 0.863636\
1591281474: step 715, loss 0.403515, acc 0.863636\
1591281475: step 716, loss 0.504563, acc 0.909091\
1591281476: step 717, loss 0.167407, acc 0.954545\
1591281477: step 718, loss 0.0482372, acc 1\
1591281477: step 719, loss 0.108176, acc 1\
1591281478: step 720, loss 0.0785669, acc 0.954545\
1591281479: step 721, loss 0.0907179, acc 0.954545\
1591281480: step 722, loss 0.313014, acc 0.863636\
1591281481: step 723, loss 0.0500935, acc 1\
1591281482: step 724, loss 0.121176, acc 0.954545\
1591281483: step 725, loss 0.11575, acc 0.954545\
1591281484: step 726, loss 0.0657528, acc 1\
1591281484: step 727, loss 0.145556, acc 0.954545\
1591281485: step 728, loss 0.172777, acc 0.954545\
1591281486: step 729, loss 0.159212, acc 0.909091\
1591281487: step 730, loss 0.128367, acc 0.954545\
1591281488: step 731, loss 0.295315, acc 0.909091\
1591281489: step 732, loss 0.248224, acc 0.863636\
1591281490: step 733, loss 0.0405292, acc 1\
1591281490: step 734, loss 0.223715, acc 0.954545\
1591281491: step 735, loss 0.0985653, acc 0.954545\
1591281492: step 736, loss 0.218778, acc 0.954545\
1591281493: step 737, loss 0.16102, acc 0.954545\
1591281494: step 738, loss 0.191806, acc 0.954545\
1591281495: step 739, loss 0.148369, acc 0.954545\
1591281496: step 740, loss 0.10124, acc 0.954545\
1591281496: step 741, loss 0.251234, acc 0.909091\
1591281497: step 742, loss 0.140912, acc 0.909091\
1591281498: step 743, loss 0.116537, acc 0.954545\
1591281499: step 744, loss 0.133093, acc 0.909091\
1591281500: step 745, loss 0.0679141, acc 1\
1591281501: step 746, loss 0.138651, acc 0.954545\
1591281501: step 747, loss 0.32802, acc 0.909091\
1591281502: step 748, loss 0.196266, acc 0.909091\
1591281503: step 749, loss 0.162607, acc 0.954545\
1591281504: step 750, loss 0.279438, acc 0.909091\
1591281505: step 751, loss 0.0676127, acc 1\
1591281506: step 752, loss 0.085694, acc 1\
1591281507: step 753, loss 0.078203, acc 1\
1591281507: step 754, loss 0.146381, acc 0.954545\
1591281508: step 755, loss 0.0624248, acc 1\
1591281509: step 756, loss 0.151943, acc 0.954545\
1591281510: step 757, loss 0.0569716, acc 1\
1591281511: step 758, loss 0.369306, acc 0.818182\
1591281512: step 759, loss 0.00776722, acc 1\
1591281512: step 760, loss 0.228485, acc 0.909091\
1591281513: step 761, loss 0.293491, acc 0.909091\
1591281514: step 762, loss 0.107812, acc 0.954545\
1591281515: step 763, loss 0.115757, acc 0.954545\
1591281516: step 764, loss 0.00811213, acc 1\
1591281516: step 765, loss 0.00905006, acc 1\
1591281517: step 766, loss 0.224739, acc 0.863636\
1591281518: step 767, loss 0.0965441, acc 1\
1591281519: step 768, loss 0.0449412, acc 1\
1591281520: step 769, loss 0.336308, acc 0.863636\
1591281521: step 770, loss 0.0782699, acc 0.954545\
1591281521: step 771, loss 0.0328359, acc 1\
1591281522: step 772, loss 0.042311, acc 1\
1591281523: step 773, loss 0.103341, acc 0.954545\
1591281524: step 774, loss 0.106985, acc 0.954545\
1591281525: step 775, loss 0.0356878, acc 1\
1591281526: step 776, loss 0.193808, acc 0.909091\
1591281526: step 777, loss 0.0403077, acc 1\
1591281527: step 778, loss 0.128854, acc 0.954545\
1591281528: step 779, loss 0.0256383, acc 1\
1591281529: step 780, loss 0.0595167, acc 0.954545\
1591281530: step 781, loss 0.0844056, acc 1\
1591281531: step 782, loss 0.0985288, acc 0.954545\
1591281531: step 783, loss 0.04717, acc 1\
1591281532: step 784, loss 0.213939, acc 0.909091\
1591281533: step 785, loss 0.0146866, acc 1\
1591281534: step 786, loss 0.0219913, acc 1\
1591281535: step 787, loss 0.019457, acc 1\
1591281536: step 788, loss 0.248382, acc 0.909091\
1591281537: step 789, loss 0.0908327, acc 0.954545\
1591281537: step 790, loss 0.25972, acc 0.863636\
1591281538: step 791, loss 0.0293683, acc 1\
1591281539: step 792, loss 0.167047, acc 0.909091\
1591281540: step 793, loss 0.205211, acc 0.909091\
1591281541: step 794, loss 0.67231, acc 0.863636\
1591281542: step 795, loss 0.0209626, acc 1\
1591281543: step 796, loss 0.135263, acc 0.909091\
1591281544: step 797, loss 0.251742, acc 0.909091\
1591281545: step 798, loss 0.119921, acc 0.954545\
1591281546: step 799, loss 0.0789845, acc 0.954545\
1591281547: step 800, loss 0.0705444, acc 0.954545\
++++++++++++++++++dev++++++++++++++1591281555: step 800, loss 0.658099, acc 0.808853\
1591281555: step 801, loss 0.0117054, acc 1\
1591281556: step 802, loss 0.0589693, acc 1\
1591281557: step 803, loss 0.0598563, acc 0.954545\
1591281558: step 804, loss 0.0123363, acc 1\
1591281559: step 805, loss 0.137124, acc 0.909091\
1591281560: step 806, loss 0.189398, acc 0.954545\
1591281561: step 807, loss 0.06347, acc 1\
1591281562: step 808, loss 0.0746713, acc 1\
1591281562: step 809, loss 0.232251, acc 0.909091\
1591281563: step 810, loss 0.164517, acc 0.909091\
1591281564: step 811, loss 0.211628, acc 0.909091\
1591281565: step 812, loss 0.161878, acc 0.909091\
1591281566: step 813, loss 0.0479393, acc 1\
1591281567: step 814, loss 0.296671, acc 0.863636\
1591281568: step 815, loss 0.0158305, acc 1\
1591281568: step 816, loss 0.0110722, acc 1\
current epoch 5\
1591281569: step 817, loss 0.135892, acc 0.909091\
1591281570: step 818, loss 0.172128, acc 0.909091\
1591281571: step 819, loss 0.0758503, acc 0.954545\
1591281571: step 820, loss 0.136546, acc 0.909091\
1591281572: step 821, loss 0.0201213, acc 1\
1591281573: step 822, loss 0.327962, acc 0.863636\
1591281574: step 823, loss 0.0746149, acc 0.954545\
1591281575: step 824, loss 0.0116597, acc 1\
1591281576: step 825, loss 0.212708, acc 0.909091\
1591281576: step 826, loss 0.135336, acc 0.954545\
1591281577: step 827, loss 0.0497045, acc 1\
1591281578: step 828, loss 0.103528, acc 0.954545\
1591281579: step 829, loss 0.0878802, acc 0.954545\
1591281580: step 830, loss 0.0331978, acc 1\
1591281581: step 831, loss 0.00180173, acc 1\
1591281582: step 832, loss 0.342066, acc 0.954545\
1591281583: step 833, loss 0.110101, acc 0.954545\
1591281583: step 834, loss 0.161219, acc 0.954545\
1591281584: step 835, loss 0.112269, acc 0.909091\
1591281585: step 836, loss 0.205468, acc 0.909091\
1591281586: step 837, loss 0.0610876, acc 1\
1591281587: step 838, loss 0.0195933, acc 1\
1591281588: step 839, loss 0.286909, acc 0.863636\
1591281589: step 840, loss 0.107133, acc 0.954545\
1591281590: step 841, loss 0.00601938, acc 1\
1591281591: step 842, loss 0.0282699, acc 1\
1591281592: step 843, loss 0.0835495, acc 0.954545\
1591281592: step 844, loss 0.227313, acc 0.954545\
1591281593: step 845, loss 0.0537137, acc 1\
1591281594: step 846, loss 0.0674496, acc 1\
1591281595: step 847, loss 0.0157564, acc 1\
1591281596: step 848, loss 0.0821539, acc 0.954545\
1591281597: step 849, loss 0.285563, acc 0.954545\
1591281598: step 850, loss 0.114653, acc 0.954545\
1591281599: step 851, loss 0.0584362, acc 0.954545\
1591281599: step 852, loss 0.176393, acc 0.863636\
1591281600: step 853, loss 0.297596, acc 0.954545\
1591281601: step 854, loss 0.0333017, acc 1\
1591281602: step 855, loss 0.0684119, acc 0.954545\
1591281603: step 856, loss 0.141639, acc 0.909091\
1591281604: step 857, loss 0.225511, acc 0.954545\
1591281605: step 858, loss 0.187231, acc 0.909091\
1591281606: step 859, loss 0.168048, acc 0.954545\
1591281606: step 860, loss 0.00703224, acc 1\
1591281607: step 861, loss 0.476066, acc 0.863636\
1591281608: step 862, loss 0.179517, acc 0.954545\
1591281609: step 863, loss 0.0874173, acc 1\
1591281610: step 864, loss 0.108124, acc 0.954545\
1591281611: step 865, loss 0.201491, acc 0.954545\
1591281612: step 866, loss 0.311862, acc 0.909091\
1591281613: step 867, loss 0.11521, acc 0.954545\
1591281613: step 868, loss 0.0977042, acc 0.954545\
1591281614: step 869, loss 0.0943312, acc 0.954545\
1591281615: step 870, loss 0.115041, acc 0.954545\
1591281616: step 871, loss 0.0619723, acc 0.954545\
1591281617: step 872, loss 0.0152012, acc 1\
1591281618: step 873, loss 0.239948, acc 0.909091\
1591281619: step 874, loss 0.133359, acc 0.954545\
1591281620: step 875, loss 0.138228, acc 0.954545\
1591281620: step 876, loss 0.15385, acc 0.909091\
1591281621: step 877, loss 0.0432476, acc 1\
1591281622: step 878, loss 0.0507006, acc 1\
1591281623: step 879, loss 0.0225696, acc 1\
1591281624: step 880, loss 0.164928, acc 0.954545\
1591281625: step 881, loss 0.1393, acc 0.954545\
1591281626: step 882, loss 0.0825259, acc 1\
1591281627: step 883, loss 0.0766265, acc 0.954545\
1591281627: step 884, loss 0.138578, acc 0.954545\
1591281628: step 885, loss 0.0998727, acc 0.909091\
1591281629: step 886, loss 0.246349, acc 0.954545\
1591281630: step 887, loss 0.047349, acc 1\
1591281631: step 888, loss 0.0232823, acc 1\
1591281632: step 889, loss 0.0380991, acc 1\
1591281633: step 890, loss 0.027983, acc 1\
1591281634: step 891, loss 0.342539, acc 0.909091\
1591281634: step 892, loss 0.416495, acc 0.863636\
1591281635: step 893, loss 0.0271721, acc 1\
1591281636: step 894, loss 0.10657, acc 0.954545\
1591281637: step 895, loss 0.0965575, acc 0.954545\
1591281638: step 896, loss 0.20623, acc 0.909091\
1591281639: step 897, loss 0.00849349, acc 1\
1591281640: step 898, loss 0.0592852, acc 1\
1591281640: step 899, loss 0.130213, acc 0.909091\
1591281641: step 900, loss 0.00544902, acc 1\
++++++++++++++++++dev++++++++++++++1591281649: step 900, loss 0.66455, acc 0.820926\
1591281649: step 901, loss 0.102157, acc 0.954545\
1591281650: step 902, loss 0.17876, acc 0.909091\
1591281651: step 903, loss 0.0585638, acc 1\
1591281652: step 904, loss 0.0293001, acc 1\
1591281653: step 905, loss 0.0910234, acc 0.954545\
1591281654: step 906, loss 0.0596757, acc 1\
1591281655: step 907, loss 0.00548356, acc 1\
1591281656: step 908, loss 0.0193886, acc 1\
1591281657: step 909, loss 0.0528518, acc 1\
1591281657: step 910, loss 0.184057, acc 0.909091\
1591281658: step 911, loss 0.0623122, acc 1\
1591281659: step 912, loss 0.109989, acc 0.954545\
1591281660: step 913, loss 0.171578, acc 0.909091\
1591281661: step 914, loss 0.0311143, acc 1\
1591281662: step 915, loss 0.0304001, acc 1\
1591281663: step 916, loss 0.163881, acc 0.954545\
1591281663: step 917, loss 0.060744, acc 0.954545\
1591281664: step 918, loss 0.100344, acc 0.954545\
1591281665: step 919, loss 0.259626, acc 0.909091\
1591281666: step 920, loss 0.105581, acc 0.954545\
1591281667: step 921, loss 0.0610383, acc 1\
1591281668: step 922, loss 0.163788, acc 0.954545\
1591281668: step 923, loss 0.0638063, acc 1\
1591281669: step 924, loss 0.085651, acc 0.954545\
1591281670: step 925, loss 0.0824389, acc 0.954545\
1591281671: step 926, loss 0.18413, acc 0.909091\
1591281672: step 927, loss 0.0499729, acc 1\
1591281673: step 928, loss 0.113481, acc 0.954545\
1591281673: step 929, loss 0.048379, acc 0.954545\
1591281674: step 930, loss 0.0902489, acc 0.909091\
1591281675: step 931, loss 0.00676469, acc 1\
1591281676: step 932, loss 0.058606, acc 0.954545\
1591281677: step 933, loss 0.210535, acc 0.863636\
1591281678: step 934, loss 0.0113823, acc 1\
1591281679: step 935, loss 0.188625, acc 0.863636\
1591281679: step 936, loss 0.0803045, acc 0.954545\
1591281680: step 937, loss 0.0150035, acc 1\
1591281681: step 938, loss 0.297341, acc 0.954545\
1591281682: step 939, loss 0.119136, acc 0.954545\
1591281683: step 940, loss 0.189452, acc 0.954545\
1591281684: step 941, loss 0.0530075, acc 1\
1591281685: step 942, loss 0.3484, acc 0.909091\
1591281686: step 943, loss 0.0905718, acc 0.954545\
1591281686: step 944, loss 0.0972565, acc 0.954545\
1591281687: step 945, loss 0.150792, acc 0.909091\
1591281688: step 946, loss 0.0125239, acc 1\
1591281689: step 947, loss 0.024772, acc 1\
1591281690: step 948, loss 0.0837008, acc 0.954545\
1591281691: step 949, loss 0.0737257, acc 0.954545\
1591281692: step 950, loss 0.130758, acc 0.909091\
1591281692: step 951, loss 0.330534, acc 0.863636\
1591281693: step 952, loss 0.0872764, acc 0.954545\
1591281694: step 953, loss 0.0814647, acc 1\
1591281695: step 954, loss 0.0808978, acc 0.954545\
1591281696: step 955, loss 0.00926674, acc 1\
1591281697: step 956, loss 0.0684299, acc 1\
1591281698: step 957, loss 0.0653495, acc 1\
1591281699: step 958, loss 0.0667647, acc 0.954545\
1591281699: step 959, loss 0.00559575, acc 1\
1591281700: step 960, loss 0.0497782, acc 1\
1591281701: step 961, loss 0.00857664, acc 1\
1591281702: step 962, loss 0.434947, acc 0.909091\
1591281703: step 963, loss 0.034843, acc 1\
1591281704: step 964, loss 0.0817596, acc 0.954545\
1591281705: step 965, loss 0.108393, acc 0.954545\
1591281705: step 966, loss 0.0176362, acc 1\
1591281706: step 967, loss 0.0300856, acc 1\
1591281707: step 968, loss 0.0281453, acc 1\
1591281708: step 969, loss 0.00734243, acc 1\
1591281709: step 970, loss 0.0700299, acc 0.954545\
1591281710: step 971, loss 0.0568784, acc 1\
1591281711: step 972, loss 0.0231613, acc 1\
1591281711: step 973, loss 0.143173, acc 0.954545\
1591281712: step 974, loss 0.0515193, acc 1\
1591281713: step 975, loss 0.00918698, acc 1\
1591281714: step 976, loss 0.00372624, acc 1\
1591281715: step 977, loss 0.0119515, acc 1\
1591281716: step 978, loss 0.0121845, acc 1\
1591281716: step 979, loss 0.0289926, acc 1\
1591281717: step 980, loss 0.0584417, acc 1\
1591281718: step 981, loss 0.0432977, acc 1\
1591281719: step 982, loss 0.116335, acc 0.954545\
1591281720: step 983, loss 0.017547, acc 1\
1591281721: step 984, loss 0.0537851, acc 1\
1591281722: step 985, loss 0.0314976, acc 1\
1591281722: step 986, loss 0.0680304, acc 0.954545\
1591281723: step 987, loss 0.00719202, acc 1\
1591281724: step 988, loss 0.139181, acc 0.954545\
1591281725: step 989, loss 0.00313679, acc 1\
1591281726: step 990, loss 0.0225821, acc 1\
1591281727: step 991, loss 0.00520331, acc 1\
1591281727: step 992, loss 0.187378, acc 0.909091\
1591281728: step 993, loss 0.0139235, acc 1\
1591281729: step 994, loss 0.132761, acc 0.954545\
1591281730: step 995, loss 0.0136988, acc 1\
1591281731: step 996, loss 0.106136, acc 0.954545\
1591281732: step 997, loss 0.00505785, acc 1\
1591281733: step 998, loss 0.545158, acc 0.863636\
1591281734: step 999, loss 0.00278454, acc 1\
1591281735: step 1000, loss 0.0042359, acc 1\
++++++++++++++++++dev++++++++++++++1591281741: step 1000, loss 0.706706, acc 0.816901\
1591281742: step 1001, loss 0.17468, acc 0.954545\
1591281743: step 1002, loss 0.00641821, acc 1\
1591281744: step 1003, loss 0.027445, acc 1\
1591281745: step 1004, loss 0.099464, acc 0.909091\
1591281746: step 1005, loss 0.00495356, acc 1\
1591281746: step 1006, loss 0.0258382, acc 1\
1591281747: step 1007, loss 0.0744268, acc 0.954545\
1591281748: step 1008, loss 0.0054192, acc 1\
1591281749: step 1009, loss 0.0189679, acc 1\
1591281750: step 1010, loss 0.144775, acc 0.954545\
1591281751: step 1011, loss 0.142519, acc 0.954545\
1591281751: step 1012, loss 0.0622719, acc 0.954545\
1591281752: step 1013, loss 0.0204783, acc 1\
1591281753: step 1014, loss 0.193621, acc 0.909091\
1591281754: step 1015, loss 0.195163, acc 0.909091\
1591281755: step 1016, loss 0.139009, acc 0.909091\
1591281756: step 1017, loss 0.10318, acc 0.954545\
1591281756: step 1018, loss 0.0855072, acc 0.954545\
1591281757: step 1019, loss 0.0273009, acc 1\
1591281758: step 1020, loss 0.00237931, acc 1}