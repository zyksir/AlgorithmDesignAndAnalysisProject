{\rtf1\ansi\ansicpg936\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \CocoaLigature0 current epoch 1\
1591268005: step 1, loss 1.59671, acc 0.181818\
1591268006: step 2, loss 3.78476, acc 0.272727\
1591268007: step 3, loss 2.32857, acc 0.181818\
1591268008: step 4, loss 1.74116, acc 0.272727\
1591268009: step 5, loss 1.6324, acc 0.227273\
1591268010: step 6, loss 1.68549, acc 0.181818\
1591268011: step 7, loss 1.6659, acc 0.136364\
1591268011: step 8, loss 1.6235, acc 0.136364\
1591268012: step 9, loss 1.65513, acc 0.181818\
1591268013: step 10, loss 1.61947, acc 0.318182\
1591268014: step 11, loss 1.60555, acc 0.227273\
1591268015: step 12, loss 1.64762, acc 0.318182\
1591268016: step 13, loss 1.56973, acc 0.272727\
1591268017: step 14, loss 1.64242, acc 0.181818\
1591268017: step 15, loss 1.72539, acc 0.227273\
1591268018: step 16, loss 1.55646, acc 0.363636\
1591268019: step 17, loss 1.66881, acc 0.272727\
1591268020: step 18, loss 1.50081, acc 0.363636\
1591268021: step 19, loss 1.64589, acc 0.227273\
1591268022: step 20, loss 1.65279, acc 0.272727\
1591268023: step 21, loss 1.86704, acc 0.0909091\
1591268023: step 22, loss 1.51534, acc 0.318182\
1591268024: step 23, loss 1.50459, acc 0.272727\
1591268025: step 24, loss 1.41192, acc 0.409091\
1591268026: step 25, loss 1.69962, acc 0.363636\
1591268027: step 26, loss 1.56193, acc 0.272727\
1591268028: step 27, loss 1.72871, acc 0.181818\
1591268029: step 28, loss 1.51475, acc 0.363636\
1591268029: step 29, loss 1.4919, acc 0.318182\
1591268030: step 30, loss 1.65366, acc 0.227273\
1591268031: step 31, loss 1.58837, acc 0.454545\
1591268032: step 32, loss 1.59535, acc 0.136364\
1591268033: step 33, loss 1.41317, acc 0.545455\
1591268034: step 34, loss 1.72902, acc 0.227273\
1591268035: step 35, loss 1.59297, acc 0.227273\
1591268035: step 36, loss 1.52241, acc 0.227273\
1591268036: step 37, loss 1.35643, acc 0.409091\
1591268037: step 38, loss 1.50685, acc 0.363636\
1591268038: step 39, loss 1.48003, acc 0.363636\
1591268039: step 40, loss 1.37781, acc 0.363636\
1591268040: step 41, loss 1.49835, acc 0.318182\
1591268041: step 42, loss 1.6873, acc 0.136364\
1591268041: step 43, loss 1.38052, acc 0.409091\
1591268042: step 44, loss 1.46064, acc 0.181818\
1591268043: step 45, loss 1.69348, acc 0.227273\
1591268044: step 46, loss 1.79474, acc 0.227273\
1591268045: step 47, loss 1.60721, acc 0.181818\
1591268046: step 48, loss 1.56877, acc 0.318182\
1591268047: step 49, loss 1.49844, acc 0.5\
1591268047: step 50, loss 1.55202, acc 0.181818\
1591268048: step 51, loss 1.59221, acc 0.318182\
1591268049: step 52, loss 1.45167, acc 0.318182\
1591268050: step 53, loss 1.46299, acc 0.363636\
1591268051: step 54, loss 1.58915, acc 0.363636\
1591268052: step 55, loss 1.75696, acc 0.272727\
1591268053: step 56, loss 1.87029, acc 0.227273\
1591268053: step 57, loss 1.69181, acc 0.272727\
1591268054: step 58, loss 1.58694, acc 0.318182\
1591268055: step 59, loss 1.60986, acc 0.227273\
1591268056: step 60, loss 1.45177, acc 0.363636\
1591268057: step 61, loss 1.38674, acc 0.227273\
1591268058: step 62, loss 1.25465, acc 0.454545\
1591268059: step 63, loss 1.51781, acc 0.318182\
1591268059: step 64, loss 1.52878, acc 0.272727\
1591268060: step 65, loss 1.37988, acc 0.5\
1591268061: step 66, loss 1.54144, acc 0.363636\
1591268062: step 67, loss 1.32118, acc 0.454545\
1591268063: step 68, loss 1.64159, acc 0.181818\
1591268064: step 69, loss 1.45185, acc 0.227273\
1591268065: step 70, loss 1.52295, acc 0.318182\
1591268066: step 71, loss 1.48056, acc 0.272727\
1591268066: step 72, loss 1.50798, acc 0.272727\
1591268067: step 73, loss 1.38872, acc 0.272727\
1591268068: step 74, loss 1.39272, acc 0.363636\
1591268069: step 75, loss 1.71254, acc 0.227273\
1591268070: step 76, loss 1.65936, acc 0.363636\
1591268071: step 77, loss 1.37148, acc 0.454545\
1591268072: step 78, loss 1.49946, acc 0.227273\
1591268072: step 79, loss 1.16821, acc 0.5\
1591268073: step 80, loss 1.49872, acc 0.318182\
1591268074: step 81, loss 1.46589, acc 0.409091\
1591268075: step 82, loss 1.2984, acc 0.545455\
1591268076: step 83, loss 1.35401, acc 0.454545\
1591268077: step 84, loss 1.28199, acc 0.409091\
1591268078: step 85, loss 1.32121, acc 0.545455\
1591268079: step 86, loss 1.5742, acc 0.363636\
1591268079: step 87, loss 1.38674, acc 0.409091\
1591268080: step 88, loss 1.44196, acc 0.363636\
1591268081: step 89, loss 1.26577, acc 0.454545\
1591268082: step 90, loss 1.47441, acc 0.454545\
1591268083: step 91, loss 1.42861, acc 0.454545\
1591268084: step 92, loss 1.32678, acc 0.5\
1591268085: step 93, loss 1.7738, acc 0.318182\
1591268085: step 94, loss 1.53779, acc 0.454545\
1591268086: step 95, loss 1.40937, acc 0.363636\
1591268087: step 96, loss 1.47163, acc 0.363636\
1591268088: step 97, loss 1.30644, acc 0.409091\
1591268089: step 98, loss 1.51587, acc 0.272727\
1591268090: step 99, loss 1.43198, acc 0.409091\
1591268091: step 100, loss 1.35284, acc 0.409091\
++++++++++++++++++dev++++++++++++++1591268099: step 100, loss 1.40588, acc 0.364185\
1591268100: step 101, loss 1.66925, acc 0.272727\
1591268101: step 102, loss 1.31271, acc 0.454545\
1591268102: step 103, loss 1.35768, acc 0.363636\
1591268103: step 104, loss 1.39837, acc 0.454545\
1591268103: step 105, loss 1.24477, acc 0.409091\
1591268104: step 106, loss 1.61769, acc 0.227273\
1591268105: step 107, loss 1.17512, acc 0.5\
1591268106: step 108, loss 1.49289, acc 0.363636\
1591268107: step 109, loss 1.3712, acc 0.318182\
1591268108: step 110, loss 1.339, acc 0.272727\
1591268108: step 111, loss 1.47272, acc 0.318182\
1591268109: step 112, loss 1.41929, acc 0.363636\
1591268110: step 113, loss 1.58702, acc 0.227273\
1591268111: step 114, loss 1.20368, acc 0.409091\
1591268112: step 115, loss 1.15919, acc 0.5\
1591268113: step 116, loss 1.30043, acc 0.454545\
1591268113: step 117, loss 1.51012, acc 0.318182\
1591268114: step 118, loss 1.20921, acc 0.545455\
1591268115: step 119, loss 1.3181, acc 0.5\
1591268116: step 120, loss 1.20354, acc 0.5\
1591268117: step 121, loss 1.42961, acc 0.318182\
1591268118: step 122, loss 1.27672, acc 0.5\
1591268118: step 123, loss 1.27327, acc 0.409091\
1591268119: step 124, loss 1.20893, acc 0.545455\
1591268120: step 125, loss 1.20109, acc 0.454545\
1591268121: step 126, loss 1.26954, acc 0.363636\
1591268122: step 127, loss 1.08894, acc 0.636364\
1591268123: step 128, loss 1.27474, acc 0.454545\
1591268123: step 129, loss 1.24622, acc 0.5\
1591268124: step 130, loss 1.12708, acc 0.681818\
1591268125: step 131, loss 1.07909, acc 0.545455\
1591268126: step 132, loss 1.04181, acc 0.636364\
1591268127: step 133, loss 1.11145, acc 0.590909\
1591268128: step 134, loss 1.01878, acc 0.545455\
1591268129: step 135, loss 1.1042, acc 0.636364\
1591268129: step 136, loss 1.28175, acc 0.409091\
1591268130: step 137, loss 1.25458, acc 0.409091\
1591268131: step 138, loss 1.09997, acc 0.409091\
1591268132: step 139, loss 1.32245, acc 0.454545\
1591268133: step 140, loss 0.930314, acc 0.636364\
1591268134: step 141, loss 1.09927, acc 0.681818\
1591268134: step 142, loss 1.11804, acc 0.409091\
1591268135: step 143, loss 0.892242, acc 0.681818\
1591268136: step 144, loss 1.40094, acc 0.5\
1591268137: step 145, loss 1.0203, acc 0.590909\
1591268138: step 146, loss 1.34283, acc 0.318182\
1591268139: step 147, loss 1.16177, acc 0.454545\
1591268139: step 148, loss 1.10021, acc 0.5\
1591268140: step 149, loss 1.20314, acc 0.409091\
1591268141: step 150, loss 1.05953, acc 0.590909\
1591268142: step 151, loss 1.23293, acc 0.5\
1591268143: step 152, loss 0.806474, acc 0.772727\
1591268144: step 153, loss 1.12049, acc 0.454545\
1591268144: step 154, loss 0.858018, acc 0.681818\
1591268145: step 155, loss 1.30981, acc 0.454545\
1591268146: step 156, loss 0.847369, acc 0.636364\
1591268147: step 157, loss 1.21036, acc 0.5\
1591268148: step 158, loss 1.09936, acc 0.5\
1591268148: step 159, loss 0.945349, acc 0.590909\
1591268149: step 160, loss 1.05926, acc 0.5\
1591268150: step 161, loss 0.937605, acc 0.636364\
1591268151: step 162, loss 1.22908, acc 0.5\
1591268152: step 163, loss 1.1018, acc 0.590909\
1591268153: step 164, loss 1.56473, acc 0.454545\
1591268153: step 165, loss 0.975816, acc 0.590909\
1591268154: step 166, loss 1.10835, acc 0.5\
1591268155: step 167, loss 0.88894, acc 0.636364\
1591268156: step 168, loss 0.950414, acc 0.636364\
1591268157: step 169, loss 1.04081, acc 0.545455\
1591268158: step 170, loss 1.32128, acc 0.318182\
1591268158: step 171, loss 1.14036, acc 0.454545\
1591268159: step 172, loss 0.98685, acc 0.590909\
1591268160: step 173, loss 0.947843, acc 0.545455\
1591268161: step 174, loss 0.89404, acc 0.681818\
1591268162: step 175, loss 1.26297, acc 0.5\
1591268163: step 176, loss 1.04058, acc 0.636364\
1591268163: step 177, loss 0.882243, acc 0.454545\
1591268164: step 178, loss 1.07886, acc 0.409091\
1591268165: step 179, loss 1.32987, acc 0.545455\
1591268166: step 180, loss 0.843905, acc 0.545455\
1591268167: step 181, loss 0.982668, acc 0.636364\
1591268167: step 182, loss 1.03085, acc 0.5\
1591268168: step 183, loss 0.898069, acc 0.590909\
1591268169: step 184, loss 1.01841, acc 0.545455\
1591268170: step 185, loss 1.13762, acc 0.590909\
1591268171: step 186, loss 0.743109, acc 0.772727\
1591268172: step 187, loss 1.02883, acc 0.590909\
1591268172: step 188, loss 1.10257, acc 0.545455\
1591268173: step 189, loss 0.681839, acc 0.636364\
1591268174: step 190, loss 1.04339, acc 0.363636\
1591268175: step 191, loss 1.41355, acc 0.5\
1591268176: step 192, loss 0.909835, acc 0.5\
1591268177: step 193, loss 1.34828, acc 0.5\
1591268177: step 194, loss 1.29321, acc 0.454545\
1591268178: step 195, loss 0.797351, acc 0.727273\
1591268179: step 196, loss 1.02697, acc 0.727273\
1591268180: step 197, loss 1.23373, acc 0.5\
1591268181: step 198, loss 1.05689, acc 0.590909\
1591268181: step 199, loss 0.998369, acc 0.636364\
1591268182: step 200, loss 0.992587, acc 0.409091\
++++++++++++++++++dev++++++++++++++1591268189: step 200, loss 0.862248, acc 0.651911\
1591268190: step 201, loss 1.11403, acc 0.545455\
1591268191: step 202, loss 1.2095, acc 0.5\
1591268191: step 203, loss 0.78096, acc 0.545455\
1591268192: step 204, loss 0.586683, acc 0.785714\
current epoch 2\
1591268193: step 205, loss 0.600583, acc 0.772727\
1591268194: step 206, loss 0.724719, acc 0.636364\
1591268194: step 207, loss 1.12561, acc 0.5\
1591268195: step 208, loss 1.04163, acc 0.590909\
1591268196: step 209, loss 1.28966, acc 0.318182\
1591268197: step 210, loss 0.939991, acc 0.636364\
1591268198: step 211, loss 0.885363, acc 0.5\
1591268198: step 212, loss 0.665099, acc 0.727273\
1591268199: step 213, loss 0.711032, acc 0.727273\
1591268200: step 214, loss 0.827238, acc 0.727273\
1591268201: step 215, loss 0.93582, acc 0.590909\
1591268202: step 216, loss 1.10632, acc 0.545455\
1591268203: step 217, loss 0.781276, acc 0.681818\
1591268203: step 218, loss 0.910218, acc 0.5\
1591268204: step 219, loss 0.84624, acc 0.590909\
1591268205: step 220, loss 0.893988, acc 0.545455\
1591268206: step 221, loss 0.578011, acc 0.818182\
1591268207: step 222, loss 0.859029, acc 0.545455\
1591268208: step 223, loss 0.794095, acc 0.590909\
1591268208: step 224, loss 0.773235, acc 0.636364\
1591268209: step 225, loss 1.22678, acc 0.5\
1591268210: step 226, loss 0.75678, acc 0.681818\
1591268211: step 227, loss 0.688543, acc 0.772727\
1591268212: step 228, loss 0.427937, acc 0.818182\
1591268212: step 229, loss 1.08189, acc 0.636364\
1591268213: step 230, loss 0.680361, acc 0.772727\
1591268214: step 231, loss 0.63612, acc 0.772727\
1591268215: step 232, loss 0.753408, acc 0.681818\
1591268216: step 233, loss 0.552919, acc 0.727273\
1591268217: step 234, loss 0.856198, acc 0.727273\
1591268217: step 235, loss 0.690997, acc 0.636364\
1591268218: step 236, loss 0.854561, acc 0.681818\
1591268219: step 237, loss 0.628917, acc 0.772727\
1591268220: step 238, loss 1.21082, acc 0.681818\
1591268221: step 239, loss 0.964081, acc 0.545455\
1591268222: step 240, loss 0.890121, acc 0.5\
1591268222: step 241, loss 0.809334, acc 0.636364\
1591268223: step 242, loss 0.701627, acc 0.681818\
1591268224: step 243, loss 0.815976, acc 0.772727\
1591268225: step 244, loss 0.891069, acc 0.681818\
1591268226: step 245, loss 0.712633, acc 0.818182\
1591268226: step 246, loss 0.901819, acc 0.590909\
1591268227: step 247, loss 0.758575, acc 0.636364\
1591268228: step 248, loss 0.796749, acc 0.727273\
1591268229: step 249, loss 1.00221, acc 0.636364\
1591268230: step 250, loss 0.928915, acc 0.636364\
1591268231: step 251, loss 0.760993, acc 0.727273\
1591268231: step 252, loss 0.710737, acc 0.772727\
1591268232: step 253, loss 0.939473, acc 0.636364\
1591268233: step 254, loss 0.819613, acc 0.681818\
1591268234: step 255, loss 0.667524, acc 0.772727\
1591268235: step 256, loss 0.761792, acc 0.681818\
1591268235: step 257, loss 0.691347, acc 0.772727\
1591268236: step 258, loss 0.868831, acc 0.636364\
1591268237: step 259, loss 1.08156, acc 0.5\
1591268238: step 260, loss 0.603402, acc 0.818182\
1591268239: step 261, loss 0.816999, acc 0.727273\
1591268240: step 262, loss 0.990746, acc 0.636364\
1591268240: step 263, loss 0.881414, acc 0.636364\
1591268241: step 264, loss 0.949073, acc 0.636364\
1591268242: step 265, loss 0.526928, acc 0.727273\
1591268243: step 266, loss 0.588201, acc 0.818182\
1591268244: step 267, loss 0.462945, acc 0.772727\
1591268245: step 268, loss 0.570845, acc 0.772727\
1591268245: step 269, loss 0.481315, acc 0.818182\
1591268246: step 270, loss 0.572645, acc 0.772727\
1591268247: step 271, loss 0.463672, acc 0.863636\
1591268248: step 272, loss 0.535664, acc 0.863636\
1591268249: step 273, loss 0.666591, acc 0.681818\
1591268249: step 274, loss 0.638619, acc 0.863636\
1591268250: step 275, loss 0.857529, acc 0.772727\
1591268251: step 276, loss 0.761355, acc 0.727273\
1591268252: step 277, loss 0.693686, acc 0.909091\
1591268253: step 278, loss 0.631074, acc 0.727273\
1591268254: step 279, loss 0.810364, acc 0.681818\
1591268254: step 280, loss 0.812108, acc 0.727273\
1591268255: step 281, loss 0.535528, acc 0.818182\
1591268256: step 282, loss 0.645457, acc 0.727273\
1591268257: step 283, loss 0.802181, acc 0.727273\
1591268258: step 284, loss 0.682822, acc 0.727273\
1591268259: step 285, loss 0.759885, acc 0.727273\
1591268259: step 286, loss 0.583077, acc 0.772727\
1591268260: step 287, loss 0.384985, acc 0.909091\
1591268261: step 288, loss 0.538803, acc 0.818182\
1591268262: step 289, loss 0.652818, acc 0.681818\
1591268263: step 290, loss 0.740705, acc 0.727273\
1591268263: step 291, loss 0.582678, acc 0.772727\
1591268264: step 292, loss 0.559009, acc 0.772727\
1591268265: step 293, loss 0.931134, acc 0.681818\
1591268266: step 294, loss 0.763164, acc 0.681818\
1591268267: step 295, loss 0.304358, acc 0.954545\
1591268268: step 296, loss 0.499262, acc 0.772727\
1591268268: step 297, loss 0.947338, acc 0.590909\
1591268269: step 298, loss 0.878735, acc 0.681818\
1591268270: step 299, loss 0.608242, acc 0.727273\
1591268271: step 300, loss 0.879404, acc 0.681818\
++++++++++++++++++dev++++++++++++++1591268277: step 300, loss 0.704282, acc 0.748491\
1591268278: step 301, loss 0.595061, acc 0.818182\
1591268279: step 302, loss 0.518099, acc 0.863636\
1591268280: step 303, loss 0.523741, acc 0.818182\
1591268281: step 304, loss 0.844365, acc 0.681818\
1591268282: step 305, loss 1.16074, acc 0.5\
1591268282: step 306, loss 0.862336, acc 0.727273\
1591268283: step 307, loss 0.943354, acc 0.636364\
1591268284: step 308, loss 0.755706, acc 0.818182\
1591268285: step 309, loss 0.530233, acc 0.818182\
1591268286: step 310, loss 0.836701, acc 0.636364\
1591268287: step 311, loss 0.69753, acc 0.727273\
1591268287: step 312, loss 0.510911, acc 0.818182\
1591268288: step 313, loss 0.539449, acc 0.863636\
1591268289: step 314, loss 0.765907, acc 0.590909\
1591268290: step 315, loss 0.54137, acc 0.863636\
1591268291: step 316, loss 0.437196, acc 0.818182\
1591268291: step 317, loss 0.993675, acc 0.545455\
1591268292: step 318, loss 0.303985, acc 0.954545\
1591268293: step 319, loss 0.700489, acc 0.636364\
1591268294: step 320, loss 0.599964, acc 0.772727\
1591268295: step 321, loss 0.651732, acc 0.681818\
1591268296: step 322, loss 0.373229, acc 0.772727\
1591268296: step 323, loss 0.93471, acc 0.636364\
1591268297: step 324, loss 0.529693, acc 0.772727\
1591268298: step 325, loss 0.936013, acc 0.727273\
1591268299: step 326, loss 0.641877, acc 0.818182\
1591268300: step 327, loss 0.6518, acc 0.727273\
1591268301: step 328, loss 0.660327, acc 0.636364\
1591268301: step 329, loss 0.450505, acc 0.772727\
1591268302: step 330, loss 0.654414, acc 0.772727\
1591268303: step 331, loss 0.462806, acc 0.818182\
1591268304: step 332, loss 0.749694, acc 0.727273\
1591268305: step 333, loss 0.690836, acc 0.772727\
1591268305: step 334, loss 0.543049, acc 0.818182\
1591268306: step 335, loss 0.617718, acc 0.772727\
1591268307: step 336, loss 0.343827, acc 0.863636\
1591268308: step 337, loss 0.343224, acc 0.863636\
1591268309: step 338, loss 0.400388, acc 0.863636\
1591268310: step 339, loss 0.847132, acc 0.681818\
1591268310: step 340, loss 0.975627, acc 0.681818\
1591268311: step 341, loss 0.661247, acc 0.727273\
1591268312: step 342, loss 0.53748, acc 0.818182\
1591268313: step 343, loss 0.611502, acc 0.772727\
1591268314: step 344, loss 0.406089, acc 0.863636\
1591268315: step 345, loss 0.378335, acc 0.863636\
1591268315: step 346, loss 0.636261, acc 0.818182\
1591268316: step 347, loss 0.419378, acc 0.863636\
1591268317: step 348, loss 0.571259, acc 0.727273\
1591268318: step 349, loss 0.282719, acc 0.909091\
1591268319: step 350, loss 0.802211, acc 0.681818\
1591268319: step 351, loss 0.714877, acc 0.818182\
1591268320: step 352, loss 0.660723, acc 0.727273\
1591268321: step 353, loss 0.754741, acc 0.772727\
1591268322: step 354, loss 0.482302, acc 0.818182\
1591268323: step 355, loss 0.515727, acc 0.863636\
1591268324: step 356, loss 0.367823, acc 0.818182\
1591268324: step 357, loss 0.727936, acc 0.772727\
1591268325: step 358, loss 0.652181, acc 0.818182\
1591268326: step 359, loss 0.699251, acc 0.545455\
1591268327: step 360, loss 0.576501, acc 0.727273\
1591268328: step 361, loss 0.503062, acc 0.863636\
1591268329: step 362, loss 0.517097, acc 0.772727\
1591268329: step 363, loss 0.498124, acc 0.818182\
1591268330: step 364, loss 0.393475, acc 0.818182\
1591268331: step 365, loss 0.673556, acc 0.636364\
1591268332: step 366, loss 0.699438, acc 0.772727\
1591268333: step 367, loss 0.310574, acc 0.909091\
1591268334: step 368, loss 0.830776, acc 0.681818\
1591268334: step 369, loss 0.466789, acc 0.818182\
1591268335: step 370, loss 0.407197, acc 0.863636\
1591268336: step 371, loss 0.248246, acc 0.954545\
1591268337: step 372, loss 0.348222, acc 0.863636\
1591268338: step 373, loss 0.671049, acc 0.818182\
1591268338: step 374, loss 0.664983, acc 0.772727\
1591268339: step 375, loss 0.632826, acc 0.772727\
1591268340: step 376, loss 0.547839, acc 0.772727\
1591268341: step 377, loss 0.30073, acc 0.954545\
1591268342: step 378, loss 0.480199, acc 0.818182\
1591268343: step 379, loss 0.779302, acc 0.818182\
1591268343: step 380, loss 0.555041, acc 0.818182\
1591268344: step 381, loss 0.585802, acc 0.863636\
1591268345: step 382, loss 0.790348, acc 0.772727\
1591268346: step 383, loss 0.719891, acc 0.863636\
1591268347: step 384, loss 0.581133, acc 0.772727\
1591268348: step 385, loss 0.252227, acc 0.909091\
1591268348: step 386, loss 0.649814, acc 0.727273\
1591268349: step 387, loss 0.311481, acc 0.909091\
1591268350: step 388, loss 0.454072, acc 0.818182\
1591268351: step 389, loss 0.728003, acc 0.772727\
1591268352: step 390, loss 0.367433, acc 0.863636\
1591268352: step 391, loss 0.403328, acc 0.863636\
1591268353: step 392, loss 0.46175, acc 0.818182\
1591268354: step 393, loss 0.249793, acc 0.954545\
1591268355: step 394, loss 0.724571, acc 0.772727\
1591268356: step 395, loss 0.595874, acc 0.727273\
1591268357: step 396, loss 0.404538, acc 0.772727\
1591268357: step 397, loss 1.00094, acc 0.636364\
1591268358: step 398, loss 0.666112, acc 0.727273\
1591268359: step 399, loss 0.312174, acc 0.909091\
1591268360: step 400, loss 0.545765, acc 0.772727\
++++++++++++++++++dev++++++++++++++1591268367: step 400, loss 0.640079, acc 0.772636\
1591268367: step 401, loss 0.454354, acc 0.818182\
1591268368: step 402, loss 0.341474, acc 0.909091\
1591268369: step 403, loss 0.52778, acc 0.772727\
1591268370: step 404, loss 0.537637, acc 0.727273\
1591268371: step 405, loss 0.463881, acc 0.909091\
1591268372: step 406, loss 0.665229, acc 0.681818\
1591268372: step 407, loss 0.513268, acc 0.772727\
1591268373: step 408, loss 0.143317, acc 1\
current epoch 3\
1591268374: step 409, loss 0.402882, acc 0.772727\
1591268375: step 410, loss 0.400506, acc 0.818182\
1591268375: step 411, loss 0.707791, acc 0.636364\
1591268376: step 412, loss 0.709882, acc 0.681818\
1591268377: step 413, loss 0.446041, acc 0.863636\
1591268378: step 414, loss 0.356038, acc 0.772727\
1591268379: step 415, loss 0.450016, acc 0.772727\
1591268380: step 416, loss 0.217987, acc 0.909091\
1591268380: step 417, loss 0.398929, acc 0.818182\
1591268381: step 418, loss 0.507259, acc 0.818182\
1591268382: step 419, loss 0.462201, acc 0.818182\
1591268383: step 420, loss 0.905087, acc 0.636364\
1591268384: step 421, loss 0.211689, acc 0.954545\
1591268384: step 422, loss 0.277899, acc 0.863636\
1591268385: step 423, loss 0.555298, acc 0.681818\
1591268386: step 424, loss 0.297979, acc 0.909091\
1591268387: step 425, loss 0.234627, acc 0.909091\
1591268388: step 426, loss 0.34871, acc 0.909091\
1591268389: step 427, loss 0.204575, acc 0.909091\
1591268389: step 428, loss 0.250565, acc 0.909091\
1591268390: step 429, loss 0.706461, acc 0.772727\
1591268391: step 430, loss 0.337897, acc 0.954545\
1591268392: step 431, loss 0.223966, acc 0.863636\
1591268393: step 432, loss 0.139298, acc 1\
1591268394: step 433, loss 0.284111, acc 0.818182\
1591268394: step 434, loss 0.274013, acc 0.909091\
1591268395: step 435, loss 0.0890007, acc 1\
1591268396: step 436, loss 0.532463, acc 0.818182\
1591268397: step 437, loss 0.158782, acc 0.954545\
1591268398: step 438, loss 0.354363, acc 0.863636\
1591268399: step 439, loss 0.166818, acc 1\
1591268399: step 440, loss 0.39163, acc 0.909091\
1591268400: step 441, loss 0.231651, acc 0.863636\
1591268401: step 442, loss 0.504815, acc 0.863636\
1591268402: step 443, loss 0.467098, acc 0.772727\
1591268403: step 444, loss 0.327768, acc 0.863636\
1591268403: step 445, loss 0.519584, acc 0.909091\
1591268404: step 446, loss 0.181276, acc 0.909091\
1591268405: step 447, loss 0.417538, acc 0.863636\
1591268406: step 448, loss 0.320132, acc 0.909091\
1591268407: step 449, loss 0.405361, acc 0.909091\
1591268408: step 450, loss 0.562603, acc 0.772727\
1591268408: step 451, loss 0.300801, acc 0.909091\
1591268409: step 452, loss 0.264056, acc 0.909091\
1591268410: step 453, loss 0.419461, acc 0.863636\
1591268411: step 454, loss 0.391918, acc 0.772727\
1591268412: step 455, loss 0.261746, acc 0.954545\
1591268413: step 456, loss 0.148074, acc 1\
1591268413: step 457, loss 0.53064, acc 0.772727\
1591268414: step 458, loss 0.319656, acc 0.863636\
1591268415: step 459, loss 0.201785, acc 0.954545\
1591268416: step 460, loss 0.572382, acc 0.772727\
1591268417: step 461, loss 0.158672, acc 0.909091\
1591268417: step 462, loss 0.410766, acc 0.863636\
1591268418: step 463, loss 0.197874, acc 0.954545\
1591268419: step 464, loss 0.191349, acc 0.954545\
1591268420: step 465, loss 0.457564, acc 0.818182\
1591268421: step 466, loss 0.622637, acc 0.681818\
1591268422: step 467, loss 0.465097, acc 0.863636\
1591268422: step 468, loss 0.452695, acc 0.863636\
1591268423: step 469, loss 0.284266, acc 0.818182\
1591268424: step 470, loss 0.20679, acc 0.909091\
1591268425: step 471, loss 0.379915, acc 0.863636\
1591268426: step 472, loss 0.368712, acc 0.863636\
1591268427: step 473, loss 0.355744, acc 0.863636\
1591268427: step 474, loss 0.174069, acc 0.954545\
1591268428: step 475, loss 0.125674, acc 1\
1591268429: step 476, loss 0.386265, acc 0.772727\
1591268430: step 477, loss 0.323265, acc 0.909091\
1591268431: step 478, loss 0.474849, acc 0.863636\
1591268431: step 479, loss 0.41619, acc 0.909091\
1591268432: step 480, loss 0.364166, acc 0.863636\
1591268433: step 481, loss 0.371675, acc 0.772727\
1591268434: step 482, loss 0.144428, acc 1\
1591268435: step 483, loss 0.453932, acc 0.818182\
1591268436: step 484, loss 0.349897, acc 0.863636\
1591268436: step 485, loss 0.111174, acc 1\
1591268437: step 486, loss 0.275507, acc 0.954545\
1591268438: step 487, loss 0.190652, acc 0.909091\
1591268439: step 488, loss 0.6213, acc 0.727273\
1591268440: step 489, loss 0.153772, acc 0.909091\
1591268441: step 490, loss 0.188128, acc 1\
1591268441: step 491, loss 0.251925, acc 0.863636\
1591268442: step 492, loss 0.11352, acc 0.954545\
1591268443: step 493, loss 0.282181, acc 0.863636\
1591268444: step 494, loss 0.47904, acc 0.818182\
1591268445: step 495, loss 0.0519537, acc 1\
1591268446: step 496, loss 0.171801, acc 0.954545\
1591268446: step 497, loss 0.566396, acc 0.818182\
1591268447: step 498, loss 0.410221, acc 0.818182\
1591268448: step 499, loss 0.116418, acc 0.954545\
1591268449: step 500, loss 0.22707, acc 0.954545\
++++++++++++++++++dev++++++++++++++1591268456: step 500, loss 0.772821, acc 0.760563\
1591268456: step 501, loss 0.542139, acc 0.818182\
1591268457: step 502, loss 0.411732, acc 0.818182\
1591268458: step 503, loss 0.531217, acc 0.818182\
1591268459: step 504, loss 0.0868339, acc 0.954545\
1591268460: step 505, loss 0.481219, acc 0.727273\
1591268460: step 506, loss 0.258642, acc 0.863636\
1591268461: step 507, loss 0.139207, acc 0.954545\
1591268462: step 508, loss 0.267759, acc 0.954545\
1591268463: step 509, loss 0.45167, acc 0.818182\
1591268464: step 510, loss 0.456989, acc 0.727273\
1591268465: step 511, loss 0.32517, acc 0.818182\
1591268465: step 512, loss 0.307417, acc 0.909091\
1591268466: step 513, loss 0.469551, acc 0.818182\
1591268467: step 514, loss 0.621385, acc 0.818182\
1591268468: step 515, loss 0.193359, acc 0.909091\
1591268469: step 516, loss 0.218868, acc 0.954545\
1591268470: step 517, loss 0.176184, acc 0.954545\
1591268470: step 518, loss 0.425297, acc 0.863636\
1591268471: step 519, loss 0.223935, acc 0.909091\
1591268472: step 520, loss 0.213705, acc 0.909091\
1591268473: step 521, loss 1.00216, acc 0.681818\
1591268474: step 522, loss 0.0744948, acc 1\
1591268474: step 523, loss 0.253686, acc 0.909091\
1591268475: step 524, loss 0.191315, acc 0.954545\
1591268476: step 525, loss 0.313408, acc 0.863636\
1591268477: step 526, loss 0.245913, acc 0.909091\
1591268478: step 527, loss 0.689599, acc 0.727273\
1591268479: step 528, loss 0.253084, acc 0.954545\
1591268479: step 529, loss 0.389527, acc 0.818182\
1591268480: step 530, loss 0.223764, acc 0.954545\
1591268481: step 531, loss 0.17441, acc 0.909091\
1591268482: step 532, loss 0.757126, acc 0.681818\
1591268483: step 533, loss 0.149863, acc 1\
1591268484: step 534, loss 0.470447, acc 0.863636\
1591268484: step 535, loss 0.570417, acc 0.772727\
1591268485: step 536, loss 0.185817, acc 0.954545\
1591268486: step 537, loss 0.239826, acc 0.909091\
1591268487: step 538, loss 0.401995, acc 0.818182\
1591268488: step 539, loss 0.343076, acc 0.863636\
1591268488: step 540, loss 0.222871, acc 0.909091\
1591268489: step 541, loss 0.111997, acc 0.954545\
1591268490: step 542, loss 0.14344, acc 0.954545\
1591268491: step 543, loss 0.358627, acc 0.818182\
1591268492: step 544, loss 0.189118, acc 0.863636\
1591268493: step 545, loss 0.274981, acc 0.863636\
1591268493: step 546, loss 0.254065, acc 0.909091\
1591268494: step 547, loss 0.214685, acc 0.909091\
1591268495: step 548, loss 0.165681, acc 0.909091\
1591268496: step 549, loss 0.212925, acc 0.909091\
1591268497: step 550, loss 0.167182, acc 0.909091\
1591268498: step 551, loss 0.0852323, acc 0.954545\
1591268498: step 552, loss 0.367546, acc 0.863636\
1591268499: step 553, loss 0.0904815, acc 1\
1591268500: step 554, loss 0.362836, acc 0.863636\
1591268501: step 555, loss 0.0970955, acc 1\
1591268502: step 556, loss 0.473509, acc 0.863636\
1591268503: step 557, loss 0.292104, acc 0.863636\
1591268503: step 558, loss 0.169428, acc 0.954545\
1591268504: step 559, loss 0.144297, acc 0.954545\
1591268505: step 560, loss 0.12869, acc 0.909091\
1591268506: step 561, loss 0.489951, acc 0.818182\
1591268507: step 562, loss 0.268648, acc 0.863636\
1591268508: step 563, loss 0.336212, acc 0.818182\
1591268508: step 564, loss 0.280143, acc 0.909091\
1591268509: step 565, loss 0.242875, acc 0.863636\
1591268510: step 566, loss 0.0618012, acc 1\
1591268511: step 567, loss 0.0725059, acc 1\
1591268512: step 568, loss 0.166229, acc 0.909091\
1591268512: step 569, loss 0.506343, acc 0.772727\
1591268513: step 570, loss 0.182261, acc 0.909091\
1591268514: step 571, loss 0.102685, acc 1\
1591268515: step 572, loss 0.261254, acc 0.909091\
1591268516: step 573, loss 0.210193, acc 0.909091\
1591268517: step 574, loss 0.109445, acc 0.954545\
1591268517: step 575, loss 0.0615018, acc 1\
1591268518: step 576, loss 0.113694, acc 0.909091\
1591268519: step 577, loss 0.301645, acc 0.909091\
1591268520: step 578, loss 0.414462, acc 0.818182\
1591268521: step 579, loss 0.202044, acc 0.909091\
1591268522: step 580, loss 0.372984, acc 0.818182\
1591268522: step 581, loss 0.073598, acc 0.954545\
1591268523: step 582, loss 0.229305, acc 0.954545\
1591268524: step 583, loss 0.434848, acc 0.909091\
1591268525: step 584, loss 0.548556, acc 0.772727\
1591268526: step 585, loss 0.169314, acc 0.909091\
1591268527: step 586, loss 0.449356, acc 0.818182\
1591268527: step 587, loss 0.151782, acc 0.954545\
1591268528: step 588, loss 0.25455, acc 0.863636\
1591268529: step 589, loss 0.0908167, acc 0.954545\
1591268530: step 590, loss 0.500146, acc 0.818182\
1591268531: step 591, loss 0.0558336, acc 1\
1591268531: step 592, loss 0.203544, acc 0.909091\
1591268532: step 593, loss 0.543931, acc 0.863636\
1591268533: step 594, loss 0.177205, acc 0.954545\
1591268534: step 595, loss 0.101968, acc 1\
1591268535: step 596, loss 0.0988192, acc 0.954545\
1591268536: step 597, loss 0.234814, acc 0.909091\
1591268536: step 598, loss 0.189724, acc 0.909091\
1591268537: step 599, loss 0.291448, acc 0.818182\
1591268538: step 600, loss 0.201732, acc 0.909091\
++++++++++++++++++dev++++++++++++++1591268545: step 600, loss 0.680364, acc 0.780684\
1591268546: step 601, loss 0.341951, acc 0.863636\
1591268546: step 602, loss 0.15133, acc 0.954545\
1591268547: step 603, loss 0.176645, acc 0.909091\
1591268548: step 604, loss 0.116411, acc 1\
1591268549: step 605, loss 0.155389, acc 0.954545\
1591268550: step 606, loss 0.248116, acc 0.954545\
1591268551: step 607, loss 0.320089, acc 0.909091\
1591268551: step 608, loss 0.218078, acc 0.909091\
1591268552: step 609, loss 0.189228, acc 0.909091\
1591268553: step 610, loss 0.314441, acc 0.818182\
1591268554: step 611, loss 0.263777, acc 0.863636\
1591268554: step 612, loss 0.0334269, acc 1\
current epoch 4\
1591268555: step 613, loss 0.574981, acc 0.818182\
1591268556: step 614, loss 0.0760827, acc 1\
1591268557: step 615, loss 0.0864067, acc 1\
1591268558: step 616, loss 0.50092, acc 0.727273\
1591268559: step 617, loss 0.0988594, acc 0.954545\
1591268559: step 618, loss 0.147551, acc 0.909091\
1591268560: step 619, loss 0.036914, acc 1\
1591268561: step 620, loss 0.081635, acc 0.954545\
1591268562: step 621, loss 0.166728, acc 0.909091\
1591268563: step 622, loss 0.307346, acc 0.863636\
1591268564: step 623, loss 0.388212, acc 0.863636\
1591268565: step 624, loss 0.361468, acc 0.863636\
1591268566: step 625, loss 0.0939728, acc 0.954545\
1591268567: step 626, loss 0.0982406, acc 0.954545\
1591268567: step 627, loss 0.0573879, acc 1\
1591268568: step 628, loss 0.0995969, acc 0.954545\
1591268569: step 629, loss 0.0977479, acc 0.954545\
1591268570: step 630, loss 0.174596, acc 0.954545\
1591268571: step 631, loss 0.117365, acc 0.909091\
1591268572: step 632, loss 0.160901, acc 0.909091\
1591268572: step 633, loss 0.0856057, acc 1\
1591268573: step 634, loss 0.073441, acc 0.954545\
1591268574: step 635, loss 0.152273, acc 0.909091\
1591268575: step 636, loss 0.0863815, acc 0.954545\
1591268576: step 637, loss 0.259125, acc 0.909091\
1591268577: step 638, loss 0.2399, acc 0.909091\
1591268577: step 639, loss 0.125139, acc 0.909091\
1591268578: step 640, loss 0.180931, acc 0.954545\
1591268579: step 641, loss 0.0149603, acc 1\
1591268580: step 642, loss 0.258848, acc 0.909091\
1591268581: step 643, loss 0.0245169, acc 1\
1591268582: step 644, loss 0.105553, acc 0.954545\
1591268582: step 645, loss 0.216182, acc 0.954545\
1591268583: step 646, loss 0.387405, acc 0.863636\
1591268584: step 647, loss 0.143838, acc 0.909091\
1591268585: step 648, loss 0.347193, acc 0.863636\
1591268586: step 649, loss 0.321435, acc 0.909091\
1591268587: step 650, loss 0.0429853, acc 1\
1591268587: step 651, loss 0.446106, acc 0.863636\
1591268588: step 652, loss 0.268514, acc 0.863636\
1591268589: step 653, loss 0.479415, acc 0.818182\
1591268590: step 654, loss 0.239306, acc 0.909091\
1591268591: step 655, loss 0.0476267, acc 1\
1591268592: step 656, loss 0.0682919, acc 1\
1591268592: step 657, loss 0.367987, acc 0.909091\
1591268593: step 658, loss 0.140815, acc 0.954545\
1591268594: step 659, loss 0.0754539, acc 1\
1591268595: step 660, loss 0.171078, acc 0.954545\
1591268596: step 661, loss 0.260854, acc 0.909091\
1591268597: step 662, loss 0.211998, acc 0.909091\
1591268597: step 663, loss 0.23059, acc 0.909091\
1591268598: step 664, loss 0.304094, acc 0.863636\
1591268599: step 665, loss 0.115798, acc 0.954545\
1591268600: step 666, loss 0.0189062, acc 1\
1591268601: step 667, loss 0.168954, acc 0.954545\
1591268602: step 668, loss 0.0746423, acc 1\
1591268602: step 669, loss 0.308902, acc 0.863636\
1591268603: step 670, loss 0.119948, acc 0.954545\
1591268604: step 671, loss 0.214326, acc 0.954545\
1591268605: step 672, loss 0.17378, acc 0.954545\
1591268606: step 673, loss 0.0804231, acc 1\
1591268607: step 674, loss 0.0682976, acc 1\
1591268607: step 675, loss 0.0164151, acc 1\
1591268608: step 676, loss 0.361887, acc 0.818182\
1591268609: step 677, loss 0.130986, acc 0.954545\
1591268610: step 678, loss 0.0393768, acc 1\
1591268611: step 679, loss 0.0802533, acc 1\
1591268612: step 680, loss 0.203779, acc 0.909091\
1591268612: step 681, loss 0.285284, acc 0.954545\
1591268613: step 682, loss 0.2933, acc 0.909091\
1591268614: step 683, loss 0.0841422, acc 0.954545\
1591268615: step 684, loss 0.0525141, acc 1\
1591268616: step 685, loss 0.0396751, acc 1\
1591268617: step 686, loss 0.0506971, acc 1\
1591268617: step 687, loss 0.229007, acc 0.909091\
1591268618: step 688, loss 0.388552, acc 0.909091\
1591268619: step 689, loss 0.0637879, acc 1\
1591268620: step 690, loss 0.439264, acc 0.818182\
1591268621: step 691, loss 0.120045, acc 1\
1591268622: step 692, loss 0.349071, acc 0.863636\
1591268622: step 693, loss 0.178565, acc 0.863636\
1591268623: step 694, loss 0.0722411, acc 0.954545\
1591268624: step 695, loss 0.079342, acc 1\
1591268625: step 696, loss 0.106688, acc 0.954545\
1591268626: step 697, loss 0.250695, acc 0.909091\
1591268627: step 698, loss 0.306069, acc 0.863636\
1591268627: step 699, loss 0.104663, acc 0.954545\
1591268628: step 700, loss 0.182956, acc 0.909091\
++++++++++++++++++dev++++++++++++++1591268635: step 700, loss 0.73457, acc 0.790744\
1591268636: step 701, loss 0.334575, acc 0.909091\
1591268637: step 702, loss 0.721215, acc 0.863636\
1591268638: step 703, loss 0.0036091, acc 1\
1591268638: step 704, loss 0.0347049, acc 1\
1591268639: step 705, loss 0.288137, acc 0.909091\
1591268640: step 706, loss 0.167778, acc 0.954545\
1591268641: step 707, loss 0.10994, acc 0.954545\
1591268642: step 708, loss 0.0882932, acc 0.954545\
1591268643: step 709, loss 0.255077, acc 0.909091\
1591268643: step 710, loss 0.157895, acc 0.909091\
1591268644: step 711, loss 0.0551897, acc 1\
1591268645: step 712, loss 0.153152, acc 0.954545\
1591268646: step 713, loss 0.299509, acc 0.863636\
1591268647: step 714, loss 0.0933419, acc 1\
1591268648: step 715, loss 0.149445, acc 0.954545\
1591268648: step 716, loss 0.154038, acc 0.954545\
1591268649: step 717, loss 0.358473, acc 0.863636\
1591268650: step 718, loss 0.250431, acc 0.909091\
1591268651: step 719, loss 0.188399, acc 0.909091\
1591268652: step 720, loss 0.117317, acc 0.954545\
1591268653: step 721, loss 0.184563, acc 0.909091\
1591268653: step 722, loss 0.250126, acc 0.863636\
1591268654: step 723, loss 0.0712462, acc 1\
1591268655: step 724, loss 0.179312, acc 0.909091\
1591268656: step 725, loss 0.170979, acc 0.909091\
1591268657: step 726, loss 0.0322441, acc 1\
1591268658: step 727, loss 0.0706707, acc 1\
1591268659: step 728, loss 0.149563, acc 0.909091\
1591268659: step 729, loss 0.34243, acc 0.818182\
1591268660: step 730, loss 0.0371934, acc 1\
1591268661: step 731, loss 0.198832, acc 0.954545\
1591268662: step 732, loss 0.19883, acc 0.909091\
1591268663: step 733, loss 0.253594, acc 0.909091\
1591268664: step 734, loss 0.279875, acc 0.954545\
1591268664: step 735, loss 0.0198319, acc 1\
1591268665: step 736, loss 0.375362, acc 0.818182\
1591268666: step 737, loss 0.0150167, acc 1\
1591268667: step 738, loss 0.309031, acc 0.909091\
1591268668: step 739, loss 0.3238, acc 0.909091\
1591268669: step 740, loss 0.492335, acc 0.909091\
1591268669: step 741, loss 0.186126, acc 0.909091\
1591268670: step 742, loss 0.0957231, acc 0.954545\
1591268671: step 743, loss 0.0769873, acc 1\
1591268672: step 744, loss 0.198517, acc 0.954545\
1591268673: step 745, loss 0.0884839, acc 0.954545\
1591268674: step 746, loss 0.395443, acc 0.909091\
1591268675: step 747, loss 0.124866, acc 0.909091\
1591268675: step 748, loss 0.193274, acc 0.909091\
1591268676: step 749, loss 0.394471, acc 0.818182\
1591268677: step 750, loss 0.157771, acc 0.954545\
1591268678: step 751, loss 0.128276, acc 0.954545\
1591268679: step 752, loss 0.0953342, acc 1\
1591268680: step 753, loss 0.082302, acc 0.954545\
1591268680: step 754, loss 0.243334, acc 0.909091\
1591268681: step 755, loss 0.0345696, acc 1\
1591268682: step 756, loss 0.274032, acc 0.863636\
1591268683: step 757, loss 0.0204016, acc 1\
1591268684: step 758, loss 0.409826, acc 0.772727\
1591268685: step 759, loss 0.304029, acc 0.954545\
1591268685: step 760, loss 0.406242, acc 0.863636\
1591268686: step 761, loss 0.196575, acc 0.909091\
1591268687: step 762, loss 0.117856, acc 0.954545\
1591268688: step 763, loss 0.0613816, acc 1\
1591268689: step 764, loss 0.0293573, acc 1\
1591268690: step 765, loss 0.137207, acc 0.954545\
1591268691: step 766, loss 0.0956839, acc 1\
1591268691: step 767, loss 0.254321, acc 0.863636\
1591268700: step 768, loss 0.124165, acc 0.954545\
1591268701: step 769, loss 0.254595, acc 0.863636\
1591268702: step 770, loss 0.0407467, acc 1\
1591268703: step 771, loss 0.0238026, acc 1\
1591268704: step 772, loss 0.118906, acc 0.954545\
 1591268705: step 773, loss 0.0997313, acc 0.954545\
1591268706: step 774, loss 0.081645, acc 1\
1591268707: step 775, loss 0.00578399, acc 1\
1591268708: step 776, loss 0.0810095, acc 0.954545\
1591268709: step 777, loss 0.047257, acc 1\
1591268710: step 778, loss 0.239754, acc 0.954545\
1591268710: step 779, loss 0.0346758, acc 1\
1591268711: step 780, loss 0.0833563, acc 0.954545\
1591268712: step 781, loss 0.196277, acc 0.954545\
1591268713: step 782, loss 0.0478889, acc 1\
1591268714: step 783, loss 0.0174675, acc 1\
1591268715: step 784, loss 0.271354, acc 0.818182\
1591268716: step 785, loss 0.0252066, acc 1\
1591268717: step 786, loss 0.03348, acc 1\
1591268718: step 787, loss 0.236749, acc 0.863636\
1591268719: step 788, loss 0.25521, acc 0.909091\
1591268720: step 789, loss 0.144595, acc 0.909091\
1591268721: step 790, loss 0.138332, acc 0.954545\
1591268722: step 791, loss 0.0454842, acc 1\
1591268723: step 792, loss 0.0995231, acc 0.954545\
1591268724: step 793, loss 0.0509636, acc 1\
1591268725: step 794, loss 0.83176, acc 0.772727\
1591268726: step 795, loss 0.0251555, acc 1\
1591268727: step 796, loss 0.216176, acc 0.909091\
1591268728: step 797, loss 0.456992, acc 0.909091\
1591268729: step 798, loss 0.0548609, acc 0.954545\
1591268730: step 799, loss 0.105085, acc 0.909091\
1591268731: step 800, loss 0.0729281, acc 1\
++++++++++++++++++dev++++++++++++++1591268740: step 800, loss 0.65705, acc 0.802817\
1591268740: step 801, loss 0.151578, acc 0.909091\
1591268741: step 802, loss 0.226982, acc 0.863636\
1591268742: step 803, loss 0.0641061, acc 1\
1591268743: step 804, loss 0.0615703, acc 1\
1591268744: step 805, loss 0.161454, acc 0.954545\
1591268745: step 806, loss 0.0824197, acc 0.954545\
1591268746: step 807, loss 0.0282497, acc 1\
1591268747: step 808, loss 0.0876052, acc 1\
1591268748: step 809, loss 0.213175, acc 0.954545\
1591268749: step 810, loss 0.165796, acc 0.954545\
1591268750: step 811, loss 0.201508, acc 0.909091\
1591268750: step 812, loss 0.154391, acc 0.909091\
1591268751: step 813, loss 0.102843, acc 0.954545\
1591268752: step 814, loss 0.315689, acc 0.863636\
1591268753: step 815, loss 0.0390087, acc 1\
1591268754: step 816, loss 0.052245, acc 1\
current epoch 5\
1591268755: step 817, loss 0.215199, acc 0.909091\
1591268756: step 818, loss 0.0423613, acc 1\
1591268757: step 819, loss 0.109602, acc 0.954545\
1591268757: step 820, loss 0.132862, acc 1\
1591268758: step 821, loss 0.0705548, acc 1\
1591268759: step 822, loss 0.194579, acc 0.863636\
1591268760: step 823, loss 0.404468, acc 0.863636\
1591268761: step 824, loss 0.0859946, acc 0.954545\
1591268762: step 825, loss 0.109451, acc 0.954545\
1591268763: step 826, loss 0.188794, acc 0.909091\
1591268764: step 827, loss 0.11035, acc 0.954545\
1591268765: step 828, loss 0.252294, acc 0.909091\
1591268766: step 829, loss 0.078369, acc 1\
1591268766: step 830, loss 0.101924, acc 0.954545\
1591268767: step 831, loss 0.168133, acc 0.909091\
1591268768: step 832, loss 0.0722866, acc 0.954545\
1591268769: step 833, loss 0.120723, acc 0.954545\
1591268770: step 834, loss 0.172341, acc 0.954545\
1591268771: step 835, loss 0.12339, acc 0.909091\
1591268772: step 836, loss 0.122093, acc 0.909091\
1591268773: step 837, loss 0.0360847, acc 1\
1591268774: step 838, loss 0.00570121, acc 1\
1591268775: step 839, loss 0.162351, acc 0.909091\
1591268775: step 840, loss 0.073015, acc 0.954545\
1591268776: step 841, loss 0.0321371, acc 1\
1591268777: step 842, loss 0.0727889, acc 0.954545\
1591268778: step 843, loss 0.0900452, acc 0.954545\
1591268779: step 844, loss 0.0153908, acc 1\
1591268780: step 845, loss 0.0332186, acc 1\
1591268781: step 846, loss 0.0638793, acc 0.954545\
1591268782: step 847, loss 0.00842808, acc 1\
1591268783: step 848, loss 0.1615, acc 0.909091\
1591268783: step 849, loss 0.222635, acc 0.909091\
1591268784: step 850, loss 0.221888, acc 0.909091\
1591268785: step 851, loss 0.0588775, acc 0.954545\
1591268786: step 852, loss 0.0895526, acc 0.954545\
1591268787: step 853, loss 0.173313, acc 0.954545\
1591268788: step 854, loss 0.258231, acc 0.909091\
1591268789: step 855, loss 0.217492, acc 0.863636\
1591268790: step 856, loss 0.167953, acc 0.909091\
1591268790: step 857, loss 0.255303, acc 0.954545\
1591268791: step 858, loss 0.275648, acc 0.954545\
1591268792: step 859, loss 0.0391284, acc 1\
1591268793: step 860, loss 0.139628, acc 0.954545\
1591268794: step 861, loss 0.208151, acc 0.954545\
1591268795: step 862, loss 0.218623, acc 0.909091\
1591268796: step 863, loss 0.047828, acc 1\
1591268797: step 864, loss 0.0630353, acc 1\
1591268798: step 865, loss 0.392266, acc 0.818182\
1591268799: step 866, loss 0.0973002, acc 0.954545\
1591268800: step 867, loss 0.102173, acc 0.954545\
1591268801: step 868, loss 0.29327, acc 0.863636\
1591268802: step 869, loss 0.0486449, acc 1\
1591268803: step 870, loss 0.0537505, acc 1\
1591268803: step 871, loss 0.102403, acc 0.954545\
1591268804: step 872, loss 0.0230962, acc 1\
1591268805: step 873, loss 0.44491, acc 0.863636\
1591268806: step 874, loss 0.0175765, acc 1\
1591268807: step 875, loss 0.168854, acc 0.954545\
1591268808: step 876, loss 0.154246, acc 0.954545\
1591268809: step 877, loss 0.0730038, acc 0.954545\
1591268810: step 878, loss 0.0761733, acc 1\
1591268811: step 879, loss 0.0942984, acc 1\
1591268812: step 880, loss 0.203368, acc 0.909091\
1591268813: step 881, loss 0.134866, acc 0.954545\
1591268814: step 882, loss 0.0630597, acc 1\
1591268815: step 883, loss 0.230488, acc 0.954545\
1591268816: step 884, loss 0.2551, acc 0.863636\
1591268816: step 885, loss 0.0214354, acc 1\
1591268817: step 886, loss 0.279448, acc 0.954545\
1591268818: step 887, loss 0.0878014, acc 0.954545\
1591268819: step 888, loss 0.0408963, acc 1\
1591268820: step 889, loss 0.0285698, acc 1\
1591268821: step 890, loss 0.114801, acc 0.954545\
1591268822: step 891, loss 0.134261, acc 0.954545\
1591268822: step 892, loss 0.220077, acc 0.954545\
1591268823: step 893, loss 0.00658206, acc 1\
1591268824: step 894, loss 0.248286, acc 0.909091\
1591268825: step 895, loss 0.0945373, acc 0.954545\
1591268826: step 896, loss 0.212394, acc 0.909091\
1591268827: step 897, loss 0.022776, acc 1\
1591268828: step 898, loss 0.0507046, acc 1\
1591268829: step 899, loss 0.0832656, acc 0.954545\
1591268830: step 900, loss 0.0480953, acc 0.954545\
++++++++++++++++++dev++++++++++++++1591268837: step 900, loss 0.717741, acc 0.812877\
1591268838: step 901, loss 0.170249, acc 0.909091\
1591268839: step 902, loss 0.263467, acc 0.863636\
1591268840: step 903, loss 0.00877097, acc 1\
1591268841: step 904, loss 0.013277, acc 1\
1591268841: step 905, loss 0.0541083, acc 0.954545\
1591268842: step 906, loss 0.199353, acc 0.909091\
1591268843: step 907, loss 0.00440372, acc 1\
1591268844: step 908, loss 0.0316798, acc 1\
1591268845: step 909, loss 0.0454809, acc 1\
1591268846: step 910, loss 0.387827, acc 0.909091\
1591268847: step 911, loss 0.0777156, acc 1\
1591268848: step 912, loss 0.0264108, acc 1\
1591268848: step 913, loss 0.156631, acc 0.909091\
1591268849: step 914, loss 0.00598244, acc 1\
1591268850: step 915, loss 0.0453216, acc 1\
1591268851: step 916, loss 0.15573, acc 0.954545\
1591268852: step 917, loss 0.238805, acc 0.863636\
1591268853: step 918, loss 0.125427, acc 0.909091\
1591268854: step 919, loss 0.0736579, acc 0.954545\
1591268855: step 920, loss 0.179525, acc 0.954545\
1591268856: step 921, loss 0.0660976, acc 1\
1591268857: step 922, loss 0.0556656, acc 1\
1591268857: step 923, loss 0.0742132, acc 1\
1591268858: step 924, loss 0.105431, acc 0.954545\
1591268859: step 925, loss 0.00309505, acc 1\
1591268860: step 926, loss 0.163946, acc 0.954545\
1591268861: step 927, loss 0.0440693, acc 1\
1591268862: step 928, loss 0.0860209, acc 0.954545\
1591268863: step 929, loss 0.370946, acc 0.909091\
1591268864: step 930, loss 0.00335966, acc 1\
1591268864: step 931, loss 0.0474648, acc 1\
1591268865: step 932, loss 0.106658, acc 0.954545\
1591268866: step 933, loss 0.198274, acc 0.909091\
1591268867: step 934, loss 0.00251926, acc 1\
1591268868: step 935, loss 0.168173, acc 0.909091\
1591268869: step 936, loss 0.104492, acc 0.954545\
1591268870: step 937, loss 0.0540757, acc 1\
1591268871: step 938, loss 0.19247, acc 0.954545\
1591268871: step 939, loss 0.0156331, acc 1\
1591268872: step 940, loss 0.171795, acc 0.909091\
1591268873: step 941, loss 0.0336426, acc 1\
1591268874: step 942, loss 0.445234, acc 0.954545\
1591268875: step 943, loss 0.0218789, acc 1\
1591268876: step 944, loss 0.0863934, acc 0.954545\
1591268877: step 945, loss 0.2802, acc 0.909091\
1591268878: step 946, loss 0.0941303, acc 0.909091\
1591268879: step 947, loss 0.214884, acc 0.954545\
1591268880: step 948, loss 0.178467, acc 0.909091\
1591268881: step 949, loss 0.0815803, acc 0.954545\
1591268881: step 950, loss 0.0485724, acc 0.954545\
1591268882: step 951, loss 0.185477, acc 0.909091\
1591268883: step 952, loss 0.238247, acc 0.863636\
1591268884: step 953, loss 0.40572, acc 0.772727\
1591268885: step 954, loss 0.107696, acc 0.954545\
1591268886: step 955, loss 0.0831961, acc 0.954545\
1591268887: step 956, loss 0.074361, acc 0.954545\
1591268887: step 957, loss 0.0944108, acc 0.954545\
1591268888: step 958, loss 0.0657955, acc 1\
1591268889: step 959, loss 0.0108627, acc 1\
1591268890: step 960, loss 0.0715887, acc 0.954545\
1591268891: step 961, loss 0.0275486, acc 1\
1591268892: step 962, loss 0.0689397, acc 0.954545\
1591268893: step 963, loss 0.093057, acc 0.954545\
1591268893: step 964, loss 0.173437, acc 0.909091\
1591268894: step 965, loss 0.161841, acc 0.909091\
1591268895: step 966, loss 0.0121273, acc 1\
1591268896: step 967, loss 0.0163045, acc 1\
1591268897: step 968, loss 0.0254821, acc 1\
1591268898: step 969, loss 0.00675978, acc 1\
1591268899: step 970, loss 0.111941, acc 0.954545\
1591268899: step 971, loss 0.118902, acc 1\
1591268900: step 972, loss 0.063123, acc 0.954545\
1591268901: step 973, loss 0.00976998, acc 1\
1591268902: step 974, loss 0.0149947, acc 1\
1591268903: step 975, loss 0.00410515, acc 1\
1591268904: step 976, loss 0.0482311, acc 1\
1591268905: step 977, loss 0.0263587, acc 1\
1591268906: step 978, loss 0.022551, acc 1\
1591268906: step 979, loss 0.0036965, acc 1\
1591268907: step 980, loss 0.171909, acc 0.909091\
1591268908: step 981, loss 0.0190053, acc 1\
1591268909: step 982, loss 0.00862493, acc 1\
1591268910: step 983, loss 0.019764, acc 1\
1591268911: step 984, loss 0.0859793, acc 0.954545\
1591268911: step 985, loss 0.154541, acc 0.954545\
1591268912: step 986, loss 0.0813932, acc 0.954545\
1591268913: step 987, loss 0.0154355, acc 1\
1591268914: step 988, loss 0.135469, acc 0.954545\
1591268915: step 989, loss 0.0508908, acc 0.954545\
1591268916: step 990, loss 0.0423308, acc 0.954545\
1591268917: step 991, loss 0.133492, acc 0.909091\
1591268917: step 992, loss 0.18917, acc 0.909091\
1591268918: step 993, loss 0.0647574, acc 0.954545\
1591268919: step 994, loss 0.170858, acc 0.954545\
1591268920: step 995, loss 0.0273213, acc 1\
1591268921: step 996, loss 0.252965, acc 0.909091\
1591268922: step 997, loss 0.0134057, acc 1\
1591268923: step 998, loss 0.429692, acc 0.863636\
1591268923: step 999, loss 0.00769566, acc 1\
1591268924: step 1000, loss 0.117763, acc 0.909091\
++++++++++++++++++dev++++++++++++++1591268931: step 1000, loss 0.862573, acc 0.788732}