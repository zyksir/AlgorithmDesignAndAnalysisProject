{\rtf1\ansi\ansicpg936\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \CocoaLigature0 current epoch 1\
1591276148: step 1, loss 4.06229, acc 0.272727\
1591276149: step 2, loss 27.9584, acc 0.0454545\
1591276150: step 3, loss 21.5223, acc 0.227273\
1591276151: step 4, loss 10.9651, acc 0.318182\
1591276151: step 5, loss 10.4153, acc 0.227273\
1591276152: step 6, loss 5.46306, acc 0.136364\
1591276153: step 7, loss 4.46299, acc 0.181818\
1591276154: step 8, loss 2.86539, acc 0.272727\
1591276155: step 9, loss 5.89872, acc 0.272727\
1591276156: step 10, loss 4.19185, acc 0.227273\
1591276157: step 11, loss 3.63221, acc 0.181818\
1591276157: step 12, loss 3.77994, acc 0.227273\
1591276158: step 13, loss 2.46905, acc 0.272727\
1591276159: step 14, loss 2.25724, acc 0.227273\
1591276160: step 15, loss 3.32473, acc 0.136364\
1591276161: step 16, loss 3.15847, acc 0.136364\
1591276162: step 17, loss 2.29883, acc 0.181818\
1591276162: step 18, loss 2.60107, acc 0.227273\
1591276163: step 19, loss 2.0282, acc 0.318182\
1591276164: step 20, loss 2.23742, acc 0.136364\
1591276165: step 21, loss 1.65458, acc 0.318182\
1591276166: step 22, loss 2.40417, acc 0.272727\
1591276167: step 23, loss 2.49959, acc 0.181818\
1591276168: step 24, loss 2.65293, acc 0.181818\
1591276168: step 25, loss 1.94814, acc 0.363636\
1591276169: step 26, loss 1.76585, acc 0.272727\
1591276170: step 27, loss 1.58387, acc 0.318182\
1591276171: step 28, loss 2.34378, acc 0.227273\
1591276172: step 29, loss 2.70553, acc 0.136364\
1591276173: step 30, loss 2.19248, acc 0.227273\
1591276174: step 31, loss 1.9917, acc 0.227273\
1591276174: step 32, loss 1.96369, acc 0.136364\
1591276175: step 33, loss 1.76351, acc 0.181818\
1591276176: step 34, loss 2.21569, acc 0.136364\
1591276177: step 35, loss 2.10005, acc 0.136364\
1591276178: step 36, loss 1.7024, acc 0.272727\
1591276179: step 37, loss 1.70103, acc 0.227273\
1591276180: step 38, loss 1.89197, acc 0.181818\
1591276180: step 39, loss 1.8411, acc 0.227273\
1591276181: step 40, loss 1.63766, acc 0.227273\
1591276182: step 41, loss 1.73895, acc 0.181818\
1591276183: step 42, loss 1.92934, acc 0.136364\
1591276184: step 43, loss 2.23717, acc 0.181818\
1591276185: step 44, loss 1.70703, acc 0.227273\
1591276186: step 45, loss 1.61497, acc 0.318182\
1591276186: step 46, loss 2.5742, acc 0.181818\
1591276187: step 47, loss 2.20796, acc 0.227273\
1591276188: step 48, loss 1.87286, acc 0.136364\
1591276189: step 49, loss 1.87258, acc 0.181818\
1591276190: step 50, loss 1.9368, acc 0.272727\
1591276191: step 51, loss 2.54767, acc 0.272727\
1591276192: step 52, loss 2.37641, acc 0.181818\
1591276192: step 53, loss 1.8806, acc 0.227273\
1591276193: step 54, loss 1.73319, acc 0.181818\
1591276194: step 55, loss 1.92896, acc 0.227273\
1591276195: step 56, loss 2.16026, acc 0.227273\
1591276196: step 57, loss 2.08101, acc 0.136364\
1591276197: step 58, loss 1.64701, acc 0.181818\
1591276198: step 59, loss 1.84324, acc 0.227273\
1591276198: step 60, loss 2.09423, acc 0.227273\
1591276199: step 61, loss 2.02617, acc 0.181818\
1591276200: step 62, loss 2.03552, acc 0.136364\
1591276201: step 63, loss 2.32543, acc 0.0909091\
1591276202: step 64, loss 1.94175, acc 0.0909091\
1591276203: step 65, loss 1.68355, acc 0.136364\
1591276204: step 66, loss 1.80049, acc 0.136364\
1591276205: step 67, loss 1.65631, acc 0.272727\
1591276206: step 68, loss 1.89371, acc 0.227273\
1591276206: step 69, loss 1.63224, acc 0.227273\
1591276207: step 70, loss 1.75887, acc 0.136364\
1591276208: step 71, loss 1.88277, acc 0.0909091\
1591276209: step 72, loss 2.00971, acc 0.0909091\
1591276210: step 73, loss 1.57712, acc 0.318182\
1591276211: step 74, loss 1.89062, acc 0.136364\
1591276212: step 75, loss 1.80242, acc 0.181818\
1591276213: step 76, loss 1.71033, acc 0.227273\
1591276213: step 77, loss 1.84984, acc 0.136364\
1591276214: step 78, loss 1.66794, acc 0.136364\
1591276215: step 79, loss 1.59796, acc 0.181818\
1591276216: step 80, loss 1.70694, acc 0.136364\
1591276217: step 81, loss 1.53187, acc 0.363636\
1591276218: step 82, loss 1.91701, acc 0.136364\
1591276219: step 83, loss 1.83964, acc 0.227273\
1591276220: step 84, loss 1.68541, acc 0.272727\
1591276220: step 85, loss 1.68091, acc 0.318182\
1591276221: step 86, loss 1.89176, acc 0.136364\
1591276222: step 87, loss 1.90714, acc 0.318182\
1591276223: step 88, loss 1.70806, acc 0.181818\
1591276224: step 89, loss 2.02021, acc 0.136364\
1591276225: step 90, loss 1.61751, acc 0.318182\
1591276226: step 91, loss 1.65444, acc 0.181818\
1591276227: step 92, loss 1.75102, acc 0.136364\
1591276228: step 93, loss 1.67816, acc 0.227273\
1591276228: step 94, loss 1.72229, acc 0.181818\
1591276229: step 95, loss 1.82132, acc 0.318182\
1591276230: step 96, loss 1.60858, acc 0.318182\
1591276231: step 97, loss 1.85779, acc 0.181818\
1591276232: step 98, loss 1.5455, acc 0.363636\
1591276233: step 99, loss 1.75709, acc 0.272727\
1591276234: step 100, loss 1.93254, acc 0.227273\
++++++++++++++++++dev++++++++++++++1591276242: step 100, loss 1.88205, acc 0.235412\
1591276243: step 101, loss 1.80044, acc 0.136364\
1591276244: step 102, loss 2.10369, acc 0.181818\
1591276245: step 103, loss 1.90425, acc 0.363636\
1591276246: step 104, loss 2.08196, acc 0.227273\
1591276246: step 105, loss 1.82027, acc 0.227273\
1591276247: step 106, loss 1.64178, acc 0.272727\
1591276248: step 107, loss 1.89194, acc 0.181818\
1591276249: step 108, loss 2.12648, acc 0.272727\
1591276250: step 109, loss 2.06491, acc 0.227273\
1591276251: step 110, loss 1.83742, acc 0.181818\
1591276252: step 111, loss 1.67925, acc 0.272727\
1591276252: step 112, loss 1.77093, acc 0.227273\
1591276253: step 113, loss 1.73251, acc 0.272727\
1591276254: step 114, loss 1.94687, acc 0.272727\
1591276255: step 115, loss 1.5327, acc 0.363636\
1591276256: step 116, loss 2.38126, acc 0.318182\
1591276257: step 117, loss 1.8981, acc 0.227273\
1591276258: step 118, loss 2.00015, acc 0.181818\
1591276258: step 119, loss 1.79143, acc 0.227273\
1591276259: step 120, loss 1.68255, acc 0.181818\
1591276260: step 121, loss 1.77041, acc 0.136364\
1591276261: step 122, loss 1.68851, acc 0.272727\
1591276262: step 123, loss 2.91304, acc 0.181818\
1591276263: step 124, loss 1.73758, acc 0.227273\
1591276264: step 125, loss 2.10379, acc 0.227273\
1591276264: step 126, loss 1.92594, acc 0.363636\
1591276265: step 127, loss 1.78539, acc 0.318182\
1591276266: step 128, loss 1.97764, acc 0.181818\
1591276267: step 129, loss 2.11747, acc 0.272727\
1591276268: step 130, loss 1.42107, acc 0.363636\
1591276269: step 131, loss 2.12627, acc 0.272727\
1591276270: step 132, loss 1.59634, acc 0.318182\
1591276270: step 133, loss 2.3835, acc 0.363636\
1591276271: step 134, loss 1.76901, acc 0.454545\
1591276272: step 135, loss 2.11434, acc 0.136364\
1591276273: step 136, loss 2.97363, acc 0.181818\
1591276274: step 137, loss 2.70781, acc 0.181818\
1591276275: step 138, loss 2.3158, acc 0.227273\
1591276275: step 139, loss 1.82814, acc 0.227273\
1591276276: step 140, loss 1.83391, acc 0.227273\
1591276277: step 141, loss 2.70123, acc 0.136364\
1591276278: step 142, loss 3.29063, acc 0.181818\
1591276279: step 143, loss 2.35099, acc 0.272727\
1591276280: step 144, loss 2.21318, acc 0.0909091\
1591276281: step 145, loss 2.82072, acc 0.0909091\
1591276281: step 146, loss 1.95432, acc 0.0909091\
1591276282: step 147, loss 1.81294, acc 0.409091\
1591276283: step 148, loss 2.01703, acc 0.181818\
1591276284: step 149, loss 2.78918, acc 0.136364\
1591276285: step 150, loss 2.15899, acc 0.272727\
1591276286: step 151, loss 2.12611, acc 0.227273\
1591276286: step 152, loss 2.13582, acc 0.181818\
1591276287: step 153, loss 2.1484, acc 0.181818\
1591276288: step 154, loss 2.02538, acc 0.272727\
1591276289: step 155, loss 1.58948, acc 0.363636\
1591276290: step 156, loss 2.57644, acc 0.136364\
1591276291: step 157, loss 2.02456, acc 0.227273\
1591276291: step 158, loss 1.75242, acc 0.227273\
1591276292: step 159, loss 2.1279, acc 0.227273\
1591276293: step 160, loss 1.86089, acc 0.409091\
1591276294: step 161, loss 1.9123, acc 0.409091\
1591276295: step 162, loss 1.89289, acc 0.318182\
1591276296: step 163, loss 1.52076, acc 0.409091\
1591276297: step 164, loss 1.65518, acc 0.181818\
1591276297: step 165, loss 2.16796, acc 0.227273\
1591276298: step 166, loss 1.96176, acc 0.181818\
1591276299: step 167, loss 1.92319, acc 0.181818\
1591276300: step 168, loss 1.66085, acc 0.318182\
1591276301: step 169, loss 2.14083, acc 0.227273\
1591276302: step 170, loss 2.27804, acc 0.0909091\
1591276302: step 171, loss 1.95909, acc 0.227273\
1591276303: step 172, loss 2.01805, acc 0.272727\
1591276304: step 173, loss 1.98845, acc 0.136364\
1591276305: step 174, loss 1.72378, acc 0.227273\
1591276306: step 175, loss 1.85967, acc 0.272727\
1591276307: step 176, loss 2.06067, acc 0.136364\
1591276307: step 177, loss 1.77285, acc 0.227273\
1591276308: step 178, loss 1.69409, acc 0.181818\
1591276309: step 179, loss 1.62098, acc 0.181818\
1591276310: step 180, loss 1.91215, acc 0.181818\
1591276311: step 181, loss 1.61702, acc 0.318182\
1591276312: step 182, loss 1.74585, acc 0.181818\
1591276312: step 183, loss 1.85531, acc 0.227273\
1591276313: step 184, loss 1.51368, acc 0.363636\
1591276314: step 185, loss 1.58212, acc 0.181818\
1591276315: step 186, loss 1.52714, acc 0.272727\
1591276316: step 187, loss 1.64022, acc 0.227273\
1591276316: step 188, loss 1.70473, acc 0.272727\
1591276317: step 189, loss 1.85158, acc 0.181818\
1591276318: step 190, loss 1.55597, acc 0.318182\
1591276319: step 191, loss 1.78564, acc 0.181818\
1591276320: step 192, loss 1.4238, acc 0.363636\
1591276321: step 193, loss 1.69513, acc 0.318182\
1591276321: step 194, loss 1.9864, acc 0.181818\
1591276322: step 195, loss 1.50473, acc 0.409091\
1591276323: step 196, loss 1.74935, acc 0.272727\
1591276324: step 197, loss 1.93425, acc 0.181818\
1591276325: step 198, loss 1.63056, acc 0.272727\
1591276326: step 199, loss 1.85784, acc 0.272727\
1591276326: step 200, loss 1.5222, acc 0.136364\
++++++++++++++++++dev++++++++++++++1591276334: step 200, loss 1.47789, acc 0.293763\
1591276334: step 201, loss 1.51573, acc 0.227273\
1591276335: step 202, loss 1.52738, acc 0.227273\
1591276336: step 203, loss 1.44306, acc 0.227273\
1591276337: step 204, loss 1.45606, acc 0.571429\
current epoch 2\
1591276338: step 205, loss 1.32117, acc 0.5\
1591276338: step 206, loss 1.38779, acc 0.363636\
1591276339: step 207, loss 1.43796, acc 0.409091\
1591276340: step 208, loss 1.48625, acc 0.454545\
1591276341: step 209, loss 1.67692, acc 0.318182\
1591276342: step 210, loss 1.83735, acc 0.227273\
1591276343: step 211, loss 1.72138, acc 0.318182\
1591276343: step 212, loss 1.8828, acc 0.318182\
1591276344: step 213, loss 1.7265, acc 0.227273\
1591276345: step 214, loss 1.54944, acc 0.272727\
1591276346: step 215, loss 1.78174, acc 0.272727\
1591276347: step 216, loss 1.81594, acc 0.181818\
1591276348: step 217, loss 1.66204, acc 0.136364\
1591276348: step 218, loss 1.75273, acc 0.136364\
1591276349: step 219, loss 1.94914, acc 0.363636\
1591276350: step 220, loss 1.42177, acc 0.363636\
1591276351: step 221, loss 1.42182, acc 0.363636\
1591276352: step 222, loss 1.5456, acc 0.409091\
1591276353: step 223, loss 1.75757, acc 0.409091\
1591276353: step 224, loss 1.83795, acc 0.318182\
1591276354: step 225, loss 1.64727, acc 0.181818\
1591276355: step 226, loss 1.47731, acc 0.409091\
1591276356: step 227, loss 1.5914, acc 0.363636\
1591276357: step 228, loss 1.3394, acc 0.545455\
1591276358: step 229, loss 1.59559, acc 0.272727\
1591276358: step 230, loss 1.47548, acc 0.363636\
1591276359: step 231, loss 1.59725, acc 0.363636\
1591276360: step 232, loss 1.69126, acc 0.227273\
1591276361: step 233, loss 1.40417, acc 0.454545\
1591276362: step 234, loss 1.58725, acc 0.318182\
1591276363: step 235, loss 1.52245, acc 0.227273\
1591276363: step 236, loss 1.91536, acc 0.227273\
1591276364: step 237, loss 1.43344, acc 0.5\
1591276365: step 238, loss 1.47963, acc 0.227273\
1591276366: step 239, loss 1.85793, acc 0.318182\
1591276367: step 240, loss 1.948, acc 0.318182\
1591276368: step 241, loss 1.68838, acc 0.318182\
1591276368: step 242, loss 1.54765, acc 0.318182\
1591276369: step 243, loss 1.50997, acc 0.318182\
1591276370: step 244, loss 1.89855, acc 0.363636\
1591276371: step 245, loss 1.66429, acc 0.409091\
1591276372: step 246, loss 1.82317, acc 0.5\
1591276373: step 247, loss 1.57125, acc 0.454545\
1591276373: step 248, loss 1.67587, acc 0.272727\
1591276374: step 249, loss 1.73942, acc 0.227273\
1591276375: step 250, loss 2.00791, acc 0.227273\
1591276376: step 251, loss 1.36814, acc 0.363636\
1591276377: step 252, loss 1.60127, acc 0.227273\
1591276378: step 253, loss 2.44992, acc 0.181818\
1591276378: step 254, loss 2.17351, acc 0.227273\
1591276379: step 255, loss 1.74199, acc 0.318182\
1591276380: step 256, loss 1.47274, acc 0.272727\
1591276381: step 257, loss 1.67537, acc 0.227273\
1591276382: step 258, loss 1.97666, acc 0.227273\
1591276383: step 259, loss 2.91162, acc 0.272727\
1591276383: step 260, loss 1.56125, acc 0.363636\
1591276384: step 261, loss 2.75235, acc 0.136364\
1591276385: step 262, loss 1.47028, acc 0.409091\
1591276386: step 263, loss 1.56404, acc 0.363636\
1591276387: step 264, loss 1.14554, acc 0.409091\
1591276388: step 265, loss 1.38424, acc 0.363636\
1591276388: step 266, loss 1.48174, acc 0.454545\
1591276389: step 267, loss 1.39253, acc 0.454545\
1591276390: step 268, loss 1.41882, acc 0.227273\
1591276391: step 269, loss 1.47151, acc 0.363636\
1591276392: step 270, loss 1.26763, acc 0.318182\
1591276393: step 271, loss 1.30431, acc 0.272727\
1591276393: step 272, loss 1.39286, acc 0.363636\
1591276394: step 273, loss 1.59666, acc 0.227273\
1591276395: step 274, loss 1.48928, acc 0.363636\
1591276396: step 275, loss 1.47798, acc 0.409091\
1591276397: step 276, loss 1.65076, acc 0.181818\
1591276398: step 277, loss 1.21202, acc 0.454545\
1591276398: step 278, loss 1.71925, acc 0.272727\
1591276399: step 279, loss 1.71673, acc 0.363636\
1591276400: step 280, loss 1.72129, acc 0.409091\
1591276401: step 281, loss 1.26601, acc 0.409091\
1591276402: step 282, loss 1.64695, acc 0.454545\
1591276403: step 283, loss 1.22873, acc 0.409091\
1591276403: step 284, loss 1.55003, acc 0.272727\
1591276404: step 285, loss 1.22244, acc 0.590909\
1591276405: step 286, loss 1.72717, acc 0.227273\
1591276406: step 287, loss 1.48313, acc 0.272727\
1591276407: step 288, loss 1.37207, acc 0.181818\
1591276408: step 289, loss 1.57256, acc 0.318182\
1591276408: step 290, loss 1.31853, acc 0.409091\
1591276409: step 291, loss 1.51178, acc 0.181818\
1591276410: step 292, loss 1.29836, acc 0.454545\
1591276411: step 293, loss 1.54239, acc 0.318182\
1591276412: step 294, loss 1.59888, acc 0.409091\
1591276413: step 295, loss 1.49265, acc 0.454545\
1591276413: step 296, loss 1.49205, acc 0.409091\
1591276414: step 297, loss 1.33213, acc 0.409091\
1591276415: step 298, loss 1.76077, acc 0.318182\
1591276416: step 299, loss 1.21315, acc 0.454545\
1591276417: step 300, loss 1.53869, acc 0.454545\
++++++++++++++++++dev++++++++++++++1591276424: step 300, loss 1.36437, acc 0.386318\
1591276424: step 301, loss 1.39084, acc 0.454545\
1591276425: step 302, loss 1.25008, acc 0.545455\
1591276426: step 303, loss 1.39861, acc 0.363636\
1591276427: step 304, loss 1.57158, acc 0.454545\
1591276428: step 305, loss 1.5493, acc 0.363636\
1591276429: step 306, loss 1.41731, acc 0.181818\
1591276429: step 307, loss 1.34801, acc 0.409091\
1591276430: step 308, loss 1.83322, acc 0.318182\
1591276431: step 309, loss 1.37318, acc 0.318182\
1591276432: step 310, loss 1.4566, acc 0.409091\
1591276433: step 311, loss 1.47681, acc 0.363636\
1591276433: step 312, loss 1.5985, acc 0.409091\
1591276434: step 313, loss 1.4626, acc 0.363636\
1591276435: step 314, loss 1.42766, acc 0.227273\
1591276436: step 315, loss 1.41877, acc 0.318182\
1591276437: step 316, loss 1.12255, acc 0.454545\
1591276438: step 317, loss 1.76352, acc 0.181818\
1591276438: step 318, loss 1.23356, acc 0.454545\
1591276439: step 319, loss 1.14511, acc 0.5\
1591276440: step 320, loss 1.54548, acc 0.409091\
1591276441: step 321, loss 1.43754, acc 0.363636\
1591276442: step 322, loss 1.26891, acc 0.318182\
1591276443: step 323, loss 1.3064, acc 0.545455\
1591276444: step 324, loss 1.18073, acc 0.5\
1591276444: step 325, loss 1.46002, acc 0.454545\
1591276445: step 326, loss 1.12026, acc 0.454545\
1591276446: step 327, loss 1.36655, acc 0.318182\
1591276447: step 328, loss 1.38273, acc 0.227273\
1591276448: step 329, loss 1.25927, acc 0.363636\
1591276448: step 330, loss 1.36209, acc 0.454545\
1591276449: step 331, loss 1.38728, acc 0.363636\
1591276450: step 332, loss 1.32515, acc 0.454545\
1591276451: step 333, loss 1.24849, acc 0.454545\
1591276452: step 334, loss 1.27445, acc 0.5\
1591276453: step 335, loss 1.19416, acc 0.590909\
1591276453: step 336, loss 1.29805, acc 0.5\
1591276454: step 337, loss 1.27899, acc 0.318182\
1591276455: step 338, loss 1.33678, acc 0.363636\
1591276456: step 339, loss 1.52191, acc 0.272727\
1591276457: step 340, loss 1.23428, acc 0.409091\
1591276458: step 341, loss 1.2674, acc 0.363636\
1591276458: step 342, loss 1.22774, acc 0.454545\
1591276459: step 343, loss 1.39089, acc 0.318182\
1591276460: step 344, loss 1.07485, acc 0.409091\
1591276461: step 345, loss 1.25812, acc 0.363636\
1591276462: step 346, loss 2.82279, acc 0.272727\
1591276463: step 347, loss 2.79559, acc 0.318182\
1591276463: step 348, loss 1.77614, acc 0.318182\
1591276464: step 349, loss 1.54574, acc 0.363636\
1591276465: step 350, loss 1.73128, acc 0.272727\
1591276466: step 351, loss 1.67929, acc 0.318182\
1591276467: step 352, loss 2.52207, acc 0.227273\
1591276468: step 353, loss 1.40742, acc 0.318182\
1591276468: step 354, loss 1.66403, acc 0.272727\
1591276469: step 355, loss 1.47715, acc 0.5\
1591276470: step 356, loss 1.4525, acc 0.409091\
1591276471: step 357, loss 1.45615, acc 0.454545\
1591276472: step 358, loss 1.67244, acc 0.318182\
1591276473: step 359, loss 1.80864, acc 0.272727\
1591276473: step 360, loss 1.18011, acc 0.5\
1591276474: step 361, loss 1.97325, acc 0.227273\
1591276475: step 362, loss 1.35812, acc 0.363636\
1591276476: step 363, loss 1.27687, acc 0.409091\
1591276477: step 364, loss 1.33475, acc 0.5\
1591276478: step 365, loss 1.15273, acc 0.5\
1591276478: step 366, loss 1.03789, acc 0.5\
1591276479: step 367, loss 1.48397, acc 0.318182\
1591276480: step 368, loss 1.53789, acc 0.272727\
1591276481: step 369, loss 1.21186, acc 0.5\
1591276482: step 370, loss 1.23069, acc 0.272727\
1591276483: step 371, loss 1.31524, acc 0.363636\
1591276483: step 372, loss 1.42286, acc 0.363636\
1591276484: step 373, loss 1.41081, acc 0.409091\
1591276485: step 374, loss 1.46728, acc 0.363636\
1591276486: step 375, loss 1.28608, acc 0.409091\
1591276487: step 376, loss 1.36943, acc 0.318182\
1591276488: step 377, loss 1.31144, acc 0.409091\
1591276488: step 378, loss 1.73194, acc 0.409091\
1591276489: step 379, loss 1.37904, acc 0.5\
1591276490: step 380, loss 1.77488, acc 0.272727\
1591276491: step 381, loss 1.58426, acc 0.318182\
1591276492: step 382, loss 1.42854, acc 0.409091\
1591276493: step 383, loss 1.55526, acc 0.272727\
1591276493: step 384, loss 1.61386, acc 0.363636\
1591276494: step 385, loss 1.33651, acc 0.5\
1591276495: step 386, loss 1.30643, acc 0.363636\
1591276496: step 387, loss 1.42771, acc 0.363636\
1591276497: step 388, loss 1.44671, acc 0.409091\
1591276498: step 389, loss 1.44462, acc 0.409091\
1591276498: step 390, loss 1.32484, acc 0.545455\
1591276499: step 391, loss 1.21873, acc 0.363636\
1591276500: step 392, loss 1.32367, acc 0.545455\
1591276501: step 393, loss 1.70518, acc 0.318182\
1591276502: step 394, loss 1.19879, acc 0.5\
1591276503: step 395, loss 1.82097, acc 0.318182\
1591276503: step 396, loss 1.03836, acc 0.5\
1591276504: step 397, loss 1.39355, acc 0.363636\
1591276505: step 398, loss 1.45412, acc 0.227273\
1591276506: step 399, loss 1.20645, acc 0.454545\
1591276507: step 400, loss 1.22329, acc 0.454545\
++++++++++++++++++dev++++++++++++++1591276514: step 400, loss 1.24407, acc 0.420523\
1591276514: step 401, loss 1.3042, acc 0.318182\
1591276515: step 402, loss 1.42749, acc 0.454545\
1591276516: step 403, loss 1.52947, acc 0.545455\
1591276517: step 404, loss 1.13938, acc 0.454545\
1591276518: step 405, loss 1.17698, acc 0.454545\
1591276519: step 406, loss 1.27475, acc 0.363636\
1591276519: step 407, loss 1.04245, acc 0.363636\
1591276520: step 408, loss 1.00265, acc 0.571429\
current epoch 3\
1591276521: step 409, loss 0.912626, acc 0.545455\
1591276522: step 410, loss 0.885317, acc 0.5\
1591276522: step 411, loss 1.34536, acc 0.454545\
1591276523: step 412, loss 1.63669, acc 0.5\
1591276524: step 413, loss 1.45809, acc 0.454545\
1591276525: step 414, loss 1.48572, acc 0.318182\
1591276526: step 415, loss 1.17086, acc 0.545455\
1591276527: step 416, loss 1.30017, acc 0.590909\
1591276527: step 417, loss 1.40656, acc 0.545455\
1591276528: step 418, loss 1.67041, acc 0.545455\
1591276529: step 419, loss 1.30666, acc 0.409091\
1591276530: step 420, loss 1.33123, acc 0.318182\
1591276531: step 421, loss 1.53213, acc 0.5\
1591276532: step 422, loss 1.58592, acc 0.454545\
1591276533: step 423, loss 0.919557, acc 0.590909\
1591276533: step 424, loss 1.05838, acc 0.409091\
1591276534: step 425, loss 0.906192, acc 0.545455\
1591276535: step 426, loss 0.981818, acc 0.590909\
1591276536: step 427, loss 0.996775, acc 0.5\
1591276537: step 428, loss 0.976406, acc 0.545455\
1591276538: step 429, loss 1.21064, acc 0.590909\
1591276538: step 430, loss 1.77476, acc 0.363636\
1591276539: step 431, loss 1.13094, acc 0.454545\
1591276540: step 432, loss 1.07025, acc 0.5\
1591276541: step 433, loss 1.29987, acc 0.318182\
1591276542: step 434, loss 1.24979, acc 0.5\
1591276543: step 435, loss 1.02266, acc 0.5\
1591276544: step 436, loss 1.82904, acc 0.409091\
1591276545: step 437, loss 1.2222, acc 0.590909\
1591276546: step 438, loss 1.18864, acc 0.590909\
1591276547: step 439, loss 0.823985, acc 0.681818\
1591276548: step 440, loss 1.17454, acc 0.454545\
1591276549: step 441, loss 1.06346, acc 0.590909\
1591276550: step 442, loss 1.34767, acc 0.363636\
1591276550: step 443, loss 0.955005, acc 0.5\
1591276551: step 444, loss 1.02357, acc 0.454545\
1591276552: step 445, loss 1.04054, acc 0.545455\
1591276553: step 446, loss 0.898922, acc 0.5\
1591276554: step 447, loss 1.05998, acc 0.454545\
1591276555: step 448, loss 1.17668, acc 0.409091\
1591276555: step 449, loss 0.909895, acc 0.545455\
1591276556: step 450, loss 1.00802, acc 0.681818\
1591276557: step 451, loss 0.98081, acc 0.5\
1591276558: step 452, loss 1.09193, acc 0.454545\
1591276559: step 453, loss 1.1707, acc 0.590909\
1591276560: step 454, loss 3.66805, acc 0.181818\
1591276560: step 455, loss 2.6016, acc 0.363636\
1591276561: step 456, loss 1.14976, acc 0.5\
1591276562: step 457, loss 1.95055, acc 0.409091\
1591276563: step 458, loss 1.50975, acc 0.409091\
1591276564: step 459, loss 1.27696, acc 0.363636\
1591276565: step 460, loss 1.55274, acc 0.363636\
1591276565: step 461, loss 1.16576, acc 0.5\
1591276566: step 462, loss 1.98209, acc 0.318182\
1591276567: step 463, loss 2.29937, acc 0.318182\
1591276568: step 464, loss 1.19673, acc 0.454545\
1591276569: step 465, loss 2.03515, acc 0.181818\
1591276570: step 466, loss 1.44898, acc 0.409091\
1591276570: step 467, loss 1.41347, acc 0.454545\
1591276571: step 468, loss 1.49817, acc 0.318182\
1591276572: step 469, loss 1.49274, acc 0.363636\
1591276573: step 470, loss 1.51252, acc 0.409091\
1591276574: step 471, loss 1.1041, acc 0.636364\
1591276575: step 472, loss 1.34678, acc 0.409091\
1591276575: step 473, loss 1.63689, acc 0.363636\
1591276576: step 474, loss 1.04394, acc 0.5\
1591276577: step 475, loss 1.16735, acc 0.454545\
1591276578: step 476, loss 1.10828, acc 0.590909\
1591276579: step 477, loss 1.12481, acc 0.5\
1591276580: step 478, loss 1.10356, acc 0.5\
1591276580: step 479, loss 1.09734, acc 0.590909\
1591276581: step 480, loss 2.233, acc 0.363636\
1591276582: step 481, loss 1.40579, acc 0.363636\
1591276583: step 482, loss 1.74819, acc 0.5\
1591276584: step 483, loss 1.46117, acc 0.5\
1591276585: step 484, loss 1.27441, acc 0.318182\
1591276585: step 485, loss 1.05785, acc 0.454545\
1591276586: step 486, loss 1.38532, acc 0.409091\
1591276587: step 487, loss 0.919212, acc 0.545455\
1591276588: step 488, loss 1.48133, acc 0.318182\
1591276589: step 489, loss 1.03678, acc 0.545455\
1591276590: step 490, loss 1.593, acc 0.454545\
1591276591: step 491, loss 1.39145, acc 0.5\
1591276591: step 492, loss 1.24476, acc 0.454545\
1591276592: step 493, loss 1.18152, acc 0.5\
1591276593: step 494, loss 1.08352, acc 0.454545\
1591276594: step 495, loss 1.1658, acc 0.409091\
1591276595: step 496, loss 0.997443, acc 0.454545\
1591276596: step 497, loss 1.01415, acc 0.590909\
1591276596: step 498, loss 0.95165, acc 0.636364\
1591276597: step 499, loss 1.03763, acc 0.681818\
1591276598: step 500, loss 0.961725, acc 0.636364\
++++++++++++++++++dev++++++++++++++1591276605: step 500, loss 1.14104, acc 0.452716\
1591276606: step 501, loss 1.13646, acc 0.272727\
1591276606: step 502, loss 1.27944, acc 0.409091\
1591276607: step 503, loss 0.735193, acc 0.590909\
1591276608: step 504, loss 1.04193, acc 0.5\
1591276609: step 505, loss 1.04056, acc 0.590909\
1591276610: step 506, loss 1.119, acc 0.363636\
1591276611: step 507, loss 1.04401, acc 0.636364\
1591276611: step 508, loss 1.16559, acc 0.5\
1591276612: step 509, loss 1.70691, acc 0.227273\
1591276613: step 510, loss 1.40838, acc 0.545455\
1591276614: step 511, loss 1.29173, acc 0.5\
1591276615: step 512, loss 1.22737, acc 0.681818\
1591276616: step 513, loss 1.21409, acc 0.545455\
1591276617: step 514, loss 1.12693, acc 0.454545\
1591276617: step 515, loss 1.56148, acc 0.545455\
1591276618: step 516, loss 1.18434, acc 0.5\
1591276619: step 517, loss 1.09683, acc 0.409091\
1591276620: step 518, loss 1.31004, acc 0.409091\
1591276621: step 519, loss 1.18734, acc 0.636364\
1591276622: step 520, loss 0.82603, acc 0.590909\
1591276622: step 521, loss 0.997164, acc 0.318182\
1591276623: step 522, loss 0.977232, acc 0.5\
1591276624: step 523, loss 0.774117, acc 0.681818\
1591276625: step 524, loss 0.994709, acc 0.590909\
1591276626: step 525, loss 1.09807, acc 0.454545\
1591276627: step 526, loss 0.870599, acc 0.590909\
1591276627: step 527, loss 0.892333, acc 0.636364\
1591276628: step 528, loss 1.07254, acc 0.590909\
1591276629: step 529, loss 0.854578, acc 0.545455\
1591276630: step 530, loss 1.07358, acc 0.5\
1591276631: step 531, loss 0.727252, acc 0.636364\
1591276631: step 532, loss 0.994803, acc 0.454545\
1591276632: step 533, loss 0.988094, acc 0.636364\
1591276633: step 534, loss 0.863003, acc 0.590909\
1591276634: step 535, loss 0.853471, acc 0.545455\
1591276635: step 536, loss 0.811752, acc 0.681818\
1591276636: step 537, loss 1.07989, acc 0.636364\
1591276637: step 538, loss 1.16788, acc 0.590909\
1591276637: step 539, loss 0.8825, acc 0.590909\
1591276638: step 540, loss 1.00173, acc 0.545455\
1591276639: step 541, loss 1.09469, acc 0.5\
1591276640: step 542, loss 1.07152, acc 0.454545\
1591276641: step 543, loss 1.01082, acc 0.590909\
1591276642: step 544, loss 0.839816, acc 0.545455\
1591276643: step 545, loss 1.02193, acc 0.636364\
1591276643: step 546, loss 1.17624, acc 0.590909\
1591276644: step 547, loss 0.982856, acc 0.5\
1591276645: step 548, loss 0.856155, acc 0.636364\
1591276646: step 549, loss 0.931498, acc 0.5\
1591276647: step 550, loss 1.30834, acc 0.5\
1591276648: step 551, loss 0.721243, acc 0.772727\
1591276648: step 552, loss 1.29393, acc 0.409091\
1591276649: step 553, loss 1.1385, acc 0.363636\
1591276650: step 554, loss 1.65276, acc 0.318182\
1591276651: step 555, loss 1.72602, acc 0.454545\
1591276652: step 556, loss 1.37152, acc 0.545455\
1591276652: step 557, loss 1.12512, acc 0.454545\
1591276653: step 558, loss 0.86663, acc 0.545455\
1591276654: step 559, loss 1.70395, acc 0.409091\
1591276655: step 560, loss 1.14313, acc 0.454545\
1591276656: step 561, loss 0.835269, acc 0.636364\
1591276657: step 562, loss 0.733863, acc 0.636364\
1591276657: step 563, loss 1.17833, acc 0.318182\
1591276658: step 564, loss 0.738518, acc 0.636364\
1591276659: step 565, loss 0.969964, acc 0.590909\
1591276660: step 566, loss 0.839301, acc 0.681818\
1591276661: step 567, loss 0.993151, acc 0.545455\
1591276662: step 568, loss 0.789353, acc 0.636364\
1591276663: step 569, loss 0.886734, acc 0.636364\
1591276664: step 570, loss 1.32554, acc 0.590909\
1591276665: step 571, loss 0.776893, acc 0.727273\
1591276665: step 572, loss 2.22197, acc 0.318182\
1591276666: step 573, loss 1.18053, acc 0.636364\
1591276667: step 574, loss 0.739575, acc 0.636364\
1591276668: step 575, loss 0.906075, acc 0.590909\
1591276669: step 576, loss 0.973233, acc 0.545455\
1591276670: step 577, loss 1.18494, acc 0.590909\
1591276670: step 578, loss 1.01177, acc 0.636364\
1591276671: step 579, loss 0.893248, acc 0.545455\
1591276672: step 580, loss 1.34891, acc 0.409091\
1591276673: step 581, loss 1.02027, acc 0.454545\
1591276674: step 582, loss 0.913002, acc 0.590909\
1591276675: step 583, loss 0.730624, acc 0.772727\
1591276675: step 584, loss 1.20629, acc 0.5\
1591276676: step 585, loss 0.737453, acc 0.818182\
1591276677: step 586, loss 0.941187, acc 0.636364\
1591276678: step 587, loss 0.978867, acc 0.545455\
1591276679: step 588, loss 0.853479, acc 0.636364\
1591276680: step 589, loss 0.880801, acc 0.545455\
1591276680: step 590, loss 0.833301, acc 0.727273\
1591276681: step 591, loss 0.58326, acc 0.772727\
1591276682: step 592, loss 1.14828, acc 0.545455\
1591276683: step 593, loss 1.69451, acc 0.409091\
1591276684: step 594, loss 0.744134, acc 0.636364\
1591276684: step 595, loss 1.08351, acc 0.5\
1591276685: step 596, loss 0.755079, acc 0.681818\
1591276686: step 597, loss 0.902817, acc 0.636364\
1591276687: step 598, loss 1.09831, acc 0.636364\
1591276688: step 599, loss 1.2134, acc 0.590909\
1591276689: step 600, loss 1.22393, acc 0.363636\
++++++++++++++++++dev++++++++++++++1591276696: step 600, loss 1.09594, acc 0.579477\
1591276696: step 601, loss 1.27044, acc 0.454545\
1591276697: step 602, loss 1.04102, acc 0.590909\
1591276698: step 603, loss 0.634451, acc 0.727273\
1591276699: step 604, loss 1.02539, acc 0.5\
1591276700: step 605, loss 1.02297, acc 0.590909\
1591276701: step 606, loss 2.26435, acc 0.409091\
1591276701: step 607, loss 2.39655, acc 0.454545\
1591276702: step 608, loss 2.6295, acc 0.363636\
1591276703: step 609, loss 2.08902, acc 0.454545\
1591276704: step 610, loss 1.57656, acc 0.454545\
1591276705: step 611, loss 1.22526, acc 0.590909\
1591276705: step 612, loss 0.55052, acc 0.785714\
current epoch 4\
1591276706: step 613, loss 0.94794, acc 0.590909\
1591276707: step 614, loss 0.839221, acc 0.636364\
1591276708: step 615, loss 1.49329, acc 0.363636\
1591276709: step 616, loss 2.91941, acc 0.454545\
1591276709: step 617, loss 1.33502, acc 0.545455\
1591276710: step 618, loss 1.63727, acc 0.454545\
1591276711: step 619, loss 1.19435, acc 0.545455\
1591276712: step 620, loss 0.844832, acc 0.636364\
1591276713: step 621, loss 1.07026, acc 0.5\
1591276714: step 622, loss 0.85745, acc 0.636364\
1591276714: step 623, loss 1.16789, acc 0.590909\
1591276715: step 624, loss 1.0593, acc 0.5\
1591276716: step 625, loss 1.31542, acc 0.545455\
1591276717: step 626, loss 1.59536, acc 0.454545\
1591276718: step 627, loss 0.930412, acc 0.545455\
1591276719: step 628, loss 1.13421, acc 0.5\
1591276720: step 629, loss 0.577354, acc 0.727273\
1591276720: step 630, loss 0.735308, acc 0.772727\
1591276721: step 631, loss 0.829521, acc 0.636364\
1591276722: step 632, loss 0.911626, acc 0.636364\
1591276723: step 633, loss 1.68948, acc 0.590909\
1591276724: step 634, loss 0.939007, acc 0.681818\
1591276725: step 635, loss 0.434891, acc 0.863636\
1591276725: step 636, loss 0.808953, acc 0.681818\
1591276726: step 637, loss 1.16013, acc 0.545455\
1591276727: step 638, loss 1.23114, acc 0.636364\
1591276728: step 639, loss 0.972013, acc 0.590909\
1591276729: step 640, loss 0.972374, acc 0.636364\
1591276730: step 641, loss 0.859329, acc 0.681818\
1591276731: step 642, loss 1.25859, acc 0.636364\
1591276732: step 643, loss 0.860033, acc 0.590909\
1591276732: step 644, loss 0.747705, acc 0.681818\
1591276733: step 645, loss 1.03339, acc 0.590909\
1591276734: step 646, loss 1.85254, acc 0.454545\
1591276735: step 647, loss 0.856611, acc 0.590909\
1591276736: step 648, loss 1.41923, acc 0.590909\
1591276737: step 649, loss 0.867317, acc 0.545455\
1591276738: step 650, loss 0.851666, acc 0.681818\
1591276739: step 651, loss 1.08495, acc 0.681818\
1591276739: step 652, loss 1.02281, acc 0.727273\
1591276740: step 653, loss 0.906783, acc 0.590909\
1591276741: step 654, loss 1.02976, acc 0.681818\
1591276742: step 655, loss 1.0287, acc 0.5\
1591276743: step 656, loss 1.09422, acc 0.454545\
1591276744: step 657, loss 1.11016, acc 0.590909\
1591276744: step 658, loss 1.40982, acc 0.454545\
1591276745: step 659, loss 1.82365, acc 0.545455\
1591276746: step 660, loss 0.679988, acc 0.772727\
1591276747: step 661, loss 1.13392, acc 0.590909\
1591276748: step 662, loss 1.21565, acc 0.636364\
1591276749: step 663, loss 0.858056, acc 0.818182\
1591276750: step 664, loss 0.884626, acc 0.727273\
1591276750: step 665, loss 1.05094, acc 0.545455\
1591276751: step 666, loss 1.23392, acc 0.454545\
1591276752: step 667, loss 0.951397, acc 0.636364\
1591276753: step 668, loss 0.575836, acc 0.727273\
1591276754: step 669, loss 1.30016, acc 0.454545\
1591276754: step 670, loss 1.21114, acc 0.545455\
1591276755: step 671, loss 1.59968, acc 0.636364\
1591276756: step 672, loss 0.756588, acc 0.681818\
1591276757: step 673, loss 0.946346, acc 0.545455\
1591276758: step 674, loss 0.881501, acc 0.636364\
1591276759: step 675, loss 0.564967, acc 0.772727\
1591276759: step 676, loss 1.38027, acc 0.681818\
1591276760: step 677, loss 0.870117, acc 0.727273\
1591276761: step 678, loss 0.579612, acc 0.681818\
1591276762: step 679, loss 1.02665, acc 0.5\
1591276763: step 680, loss 0.588175, acc 0.727273\
1591276764: step 681, loss 1.19708, acc 0.545455\
1591276765: step 682, loss 1.3967, acc 0.363636\
1591276765: step 683, loss 0.894642, acc 0.636364\
1591276766: step 684, loss 1.0082, acc 0.727273\
1591276767: step 685, loss 0.77453, acc 0.681818\
1591276768: step 686, loss 0.592682, acc 0.727273\
1591276769: step 687, loss 1.52128, acc 0.454545\
1591276770: step 688, loss 1.43529, acc 0.545455\
1591276771: step 689, loss 0.775208, acc 0.681818\
1591276771: step 690, loss 1.37373, acc 0.409091\
1591276772: step 691, loss 0.818328, acc 0.772727\
1591276773: step 692, loss 1.04227, acc 0.636364\
1591276774: step 693, loss 0.54066, acc 0.863636\
1591276775: step 694, loss 0.78605, acc 0.590909\
1591276775: step 695, loss 0.586676, acc 0.818182\
1591276776: step 696, loss 0.76771, acc 0.772727\
1591276777: step 697, loss 1.0746, acc 0.545455\
1591276778: step 698, loss 1.02324, acc 0.5\
1591276779: step 699, loss 0.645655, acc 0.681818\
1591276780: step 700, loss 0.66969, acc 0.681818\
++++++++++++++++++dev++++++++++++++1591276787: step 700, loss 0.866814, acc 0.668008\
1591276788: step 701, loss 0.585025, acc 0.681818\
1591276789: step 702, loss 0.847339, acc 0.681818\
1591276790: step 703, loss 0.578899, acc 0.772727\
1591276790: step 704, loss 0.731444, acc 0.636364\
1591276791: step 705, loss 0.84091, acc 0.545455\
1591276792: step 706, loss 0.940583, acc 0.590909\
1591276793: step 707, loss 0.486422, acc 0.727273\
1591276794: step 708, loss 1.03842, acc 0.5\
1591276795: step 709, loss 0.602063, acc 0.772727\
1591276796: step 710, loss 0.637538, acc 0.772727\
1591276797: step 711, loss 0.729233, acc 0.636364\
1591276797: step 712, loss 1.02264, acc 0.681818\
1591276798: step 713, loss 1.13797, acc 0.5\
1591276799: step 714, loss 0.720266, acc 0.727273\
1591276800: step 715, loss 0.877939, acc 0.636364\
1591276801: step 716, loss 0.853672, acc 0.727273\
1591276802: step 717, loss 0.630035, acc 0.681818\
1591276802: step 718, loss 0.859087, acc 0.545455\
1591276803: step 719, loss 0.746703, acc 0.681818\
1591276804: step 720, loss 1.13579, acc 0.545455\
1591276805: step 721, loss 0.846506, acc 0.636364\
1591276806: step 722, loss 0.899169, acc 0.590909\
1591276807: step 723, loss 0.851393, acc 0.636364\
1591276807: step 724, loss 1.12958, acc 0.727273\
1591276808: step 725, loss 0.684479, acc 0.772727\
1591276809: step 726, loss 0.529249, acc 0.818182\
1591276810: step 727, loss 0.647649, acc 0.681818\
1591276811: step 728, loss 0.48371, acc 0.727273\
1591276812: step 729, loss 0.997347, acc 0.636364\
1591276812: step 730, loss 0.52438, acc 0.772727\
1591276813: step 731, loss 0.862895, acc 0.727273\
1591276814: step 732, loss 1.1035, acc 0.636364\
1591276815: step 733, loss 0.876488, acc 0.590909\
1591276816: step 734, loss 0.710216, acc 0.772727\
1591276817: step 735, loss 0.476849, acc 0.772727\
1591276817: step 736, loss 0.687702, acc 0.681818\
1591276818: step 737, loss 0.635641, acc 0.727273\
1591276819: step 738, loss 0.734771, acc 0.681818\
1591276820: step 739, loss 1.06687, acc 0.545455\
1591276821: step 740, loss 1.03369, acc 0.545455\
1591276822: step 741, loss 0.667315, acc 0.818182\
1591276823: step 742, loss 0.694559, acc 0.636364\
1591276823: step 743, loss 0.692128, acc 0.727273\
1591276824: step 744, loss 0.587943, acc 0.772727\
1591276825: step 745, loss 0.584104, acc 0.772727\
1591276826: step 746, loss 0.629812, acc 0.772727\
1591276827: step 747, loss 1.18247, acc 0.545455\
1591276828: step 748, loss 0.787238, acc 0.727273\
1591276828: step 749, loss 0.689781, acc 0.772727\
1591276829: step 750, loss 0.964068, acc 0.727273\
1591276830: step 751, loss 0.612028, acc 0.681818\
1591276831: step 752, loss 0.85053, acc 0.590909\
1591276832: step 753, loss 0.98625, acc 0.681818\
1591276832: step 754, loss 1.03429, acc 0.590909\
1591276833: step 755, loss 0.471513, acc 0.818182\
1591276834: step 756, loss 0.747695, acc 0.636364\
1591276835: step 757, loss 0.986275, acc 0.590909\
1591276836: step 758, loss 0.864824, acc 0.545455\
1591276837: step 759, loss 0.670545, acc 0.772727\
1591276837: step 760, loss 0.525828, acc 0.818182\
1591276838: step 761, loss 0.571777, acc 0.772727\
1591276839: step 762, loss 0.463935, acc 0.772727\
1591276840: step 763, loss 1.25981, acc 0.636364\
1591276841: step 764, loss 0.624376, acc 0.772727\
1591276842: step 765, loss 0.639744, acc 0.681818\
1591276842: step 766, loss 0.841351, acc 0.681818\
1591276843: step 767, loss 1.59463, acc 0.545455\
1591276844: step 768, loss 0.681848, acc 0.772727\
1591276845: step 769, loss 0.747291, acc 0.681818\
1591276846: step 770, loss 0.565314, acc 0.727273\
1591276847: step 771, loss 0.756731, acc 0.727273\
1591276848: step 772, loss 0.576929, acc 0.681818\
1591276848: step 773, loss 0.834746, acc 0.636364\
1591276849: step 774, loss 1.1423, acc 0.681818\
1591276850: step 775, loss 0.304818, acc 0.909091\
1591276851: step 776, loss 1.28531, acc 0.5\
1591276852: step 777, loss 0.652202, acc 0.681818\
1591276853: step 778, loss 0.317637, acc 0.863636\
1591276853: step 779, loss 0.62152, acc 0.772727\
1591276854: step 780, loss 0.421379, acc 0.863636\
1591276855: step 781, loss 1.04162, acc 0.681818\
1591276856: step 782, loss 0.775027, acc 0.772727\
1591276857: step 783, loss 0.733208, acc 0.681818\
1591276858: step 784, loss 0.812391, acc 0.681818\
1591276859: step 785, loss 0.540688, acc 0.818182\
1591276859: step 786, loss 0.482136, acc 0.863636\
1591276860: step 787, loss 0.483979, acc 0.818182\
1591276861: step 788, loss 0.856648, acc 0.681818\
1591276862: step 789, loss 0.326697, acc 0.863636\
1591276863: step 790, loss 0.736323, acc 0.636364\
1591276864: step 791, loss 0.688464, acc 0.727273\
1591276865: step 792, loss 0.473398, acc 0.772727\
1591276865: step 793, loss 0.65416, acc 0.863636\
1591276866: step 794, loss 1.1627, acc 0.545455\
1591276867: step 795, loss 0.450215, acc 0.818182\
1591276868: step 796, loss 0.641005, acc 0.727273\
1591276869: step 797, loss 0.613362, acc 0.681818\
1591276870: step 798, loss 0.524965, acc 0.772727\
1591276871: step 799, loss 0.682299, acc 0.727273\
1591276871: step 800, loss 0.499816, acc 0.863636\
++++++++++++++++++dev++++++++++++++1591276878: step 800, loss 0.776975, acc 0.70825\
1591276879: step 801, loss 0.595098, acc 0.727273\
1591276880: step 802, loss 0.438179, acc 0.772727\
1591276881: step 803, loss 0.829016, acc 0.818182\
1591276882: step 804, loss 0.528216, acc 0.863636\
1591276882: step 805, loss 1.02391, acc 0.681818\
1591276883: step 806, loss 1.3714, acc 0.636364\
1591276884: step 807, loss 0.4211, acc 0.818182\
1591276885: step 808, loss 0.645473, acc 0.818182\
1591276886: step 809, loss 0.726019, acc 0.727273\
1591276887: step 810, loss 0.495337, acc 0.818182\
1591276887: step 811, loss 1.23599, acc 0.545455\
1591276888: step 812, loss 0.882193, acc 0.727273\
1591276889: step 813, loss 0.434058, acc 0.818182\
1591276890: step 814, loss 0.964339, acc 0.5\
1591276891: step 815, loss 0.729137, acc 0.636364\
1591276891: step 816, loss 0.255915, acc 0.928571\
current epoch 5\
1591276892: step 817, loss 0.525842, acc 0.681818\
1591276893: step 818, loss 0.71268, acc 0.727273\
1591276894: step 819, loss 0.594088, acc 0.772727\
1591276895: step 820, loss 0.548343, acc 0.727273\
1591276895: step 821, loss 0.518496, acc 0.772727\
1591276896: step 822, loss 0.715865, acc 0.590909\
1591276897: step 823, loss 0.827276, acc 0.636364\
1591276898: step 824, loss 0.509125, acc 0.727273\
1591276899: step 825, loss 0.864307, acc 0.818182\
1591276900: step 826, loss 0.86871, acc 0.636364\
1591276901: step 827, loss 0.336515, acc 0.863636\
1591276901: step 828, loss 0.71643, acc 0.727273\
1591276902: step 829, loss 0.730679, acc 0.727273\
1591276903: step 830, loss 0.783013, acc 0.727273\
1591276904: step 831, loss 0.601344, acc 0.727273\
1591276905: step 832, loss 0.665045, acc 0.727273\
1591276906: step 833, loss 0.710673, acc 0.818182\
1591276906: step 834, loss 0.855625, acc 0.727273\
1591276907: step 835, loss 0.616605, acc 0.863636\
1591276908: step 836, loss 0.412529, acc 0.818182\
1591276909: step 837, loss 0.971436, acc 0.636364\
1591276910: step 838, loss 0.561124, acc 0.818182\
1591276911: step 839, loss 1.2002, acc 0.727273\
1591276911: step 840, loss 0.219585, acc 0.909091\
1591276912: step 841, loss 0.521571, acc 0.863636\
1591276913: step 842, loss 0.893783, acc 0.727273\
1591276914: step 843, loss 0.458384, acc 0.772727\
1591276915: step 844, loss 0.378897, acc 0.863636\
1591276916: step 845, loss 0.746788, acc 0.727273\
1591276916: step 846, loss 0.47852, acc 0.772727\
1591276917: step 847, loss 0.34944, acc 0.818182\
1591276918: step 848, loss 0.53553, acc 0.818182\
1591276919: step 849, loss 0.58481, acc 0.727273\
1591276920: step 850, loss 0.739744, acc 0.590909\
1591276921: step 851, loss 0.423819, acc 0.863636\
1591276921: step 852, loss 0.417848, acc 0.863636\
1591276922: step 853, loss 0.596816, acc 0.727273\
1591276923: step 854, loss 0.407261, acc 0.772727\
1591276924: step 855, loss 0.743254, acc 0.681818\
1591276925: step 856, loss 0.431163, acc 0.818182\
1591276926: step 857, loss 0.290417, acc 0.909091\
1591276926: step 858, loss 0.460897, acc 0.772727\
1591276927: step 859, loss 0.4411, acc 0.772727\
1591276928: step 860, loss 0.577911, acc 0.727273\
1591276929: step 861, loss 0.780408, acc 0.772727\
1591276930: step 862, loss 0.484107, acc 0.772727\
1591276931: step 863, loss 1.08652, acc 0.727273\
1591276931: step 864, loss 0.462277, acc 0.727273\
1591276932: step 865, loss 0.64321, acc 0.772727\
1591276933: step 866, loss 1.32699, acc 0.545455\
1591276934: step 867, loss 0.907368, acc 0.772727\
1591276935: step 868, loss 0.705414, acc 0.772727\
1591276936: step 869, loss 0.386561, acc 0.909091\
1591276936: step 870, loss 0.393253, acc 0.863636\
1591276937: step 871, loss 0.538949, acc 0.772727\
1591276938: step 872, loss 0.524922, acc 0.772727\
1591276939: step 873, loss 1.25418, acc 0.636364\
1591276940: step 874, loss 1.10046, acc 0.636364\
1591276941: step 875, loss 0.669003, acc 0.681818\
1591276941: step 876, loss 0.347193, acc 0.772727\
1591276942: step 877, loss 0.560471, acc 0.727273\
1591276943: step 878, loss 0.697278, acc 0.772727\
1591276944: step 879, loss 0.191947, acc 0.909091\
1591276945: step 880, loss 1.1585, acc 0.681818\
1591276946: step 881, loss 0.552511, acc 0.818182\
1591276946: step 882, loss 0.558994, acc 0.727273\
1591276947: step 883, loss 0.708159, acc 0.818182\
1591276948: step 884, loss 0.451028, acc 0.818182\
1591276949: step 885, loss 0.443927, acc 0.772727\
1591276950: step 886, loss 0.571659, acc 0.681818\
1591276951: step 887, loss 0.294585, acc 0.909091\
1591276952: step 888, loss 0.823552, acc 0.727273\
1591276952: step 889, loss 0.547934, acc 0.863636\
1591276953: step 890, loss 0.593968, acc 0.681818\
1591276954: step 891, loss 1.60839, acc 0.545455\
1591276955: step 892, loss 0.713539, acc 0.636364\
1591276956: step 893, loss 0.498513, acc 0.772727\
1591276957: step 894, loss 1.57257, acc 0.636364\
1591276957: step 895, loss 0.74697, acc 0.727273\
1591276958: step 896, loss 1.75138, acc 0.636364\
1591276959: step 897, loss 0.303284, acc 0.863636\
1591276960: step 898, loss 0.58312, acc 0.772727\
1591276961: step 899, loss 0.58387, acc 0.727273\
1591276962: step 900, loss 0.655196, acc 0.772727\
++++++++++++++++++dev++++++++++++++1591276969: step 900, loss 0.849256, acc 0.732394\
1591276970: step 901, loss 0.804692, acc 0.681818\
1591276970: step 902, loss 0.420364, acc 0.818182\
1591276971: step 903, loss 0.260804, acc 0.863636\
1591276972: step 904, loss 0.399383, acc 0.863636\
1591276973: step 905, loss 0.422017, acc 0.727273\
1591276974: step 906, loss 0.91963, acc 0.590909\
1591276975: step 907, loss 0.137406, acc 0.954545\
1591276975: step 908, loss 0.340576, acc 0.818182\
1591276976: step 909, loss 0.492397, acc 0.772727\
1591276977: step 910, loss 1.02145, acc 0.681818\
1591276978: step 911, loss 0.627592, acc 0.863636\
1591276979: step 912, loss 0.591584, acc 0.590909\
1591276979: step 913, loss 0.774848, acc 0.863636\
1591276980: step 914, loss 0.400889, acc 0.818182\
1591276981: step 915, loss 0.324691, acc 0.772727\
1591276982: step 916, loss 0.929526, acc 0.772727\
1591276983: step 917, loss 0.868951, acc 0.727273\
1591276984: step 918, loss 0.696219, acc 0.772727\
1591276984: step 919, loss 0.639636, acc 0.727273\
1591276985: step 920, loss 0.52724, acc 0.863636\
1591276986: step 921, loss 0.713949, acc 0.772727\
1591276987: step 922, loss 0.423686, acc 0.818182\
1591276988: step 923, loss 0.563846, acc 0.818182\
1591276989: step 924, loss 0.846059, acc 0.681818\
1591276989: step 925, loss 0.441533, acc 0.863636\
1591276990: step 926, loss 1.05219, acc 0.681818\
1591276991: step 927, loss 0.411663, acc 0.818182\
1591276992: step 928, loss 0.639546, acc 0.772727\
1591276993: step 929, loss 0.73652, acc 0.681818\
1591276994: step 930, loss 0.377203, acc 0.818182\
1591276995: step 931, loss 0.562412, acc 0.727273\
1591276995: step 932, loss 0.390001, acc 0.863636\
1591276996: step 933, loss 0.677849, acc 0.772727\
1591276997: step 934, loss 0.351317, acc 0.863636\
1591276998: step 935, loss 0.536126, acc 0.772727\
1591276999: step 936, loss 0.406548, acc 0.818182\
1591276999: step 937, loss 0.400113, acc 0.818182\
1591277000: step 938, loss 0.571762, acc 0.772727\
1591277001: step 939, loss 0.36514, acc 0.818182\
1591277002: step 940, loss 0.805168, acc 0.681818\
1591277003: step 941, loss 0.394145, acc 0.909091\
1591277004: step 942, loss 0.447162, acc 0.818182\
1591277004: step 943, loss 0.520837, acc 0.772727\
1591277005: step 944, loss 0.577416, acc 0.863636\
1591277006: step 945, loss 0.585906, acc 0.772727\
1591277007: step 946, loss 0.656496, acc 0.772727\
1591277008: step 947, loss 0.360587, acc 0.863636\
1591277009: step 948, loss 0.528177, acc 0.727273\
1591277009: step 949, loss 0.249752, acc 0.909091\
1591277010: step 950, loss 0.357658, acc 0.909091\
1591277011: step 951, loss 0.673378, acc 0.727273\
1591277012: step 952, loss 0.416335, acc 0.863636\
1591277013: step 953, loss 0.655824, acc 0.727273\
1591277014: step 954, loss 0.616854, acc 0.818182\
1591277014: step 955, loss 0.269778, acc 0.954545\
1591277015: step 956, loss 0.379839, acc 0.863636\
1591277016: step 957, loss 0.361122, acc 0.818182\
1591277017: step 958, loss 0.762783, acc 0.863636\
1591277018: step 959, loss 0.19921, acc 0.954545\
1591277019: step 960, loss 0.321036, acc 0.909091\
1591277019: step 961, loss 0.340558, acc 0.909091\
1591277020: step 962, loss 0.263324, acc 0.909091\
1591277021: step 963, loss 0.394193, acc 0.863636\
1591277022: step 964, loss 0.230191, acc 0.954545\
1591277023: step 965, loss 0.270592, acc 0.909091\
1591277024: step 966, loss 0.201307, acc 0.909091\
1591277024: step 967, loss 0.877997, acc 0.636364\
1591277025: step 968, loss 0.293203, acc 0.863636\
1591277026: step 969, loss 0.277022, acc 0.863636\
1591277027: step 970, loss 0.656613, acc 0.818182\
1591277028: step 971, loss 0.414787, acc 0.863636\
1591277029: step 972, loss 0.226825, acc 0.863636\
1591277029: step 973, loss 0.220204, acc 0.909091\
1591277030: step 974, loss 0.114613, acc 0.954545\
1591277031: step 975, loss 0.225368, acc 0.909091\
1591277032: step 976, loss 0.204134, acc 0.954545\
1591277033: step 977, loss 0.365494, acc 0.863636\
1591277034: step 978, loss 0.586196, acc 0.727273\
1591277034: step 979, loss 0.119429, acc 0.954545\
1591277035: step 980, loss 0.692706, acc 0.727273\
1591277036: step 981, loss 0.255118, acc 0.863636\
1591277037: step 982, loss 0.17166, acc 0.954545\
1591277038: step 983, loss 0.21571, acc 0.909091\
1591277038: step 984, loss 0.18624, acc 0.954545\
1591277039: step 985, loss 0.425224, acc 0.863636\
1591277040: step 986, loss 0.546588, acc 0.818182\
1591277041: step 987, loss 0.3323, acc 0.818182\
1591277042: step 988, loss 0.729369, acc 0.863636\
1591277043: step 989, loss 0.525467, acc 0.909091\
1591277043: step 990, loss 0.243802, acc 0.863636\
1591277044: step 991, loss 0.704004, acc 0.772727\
1591277045: step 992, loss 0.611067, acc 0.818182\
1591277046: step 993, loss 0.216985, acc 0.909091\
1591277047: step 994, loss 0.371642, acc 0.863636\
1591277048: step 995, loss 0.557593, acc 0.681818\
1591277048: step 996, loss 0.483615, acc 0.863636\
1591277049: step 997, loss 0.584014, acc 0.772727\
1591277050: step 998, loss 0.71719, acc 0.772727\
1591277051: step 999, loss 0.160712, acc 0.909091\
1591277052: step 1000, loss 0.329764, acc 0.909091\
++++++++++++++++++dev++++++++++++++1591277059: step 1000, loss 0.669248, acc 0.764588}